[{"path":"https://gosukehommaEX.github.io/twoCoprimary/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Gosuke Homma Permission hereby granted, free charge, person obtaining copy software associated documentation files (‚ÄúSoftware‚Äù), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED ‚Äú‚Äù, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"vignette demonstrates sample size calculation clinical trials two co-primary endpoints one continuous one binary. methodology based Sozu et al.¬†(2012). Important note notation: Sozu et al.¬†(2012), allocation ratio defined Œ∫=n2/n1\\kappa = n_{2}/n_{1} (control/treatment), inverse notation used papers package r=n1/n2r = n_{1}/n_{2} (treatment/control). Therefore, Œ∫=1/r\\kappa = 1/r. vignette, follow notation original paper using Œ∫\\kappa maintain consistency published formulas.","code":"library(twoCoprimary) library(dplyr) library(tidyr) library(knitr)"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"clinical-context","dir":"Articles","previous_headings":"Background","what":"Clinical Context","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Mixed continuous binary co-primary endpoints common : Rheumatoid arthritis trials: mean change baseline modified total Sharp score (mTSS) + ACR50 response (yes/) Chronic kidney disease trials: mean peak percentage change baseline serum creatinine 72-h period contrast media administration + contrast-induced nephropathy (yes/)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"why-mixed-endpoints","dir":"Articles","previous_headings":"Background","what":"Why Mixed Endpoints?","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Combining continuous binary endpoints provides: Comprehensive assessment: Magnitude change (continuous) + clinical meaningfulness (binary) Regulatory relevance: Many guidelines require types Clinical interpretability: Binary endpoints easier communicate patients","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"model-and-assumptions","dir":"Articles","previous_headings":"Statistical Framework","what":"Model and Assumptions","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Consider two-arm superiority trial sample sizes n1n_{1} (treatment) n2n_{2} (control), allocation ratio Œ∫=n2/n1\\kappa = n_{2}/n_{1}. subject ii group jj (j=1j = 1: treatment, j=2j = 2: control), observe two outcomes: Outcome 1 (Continuous) (k=1k = 1): Xi,j,1‚àºN(Œºj,œÉ2)X_{,j,1} \\sim \\text{N}(\\mu_{j}, \\sigma^2) Œºj\\mu_{j} population mean group jj œÉ2\\sigma^{2} common variance across groups. Outcome 2 (Binary) (k=2k = 2): Xi,j,2‚àà{0,1}X_{,j,2} \\\\{0, 1\\} Xi,j,2=1X_{,j,2} = 1 subject ii group jj responds successfully, 0 otherwise. Let pjp_{j} denotes true success probability group jj endpoint 22.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"correlation-structure-biserial-correlation","dir":"Articles","previous_headings":"Statistical Framework","what":"Correlation Structure: Biserial Correlation","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"correlation continuous outcome binary outcome requires special consideration. Following Sozu et al.¬†(2012), assume outcomes latent bivariate normal distributions. Key concept: binary outcome Xi,j,2X_{,j,2} assumed arise dichotomizing latent continuous variable Xi,j,2*X_{,j,2}^{*} (.e., Xi,j,2*‚àºN(Œºj*,œÉ2*X_{,j,2}^{*}\\sim\\text{N}(\\mu_{j}^{\\ast},\\sigma^{2\\ast}): Xi,j,2={1if Xi,j,2*‚â•gj0if Xi,j,2*<gjX_{,j,2} = \\begin{cases}  1 & \\text{} X_{,j,2}^* \\geq g_{j} \\\\ 0 & \\text{} X_{,j,2}^* < g_{j} \\end{cases} gjg_{j} threshold (cut-point) P(Xi,j,2=1)=pj=P(Xi,j,2*‚â•gj)\\text{P}(X_{,j,2} = 1) = p_{j} = \\text{P}(X_{,j,2}^{*} \\geq g_{j}). Biserial correlation: Assuming (Xi,j,1,Xi,j,2*)(X_{,j,1}, X_{,j,2}^{*}) follow bivariate normal distribution, biserial correlation œÅ\\rho measures correlation continuous outcome latent continuous variable underlying binary outcome. detailed formula relating biserial correlation correlation test statistics, see Sozu et al.¬†(2012), equation (1) Supporting Information.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"hypothesis-testing","dir":"Articles","previous_headings":"Statistical Framework","what":"Hypothesis Testing","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"test superiority treatment control endpoints: continuous endpoint (1): H01:Œº1‚àíŒº2‚â§0 vs. H11:Œº1‚àíŒº2>0\\text{H}_{01}: \\mu_{1} - \\mu_{2} \\leq 0 \\text{ vs. } \\text{H}_{11}: \\mu_{1} - \\mu_{2} > 0 binary endpoint (2): H02:p1‚àíp2‚â§0 vs. H12:p1‚àíp2>0\\text{H}_{02}: p_{1} - p_{2} \\leq 0 \\text{ vs. } \\text{H}_{12}: p_{1} - p_{2} > 0 Co-primary endpoints (intersection-union test): H0=H01‚à™H02 vs. H1=H11‚à©H12\\text{H}_0 = \\text{H}_{01} \\cup \\text{H}_{02} \\text{ vs. } \\text{H}_1 = \\text{H}_{11} \\cap \\text{H}_{12} Reject H0\\text{H}_{0} level Œ±\\alpha H01\\text{H}_{01} H02\\text{H}_{02} rejected level Œ±\\alpha.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"test-statistics","dir":"Articles","previous_headings":"Statistical Framework","what":"Test Statistics","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Continuous endpoint (Equation 2 Sozu et al., 2012): Z1=X‚Äæ1‚àíX‚Äæ2œÉ1+Œ∫n1Z_{1} = \\frac{\\bar{X}_{1} - \\bar{X}_{2}}{\\sigma\\sqrt{\\frac{1+\\kappa}{n_{1}}}} X‚Äæ1\\bar{X}_{1} X‚Äæ2\\bar{X}_{2} sample means. œÉ\\sigma unknown, use pooled sample standard deviation. Binary endpoint - Asymptotic Normal () method (Equation 3 Sozu et al., 2012): Z2=pÃÇ1‚àípÃÇ2(1n1+1n2)pÃÇ(1‚àípÃÇ)Z_{2} = \\frac{\\hat{p}_{1} - \\hat{p}_{2}}{\\sqrt{\\left(\\frac{1}{n_{1}} + \\frac{1}{n_{2}}\\right) \\hat{p}(1 - \\hat{p})}} : pÃÇ1\\hat{p}_{1} pÃÇ2\\hat{p}_{2} sample proportions pÃÇ=n1pÃÇ1+n2pÃÇ2n1+n2\\hat{p} = \\frac{n_{1}\\hat{p}_{1} + n_{2}\\hat{p}_{2}}{n_{1} + n_{2}} pooled proportion test methods: Sozu et al.¬†(2012) also present: ANc: Asymptotic normal continuity correction (equation 5) : Arcsine transformation without continuity correction (equation 6) ASc: Arcsine transformation continuity correction (equation 7) Fisher: Fisher‚Äôs exact test (simulation-based) See paper detailed formulas. twoCoprimary package implements five methods. Note Fisher‚Äôs exact test closed-form sample size formula requires simulation-based power calculation.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"joint-distribution-and-power-calculation","dir":"Articles","previous_headings":"Statistical Framework","what":"Joint Distribution and Power Calculation","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"H1\\text{H}_{1}, test statistics (Z1,Z2)(Z_{1}, Z_{2}) asymptotically follow bivariate normal distribution. overall power given (Equation 4 Sozu et al., 2012): 1‚àíŒ≤=P[‚ãÇk=12{Zk>zŒ±}]‚âàP[‚ãÇk=12{Zk*>ck*}]1 - \\beta = \\text{P}\\left[\\bigcap_{k=1}^{2} \\{Z_{k} > z_{\\alpha}\\}\\right] \\approx \\text{P}\\left[\\bigcap_{k=1}^{2} \\left\\{Z_{k}^{*} > c_{k}^{*}\\right\\}\\right] Zk*=pÃÇ1‚àípÃÇ2‚àíŒîksekZ_{k}^{*} = \\frac{\\hat{p}_{1} - \\hat{p}_{2} - \\Delta_{k}}{se_{k}} Œîk\\Delta_{k} treatment effect, : continuous endpoint (k=1k = 1): c1*=zŒ±‚àíŒ¥1œÉŒ∫n11+Œ∫c_{1}^{*} = z_{\\alpha} - \\frac{\\delta_{1}}{\\sigma} \\sqrt{\\frac{\\kappa n_{1}}{1+\\kappa}} Œ¥1=Œº1‚àíŒº2\\delta_{1} = \\mu_{1} - \\mu_{2} effect size endpoint 1. binary endpoint (k=2k = 2, method) (Equation 5 Sozu et al., 2012): c2*=(p1+Œ∫p2){(1‚àíp1)+Œ∫(1‚àíp2)}1+Œ∫zŒ±‚àíŒ∫n1(p1‚àíp2)Œ∫p1(1‚àíp1)+p2(1‚àíp2)c_{2}^{*} = \\frac{\\sqrt{\\frac{(p_{1}+\\kappa p_{2})\\{(1-p_{1})+\\kappa(1-p_{2})\\}}{1+\\kappa}} z_{\\alpha} - \\sqrt{\\kappa n_{1}}(p_{1}-p_{2})}{\\sqrt{\\kappa p_{1}(1-p_{1})+p_{2}(1-p_{2})}} vector (Z1*,Z2*)T(Z_{1}^{*}, Z_{2}^{*})^\\text{T} approximately distributed standardized bivariate normal distribution N2(ùüé,Œ≥)\\text{N}_{2}(\\mathbf{0}, \\gamma), Œ≥\\gamma correlation test statistics. Correlation test statistics: mixed continuous binary case, correlation Œ≥\\gamma Z1Z_{1} Z2Z_{2} depends biserial correlation œÅ\\rho outcomes. explicit formula involves standard normal density function success probabilities. See equation (1) Supporting Information Sozu et al.¬†(2012) details: Corr(Xi,j,1,Xi,j,2)=œÅjŒæjpj(1‚àípj)\\text{Corr}(X_{,j,1}, X_{,j,2}) = \\frac{\\rho_{j} \\xi_{j}}{\\sqrt{p_{j}(1-p_{j})}} Œæj=12œÄexp{‚àí(gj‚àíŒºj*)22œÉj2*}\\xi_{j} = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{(g_{j} - \\mu_{j}^{\\ast})^2}{2\\sigma_{j}^{2\\ast}}\\right\\}.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"sample-size-determination","dir":"Articles","previous_headings":"Statistical Framework","what":"Sample Size Determination","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"sample size determined solving power equation numerically. given allocation ratio rr, target power 1‚àíŒ≤1 - \\beta, significance level Œ±\\alpha, find smallest n2n_{2} overall power equals exceeds 1‚àíŒ≤1 - \\beta. Computational approach: Calculate initial sample size based single-endpoint formulas Compute correlation Œ≥\\gamma test statistics using biserial correlation Calculate joint power using bivariate normal distribution Iterate target power achieved Fisher‚Äôs exact test: Fisher‚Äôs exact test, power calculation simulation-based due discrete nature test statistic. sample size calculation uses sequential search starting method‚Äôs sample size initial value.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"replicating-sozu-et-al--2012-table-2","dir":"Articles","previous_headings":"","what":"Replicating Sozu et al.¬†(2012) Table 2","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Table 2 Sozu et al.¬†(2012) shows sample sizes PREMIER study scenario different standard deviations correlations. Table 2: Sample Size per Group (n) PREMIER Study Scenario (delta1 = 4.4, p1 = 0.59, p2 = 0.46, Œ± = 0.025, 1-Œ≤ = 0.80) Interpretation: table shows standard deviation increases, required sample size increases. correlation modest effect sample size reduction (approximately 5-7% reduction œÅ=0.8\\rho = 0.8).","code":"# Recreate Sozu et al. (2012) Table 2 library(dplyr) library(tidyr)  param_grid_mixed_cb_ss <- expand.grid(   delta = 4.4,   sd = c(19, 20, 21, 22),   p1 = 0.59,   p2 = 0.46 )  result_mixed_cb_ss <- design_table(   param_grid = param_grid_mixed_cb_ss,   rho_values = c(0, 0.3, 0.5, 0.8),   r = 1,   alpha = 0.025,   beta = 0.2,   endpoint_type = \"mixed_cont_binary\",   Test = \"AN\" ) %>%    mutate_at(vars(starts_with(\"rho_\")), ~ . / 2)  kable(result_mixed_cb_ss,       caption = \"Table 2: Sample Size per Group (n) for PREMIER Study Scenario (delta1 = 4.4, p1 = 0.59, p2 = 0.46, Œ± = 0.025, 1-Œ≤ = 0.80)\",       digits = 2,       col.names = c(\"delta\", \"œÉ\", \"p1\", \"p2\", \"œÅ=0.0\", \"œÅ=0.3\", \"œÅ=0.5\", \"œÅ=0.8\"))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"replicating-sozu-et-al--2012-supporting-information-table-5","dir":"Articles","previous_headings":"","what":"Replicating Sozu et al.¬†(2012) Supporting Information Table 5","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Table 5 Supporting Information shows sample sizes scenarios higher success probabilities different test methods. Table 5 (Part ): Sample Size per Group (n) Continuity Correction (ANc) (œÉ = 1, Œ± = 0.025, 1-Œ≤ = 0.80)Table 5 (Part B): Sample Size per Group (n) Arcsine Continuity Correction (ASc) (œÉ = 1, Œ± = 0.025, 1-Œ≤ = 0.80)values may differ slightly Supporting Information Table 5 Sozu et al.¬†(2012) due numerical differences computing bivariate normal cumulative distribution function SAS R implementations. Key findings: ANc ASc give similar sample sizes Correlation effect modest scenarios Higher success probabilities (p1p_{1}) generally require larger sample sizes effect size small","code":"# Recreate Supporting Information Table 5 param_grid_mixed_cb_ss2 <- tibble(   delta = c(0.235, 0.397, 0.521, 0.190, 0.335, 0.457),   sd = 1,   p1 = c(rep(0.99, 3), rep(0.95, 3)),   p2 = c(seq(0.95, 0.85, length.out = 3), seq(0.90, 0.80, length.out = 3)) )  result_mixed_cb_ss2 <- do.call(   bind_rows,   lapply(c(\"ANc\", \"ASc\"), function(test) {     design_table(       param_grid = param_grid_mixed_cb_ss2,       rho_values = c(0, 0.3, 0.5, 0.8),       r = 1,       alpha = 0.025,       beta = 0.2,       endpoint_type = \"mixed_cont_binary\",       Test = test     ) %>%        mutate_at(vars(starts_with(\"rho_\")), ~ . / 2) %>%        mutate(Test = test)   }) ) %>%    arrange(desc(p1), delta) %>%    select(delta, sd, p1, p2, Test, everything())  # Display for ANc result_anc <- result_mixed_cb_ss2 %>%    filter(Test == \"ANc\") %>%    select(-Test)  kable(result_anc,       caption = \"Table 5 (Part A): Sample Size per Group (n) with Continuity Correction (ANc) (œÉ = 1, Œ± = 0.025, 1-Œ≤ = 0.80)^a^\",       digits = 3,       col.names = c(\"delta\", \"œÉ\", \"p1\", \"p2\", \"œÅ=0.0\", \"œÅ=0.3\", \"œÅ=0.5\", \"œÅ=0.8\")) # Display for ASc result_asc <- result_mixed_cb_ss2 %>%    filter(Test == \"ASc\") %>%    select(-Test)  kable(result_asc,       caption = \"Table 5 (Part B): Sample Size per Group (n) with Arcsine and Continuity Correction (ASc) (œÉ = 1, Œ± = 0.025, 1-Œ≤ = 0.80)^a^\",       digits = 3,       col.names = c(\"delta\", \"œÉ\", \"p1\", \"p2\", \"œÅ=0.0\", \"œÅ=0.3\", \"œÅ=0.5\", \"œÅ=0.8\"))"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"example-1-balanced-design","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 1: Balanced Design","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Calculate sample size balanced design moderate effect sizes: Note: function, r=n1/n2r = n_{1}/n_{2}. Thus r=1r = 1 corresponds balanced allocation (n1=n2n_{1} = n_{2}), equivalent Œ∫=1\\kappa = 1 Sozu et al.¬†(2012).","code":"# Balanced design: nT = nC (i.e., r = 1, which corresponds to kappa = 1) result_balanced <- ss2MixedContinuousBinary(   delta = 0.5,           # Standardized effect for continuous endpoint   sd = 1,                # Standard deviation   p1 = 0.7,              # Success prob in treatment group   p2 = 0.5,              # Success prob in control group   rho = 0.5,             # Biserial correlation   r = 1,                 # Balanced allocation (r = nT/nC = 1)   alpha = 0.025,   beta = 0.2,   Test = \"AN\" )  print(result_balanced) #>  #> Sample size calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 102 #>              n2 = 102 #>               N = 204 #>           delta = 0.5 #>              sd = 1 #>               p = 0.7, 0.5 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"example-2-effect-of-correlation","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 2: Effect of Correlation","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Demonstrate biserial correlation affects sample size: Effect Biserial Correlation Sample Size  Interpretation: Higher positive correlation reduces required sample size. œÅ=0.8\\rho = 0.8, sample size reduced approximately 5-8% compared œÅ=0\\rho = 0.","code":"# Fixed effect sizes delta <- 0.5 p1 <- 0.7 p2 <- 0.5  # Range of correlations rho_values <- c(0, 0.3, 0.5, 0.8)  ss_by_rho <- sapply(rho_values, function(rho) {   result <- ss2MixedContinuousBinary(     delta = delta,     sd = 1,     p1 = p1,     p2 = p2,     rho = rho,     r = 1,     alpha = 0.025,     beta = 0.2,     Test = \"AN\"   )   result$n2 })  result_df <- data.frame(   rho = rho_values,   n_per_group = ss_by_rho,   N_total = ss_by_rho * 2,   reduction_pct = round((1 - ss_by_rho / ss_by_rho[1]) * 100, 1) )  kable(result_df,       caption = \"Effect of Biserial Correlation on Sample Size\",       col.names = c(\"œÅ\", \"n per group\", \"N total\", \"Reduction (%)\")) # Plot plot(rho_values, ss_by_rho,       type = \"b\", pch = 19,      xlab = \"Biserial Correlation (œÅ)\",       ylab = \"Sample size per group (n)\",      main = \"Effect of Correlation on Sample Size\",      ylim = c(90, max(ss_by_rho) * 1.1)) grid()"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"example-3-comparison-of-test-methods","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 3: Comparison of Test Methods","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Compare different test methods binary endpoint: Comparison Test Methods Binary Endpoint Key findings: (continuity correction): Similar ANc (continuity correction): Slightly larger (~1-5% increase) (arcsine): Smallest sample size ASc (arcsine CC): Similar ANc","code":"# Fixed design parameters delta <- 0.5 p1 <- 0.7 p2 <- 0.5 rho <- 0.5  test_methods <- c(\"AN\", \"ANc\", \"AS\", \"ASc\")  test_comparison <- lapply(test_methods, function(test_method) {   result <- ss2MixedContinuousBinary(     delta = delta,     sd = 1,     p1 = p1,     p2 = p2,     rho = rho,     r = 1,     alpha = 0.025,     beta = 0.2,     Test = test_method   )      data.frame(     Test_method = test_method,     n_per_group = result$n2,     N_total = result$N   ) })  test_comparison_table <- bind_rows(test_comparison)  kable(test_comparison_table,       caption = \"Comparison of Test Methods for Binary Endpoint\",       digits = 0,       col.names = c(\"Test Method\", \"n per group\", \"N total\"))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"example-4-unbalanced-allocation","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 4: Unbalanced Allocation","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Calculate sample size 2:1 allocation ratio: Comparison: Balanced vs Unbalanced Allocation Note: function, r=n1/n2r = n_{1}/n_{2}, r=2r = 2 means n1=2√ón2n_{1} = 2 \\times n_{2}, corresponds Œ∫=n2/n1=0.5\\kappa = n_{2}/n_{1} = 0.5 Sozu et al.¬†(2012) notation.","code":"# Balanced design (r = 1, equivalent to kappa = 1) result_balanced <- ss2MixedContinuousBinary(   delta = 0.5,   sd = 1,   p1 = 0.7,   p2 = 0.5,   rho = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"AN\" )  # Unbalanced design (r = 2, i.e., nT = 2*nC, equivalent to kappa = 0.5) result_unbalanced <- ss2MixedContinuousBinary(   delta = 0.5,   sd = 1,   p1 = 0.7,   p2 = 0.5,   rho = 0.5,   r = 2,   alpha = 0.025,   beta = 0.2,   Test = \"AN\" )  comparison_allocation <- data.frame(   Design = c(\"Balanced (1:1)\", \"Unbalanced (2:1)\"),   n_treatment = c(result_balanced$n1, result_unbalanced$n1),   n_control = c(result_balanced$n2, result_unbalanced$n2),   N_total = c(result_balanced$N, result_unbalanced$N),   kappa = c(1, 0.5) )  kable(comparison_allocation,       caption = \"Comparison: Balanced vs Unbalanced Allocation\",       col.names = c(\"Design\", \"nT\", \"nC\", \"N total\", \"Œ∫\")) cat(\"\\nIncrease in total sample size:\",      round((result_unbalanced$N - result_balanced$N) / result_balanced$N * 100, 1), \"%\\n\") #>  #> Increase in total sample size: 11.8 %"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"power-verification","dir":"Articles","previous_headings":"","what":"Power Verification","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Verify calculated sample sizes achieve target power:","code":"# Use result from Example 1 power_result <- power2MixedContinuousBinary(   n1 = result_balanced$n1,   n2 = result_balanced$n2,   delta = 0.5,   sd = 1,   p1 = 0.7,   p2 = 0.5,   rho = 0.5,   alpha = 0.025,   Test = \"AN\" )  cat(\"Target power: 0.80\\n\") #> Target power: 0.80 cat(\"Achieved power (Continuous endpoint):\", round(as.numeric(power_result$power1), 4), \"\\n\") #> Achieved power (Continuous endpoint): cat(\"Achieved power (Binary endpoint):\", round(as.numeric(power_result$power2), 4), \"\\n\") #> Achieved power (Binary endpoint): cat(\"Achieved power (Co-primary):\", round(as.numeric(power_result$powerCoprimary), 4), \"\\n\") #> Achieved power (Co-primary): 0.8044"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"design-considerations","dir":"Articles","previous_headings":"Practical Recommendations","what":"Design Considerations","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Estimating biserial correlation: Use pilot data historical studies; conservative uncertain. Biserial correlation challenging estimate Pearson correlation. Latent variable assumption: Ensure binary endpoint conceptually underlying continuous scale (e.g., ‚Äúimproved‚Äù means crossing threshold continuous improvement scale). Test method selection: : common, smallest sample size ANc: Adds continuity correction conservatism : Uses arcsine transformation variance stabilization ASc: Combines arcsine transformation continuity correction Fisher: Provides exact inference computationally intensive Balanced allocation: Generally efficient (Œ∫=1\\kappa = 1, .e., r=1r = 1) unless practical constraints require otherwise. Sensitivity analysis: Calculate range plausible correlations effect sizes.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"when-to-use-this-method","dir":"Articles","previous_headings":"Practical Recommendations","what":"When to Use This Method","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Use mixed continuous-binary methods : One endpoint naturally continuous (e.g., change test score) endpoint naturally binary (e.g., clinical response yes/) endpoints clinically meaningful co-primary endpoints Sample sizes moderate large (N>50N > 50)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"challenges-and-considerations","dir":"Articles","previous_headings":"Practical Recommendations","what":"Challenges and Considerations","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Correlation estimation: Biserial correlation involves latent variable harder estimate Pearson correlation Threshold specification: dichotomization threshold affects correlation; ensure ‚Äôs clinically meaningful Asymmetric power: Mixed endpoints often unequal power two endpoints; endpoint lower power dominates sample size Asymptotic approximation: Methods rely asymptotic normality; may accurate small samples (N<50N < 50)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-continuous-binary.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Mixed Continuous and Binary Co-Primary Endpoints","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination clinical trials multiple co-primary endpoints including mixed continuous binary variables. Biometrical Journal, 54(5), 716-729.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"vignette demonstrates sample size calculation power analysis clinical trials two co-primary endpoints: overdispersed count outcome (following negative binomial distribution) continuous outcome (following normal distribution). methodology based Homma Yoshida (2024).","code":"library(twoCoprimary) library(dplyr) library(tidyr) library(knitr)"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"clinical-context","dir":"Articles","previous_headings":"Background","what":"Clinical Context","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"clinical trials treating asthma chronic obstructive pulmonary disease (COPD), regulatory agencies require evaluation : Count endpoint: Number exacerbations follow-period (overdispersed count data) Continuous endpoint: Lung function measure FEV1\\text{FEV}_{1} (forced expiratory volume 1 second)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"why-negative-binomial-distribution","dir":"Articles","previous_headings":"Background","what":"Why Negative Binomial Distribution?","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Count outcomes clinical trials often exhibit overdispersion, variance substantially exceeds mean. Poisson distribution assumes variance = mean, often violated. Negative binomial (NB) distribution accommodates overdispersion: X‚àºNB(Œª,ŒΩ)X \\sim \\text{NB}(\\lambda, \\nu) Mean: E[X]=Œª=r√ót\\text{E}[X] = \\lambda = r \\times t (rate √ó\\times time) Variance: Var[X]=Œª+Œª2/ŒΩ\\text{Var}[X] = \\lambda + \\lambda^{2}/\\nu ŒΩ‚Üí‚àû\\nu \\\\infty: NB‚ÜíPoisson\\text{NB} \\\\text{Poisson} (overdispersion) Small ŒΩ\\nu: High overdispersion (variance ‚â´\\gg mean) Variance--mean ratio (VMR): VMR=Var[X]E[X]=1+ŒªŒΩ\\text{VMR} = \\frac{\\text{Var}[X]}{\\text{E}[X]} = 1 + \\frac{\\lambda}{\\nu} VMR>1\\text{VMR} > 1, data overdispersed NB appropriate Poisson.","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"model-and-assumptions","dir":"Articles","previous_headings":"Statistical Framework","what":"Model and Assumptions","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Consider two-arm superiority trial sample sizes n1n_{1} (treatment) n2n_{2} (control), allocation ratio r=n1/n2r = n_{1}/n_{2}. subject ii group jj (j=1j = 1: treatment, j=2j = 2: control), observe two outcomes: Outcome 1 (Count): Xi,j,1‚àºNB(Œªj,ŒΩ)X_{,j,1} \\sim \\text{NB}(\\lambda_{j}, \\nu) Œªj\\lambda_{j} expected number events group jj, ŒΩ>0\\nu > 0 common dispersion parameter. Outcome 2 (Continuous): Xi,j,2‚àºN(Œºj,œÉ2)X_{,j,2} \\sim \\text{N}(\\mu_{j}, \\sigma^{2}) Œºj\\mu_{j} population mean group jj, œÉ2\\sigma^{2} common variance across groups.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"correlation-structure","dir":"Articles","previous_headings":"Statistical Framework","what":"Correlation Structure","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"correlation count continuous outcomes within subjects measured œÅj\\rho_{j} group jj. correlation must satisfy feasibility constraints based Fr√©chet-Hoeffding copula bounds, depend marginal distributions. Use corrbound2MixedCountContinuous() function check valid correlation bounds given parameters.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"hypothesis-testing","dir":"Articles","previous_headings":"Statistical Framework","what":"Hypothesis Testing","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"test superiority treatment control endpoints. Note: COPD/asthma trials, treatment benefit indicated lower values endpoints (fewer exacerbations, less decline lung function). count endpoint (1): H01:r1‚â•r2 vs. H11:r1<r2\\text{H}_{01}: r_{1} \\geq r_{2} \\text{ vs. } \\text{H}_{11}: r_{1} < r_{2} Equivalently, testing Œ≤1=log(r1)‚àílog(r2)<0\\beta_{1} = \\log(r_{1}) - \\log(r_{2}) < 0. continuous endpoint (2): H02:Œº1‚àíŒº2‚â•0 vs. H12:Œº1‚àíŒº2<0\\text{H}_{02}: \\mu_{1} - \\mu_{2} \\geq 0 \\text{ vs. } \\text{H}_{12}: \\mu_{1} - \\mu_{2} < 0 Co-primary endpoints (intersection-union test): H0=H01‚à™H02 vs. H1=H11‚à©H12\\text{H}_0 = \\text{H}_{01} \\cup \\text{H}_{02} \\text{ vs. } \\text{H}_1 = \\text{H}_{11} \\cap \\text{H}_{12} Reject H0\\text{H}_{0} level Œ±\\alpha H01\\text{H}_{01} H02\\text{H}_{02} rejected level Œ±\\alpha.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"test-statistics","dir":"Articles","previous_headings":"Statistical Framework","what":"Test Statistics","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Count endpoint (Equation 7 Homma Yoshida, 2024): Z1=Œ≤ÃÇ1Var(Œ≤ÃÇ1)Z_{1} = \\frac{\\hat{\\beta}_{1}}{\\sqrt{\\text{Var}(\\hat{\\beta}_{1})}} : Œ≤ÃÇ1=log(X‚Äæ1,1)‚àílog(X‚Äæ2,1)\\hat{\\beta}_{1} = \\log(\\bar{X}_{1,1}) - \\log(\\bar{X}_{2,1}) log rate ratio Var(Œ≤ÃÇ1)=1n2[1t(1Œª2+1rŒª1)+1+rŒΩr]=Van2\\text{Var}(\\hat{\\beta}_{1}) = \\frac{1}{n_{2}}\\left[\\frac{1}{t}\\left(\\frac{1}{\\lambda_{2}} + \\frac{1}{r\\lambda_{1}}\\right) + \\frac{1+r}{\\nu r}\\right] = \\frac{V_{}}{n_{2}} Continuous endpoint: Z2=X‚Äæ1,2‚àíX‚Äæ2,2œÉ1+rrn2Z_{2} = \\frac{\\bar{X}_{1,2} - \\bar{X}_{2,2}}{\\sigma\\sqrt{\\frac{1+r}{r n_{2}}}} œÉ\\sigma common known standard deviation.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"joint-distribution-and-correlation","dir":"Articles","previous_headings":"Statistical Framework","what":"Joint Distribution and Correlation","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"H1\\text{H}_{1}, test statistics (Z1,Z2)(Z_{1}, Z_{2}) asymptotically follow bivariate normal distribution (Appendix B Homma Yoshida, 2024): (Z1Z2)‚àºBN((œâ1œâ2),(1Œ≥Œ≥1))\\begin{pmatrix} Z_1 \\\\ Z_2 \\end{pmatrix} \\sim \\text{BN}\\left(\\begin{pmatrix} \\omega_1 \\\\ \\omega_2 \\end{pmatrix}, \\begin{pmatrix} 1 & \\gamma \\\\ \\gamma & 1 \\end{pmatrix}\\right) : œâ1=n2Œ≤1Va\\omega_{1} = \\frac{\\sqrt{n_{2}}\\beta_{1}}{\\sqrt{V_{}}} Œ≤1=log(r1)‚àílog(r2)\\beta_{1} = \\log(r_{1}) - \\log(r_{2}) œâ2=Œ¥œÉ1+rrn2\\omega_{2} = \\frac{\\delta}{\\sigma\\sqrt{\\frac{1+r}{r n_{2}}}} Œ¥=Œº1‚àíŒº2\\delta = \\mu_{1} - \\mu_{2} Correlation test statistics (Equation 11 Homma Yoshida, 2024): Œ≥=‚àëj=12n2œÅj1+Œªj/ŒΩnjŒªjVa(1+r)/r\\gamma = \\sum_{j=1}^{2} \\frac{n_{2}\\rho_{j}\\sqrt{1+\\lambda_{j}/\\nu}}{n_{j}\\sqrt{\\lambda_{j}V_{}(1+r)/r}} balanced design (r=1r = 1) common correlation (œÅ1=œÅ2=œÅ\\rho_{1} = \\rho_{2} = \\rho): Œ≥=œÅ21/Œª2+1/ŒΩ+1/Œª1+1/ŒΩ(1/Œª2+1/Œª1+2/ŒΩ)\\gamma = \\frac{\\rho}{\\sqrt{2}}\\frac{\\sqrt{1/\\lambda_{2} + 1/\\nu} + \\sqrt{1/\\lambda_{1} + 1/\\nu}}{\\sqrt{(1/\\lambda_{2} + 1/\\lambda_{1} + 2/\\nu)}}","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"power-calculation","dir":"Articles","previous_headings":"Statistical Framework","what":"Power Calculation","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"overall power (Equation 10 Homma Yoshida, 2024): 1‚àíŒ≤=P(Z1<zŒ±‚à©Z2<zŒ±‚à£H1)1 - \\beta = \\text{P}(Z_{1} < z_{\\alpha} \\cap Z_{2} < z_{\\alpha} \\mid \\text{H}_{1}) Using bivariate normal CDF Œ¶2\\Phi_{2}: 1‚àíŒ≤=Œ¶2(zŒ±‚àín2(logr1‚àílogr2)Va,zŒ±‚àín2(Œº1‚àíŒº2)œÉ1+rr|Œ≥)1 - \\beta = \\Phi_{2}\\left(z_{\\alpha} - \\frac{\\sqrt{n_{2}}(\\log r_{1} - \\log r_{2})}{\\sqrt{V_{}}}, z_{\\alpha} - \\frac{\\sqrt{n_{2}}(\\mu_{1}-\\mu_{2})}{\\sigma\\sqrt{\\frac{1+r}{r}}} \\Bigg| \\gamma\\right)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"sample-size-determination","dir":"Articles","previous_headings":"Statistical Framework","what":"Sample Size Determination","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"sample size determined solving power equation numerically. given allocation ratio rr, target power 1‚àíŒ≤1 - \\beta, significance level Œ±\\alpha, find smallest n2n_{2} overall power equals exceeds 1‚àíŒ≤1 - \\beta. Sequential search algorithm: Calculate initial sample size based single-endpoint formulas Compute power current sample size power ‚â•\\geq target: decrease n2n_{2} power << target, add 1 back power << target: increase n2n_{2} power ‚â•\\geq target","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"example-calculate-correlation-bounds","dir":"Articles","previous_headings":"Correlation Bounds","what":"Example: Calculate Correlation Bounds","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Important: Always verify specified correlation œÅ\\rho within feasible bounds parameters.","code":"# Scenario: lambda = 1.25, nu = 0.8, mu = 0, sigma = 250 bounds1 <- corrbound2MixedCountContinuous(lambda = 1.25, nu = 0.8, mu = 0, sd = 250) cat(\"Correlation bounds for NB(1.25, 0.8) and N(0, 250¬≤):\\n\") #> Correlation bounds for NB(1.25, 0.8) and N(0, 250¬≤): cat(\"Lower bound:\", round(bounds1[1], 3), \"\\n\") #> Lower bound: -0.846 cat(\"Upper bound:\", round(bounds1[2], 3), \"\\n\\n\") #> Upper bound: 0.846  # Higher dispersion (smaller nu) typically restricts bounds bounds2 <- corrbound2MixedCountContinuous(lambda = 1.25, nu = 0.5, mu = 0, sd = 250) cat(\"Correlation bounds for NB(1.25, 0.5) and N(0, 250¬≤):\\n\") #> Correlation bounds for NB(1.25, 0.5) and N(0, 250¬≤): cat(\"Lower bound:\", round(bounds2[1], 3), \"\\n\") #> Lower bound: -0.802 cat(\"Upper bound:\", round(bounds2[2], 3), \"\\n\\n\") #> Upper bound: 0.802  # Higher mean count bounds3 <- corrbound2MixedCountContinuous(lambda = 2.0, nu = 0.8, mu = 0, sd = 250) cat(\"Correlation bounds for NB(2.0, 0.8) and N(0, 250¬≤):\\n\") #> Correlation bounds for NB(2.0, 0.8) and N(0, 250¬≤): cat(\"Lower bound:\", round(bounds3[1], 3), \"\\n\") #> Lower bound: -0.863 cat(\"Upper bound:\", round(bounds3[2], 3), \"\\n\") #> Upper bound: 0.863"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"replicating-homma-and-yoshida-2024-table-1-case-b","dir":"Articles","previous_headings":"","what":"Replicating Homma and Yoshida (2024) Table 1 (Case B)","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Table 1 Homma Yoshida (2024) shows sample sizes operating characteristics various scenarios. replicate Case B ŒΩ=3\\nu = 3 ŒΩ=5\\nu = 5. Design parameters Case B: Count rates: r2=1r_{2} = 1, r1=2r_{1} = 2, t=1t = 1 ‚Üí Œª2=1\\lambda_{2} = 1, Œª1=2\\lambda_{1} = 2 Dispersion: ŒΩ=3\\nu = 3 55 Continuous means: Œº2=0\\mu_{2} = 0, Œº1=‚àí50\\mu_{1} = -50 (negative indicates less decline) Standard deviation: œÉ=75\\sigma = 75 Œ±=0.025\\alpha = 0.025 (one-sided), 1‚àíŒ≤=0.91 - \\beta = 0.9 (target power) Balanced allocation: r=1r = 1 (n1=n2n_{1} = n_{2}) Table 1 Case B: Sample Sizes (ŒΩ = 3, Balanced Design, Œ± = 0.025, 1-Œ≤ = 0.9) Table 1 Case B: Sample Sizes (ŒΩ = 5, Balanced Design, Œ± = 0.025, 1-Œ≤ = 0.9) Observations: Higher dispersion parameter ŒΩ\\nu (less overdispersion) requires smaller sample sizes Correlation reduces sample size: approximately 2-4% œÅ=0.4\\rho = 0.4, 5-8% œÅ=0.8\\rho = 0.8 effect correlation moderate compared endpoint combinations","code":"# Define scenarios for Table 1 Case B scenarios_table1_B <- expand.grid(   nu = c(3, 5),   rho = c(0, 0.2, 0.4, 0.6, 0.8),   stringsAsFactors = FALSE )  # Calculate sample sizes for each scenario results_table1_B <- lapply(1:nrow(scenarios_table1_B), function(i) {   nu_val <- scenarios_table1_B$nu[i]   rho_val <- scenarios_table1_B$rho[i]      result <- ss2MixedCountContinuous(     r1 = 1,     r2 = 2,     nu = nu_val,     t = 1,     mu1 = -50,     mu2 = 0,     sd = 75,     r = 1,     rho1 = rho_val,     rho2 = rho_val,     alpha = 0.025,     beta = 0.1   )      data.frame(     nu = nu_val,     rho = rho_val,     n2 = result$n2,     n1 = result$n1,     N = result$N   ) })  table1_B_results <- bind_rows(results_table1_B)  # Display results grouped by nu table1_B_nu3 <- table1_B_results %>%   filter(nu == 3) %>%   select(rho, n2, N)  table1_B_nu5 <- table1_B_results %>%   filter(nu == 5) %>%   select(rho, n2, N)  kable(table1_B_nu3,        caption = \"Table 1 Case B: Sample Sizes (ŒΩ = 3, Balanced Design, Œ± = 0.025, 1-Œ≤ = 0.9)\",       digits = 1,       col.names = c(\"œÅ\", \"n per group\", \"N total\")) kable(table1_B_nu5,        caption = \"Table 1 Case B: Sample Sizes (ŒΩ = 5, Balanced Design, Œ± = 0.025, 1-Œ≤ = 0.9)\",       digits = 1,       col.names = c(\"œÅ\", \"n per group\", \"N total\"))"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"example-1-balanced-design","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 1: Balanced Design","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Calculate sample size balanced design moderate effect sizes:","code":"# Balanced design: n1 = n2 (i.e., r = 1) result_balanced <- ss2MixedCountContinuous(   r1 = 1.0,              # Count rate in treatment group   r2 = 1.25,             # Count rate in control group   nu = 0.8,              # Dispersion parameter   t = 1,                 # Follow-up time   mu1 = -50,             # Mean for treatment (negative = benefit)   mu2 = 0,               # Mean for control   sd = 250,              # Standard deviation   r = 1,                 # Balanced allocation   rho1 = 0.5,            # Correlation in treatment group   rho2 = 0.5,            # Correlation in control group   alpha = 0.025,   beta = 0.2 )  print(result_balanced) #>  #> Sample size calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 705 #>              n2 = 705 #>               N = 1410 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"example-2-effect-of-correlation","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 2: Effect of Correlation","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Demonstrate correlation affects sample size: Effect Correlation Sample Size  Interpretation: Higher positive correlation reduces required sample size. œÅ=0.8\\rho = 0.8, sample size reduced approximately 5-7% compared œÅ=0\\rho = 0.","code":"# Fixed effect sizes r1 <- 1.0 r2 <- 1.25 nu <- 0.8 mu1 <- -50 mu2 <- 0 sd <- 250  # Range of correlations rho_values <- c(0, 0.2, 0.4, 0.6, 0.8)  ss_by_rho <- sapply(rho_values, function(rho) {   result <- ss2MixedCountContinuous(     r1 = r1, r2 = r2, nu = nu, t = 1,     mu1 = mu1, mu2 = mu2, sd = sd,     r = 1,     rho1 = rho, rho2 = rho,     alpha = 0.025,     beta = 0.2   )   result$n2 })  result_df <- data.frame(   rho = rho_values,   n_per_group = ss_by_rho,   N_total = ss_by_rho * 2,   reduction_pct = round((1 - ss_by_rho / ss_by_rho[1]) * 100, 1) )  kable(result_df,       caption = \"Effect of Correlation on Sample Size\",       col.names = c(\"œÅ\", \"n per group\", \"N total\", \"Reduction (%)\")) # Plot plot(rho_values, ss_by_rho,       type = \"b\", pch = 19,      xlab = \"Correlation (œÅ)\",       ylab = \"Sample size per group (n)\",      main = \"Effect of Correlation on Sample Size\",      ylim = c(600, max(ss_by_rho) * 1.1)) grid()"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"example-3-effect-of-dispersion-parameter","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 3: Effect of Dispersion Parameter","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Compare sample sizes different levels overdispersion: Effect Dispersion Parameter Sample Size Key finding: Higher overdispersion (smaller ŒΩ\\nu, larger VMR) requires larger sample sizes.","code":"# Fixed design parameters r1 <- 1.0 r2 <- 1.25 mu1 <- -50 mu2 <- 0 sd <- 250 rho <- 0.5  # Range of dispersion parameters nu_values <- c(0.5, 0.8, 1.0, 2.0, 5.0)  ss_by_nu <- sapply(nu_values, function(nu) {   result <- ss2MixedCountContinuous(     r1 = r1, r2 = r2, nu = nu, t = 1,     mu1 = mu1, mu2 = mu2, sd = sd,     r = 1,     rho1 = rho, rho2 = rho,     alpha = 0.025,     beta = 0.2   )   result$n2 })  result_df_nu <- data.frame(   nu = nu_values,   VMR = round(1 + 1.125/nu_values, 2),  # VMR at lambda = 1.125 (average)   n_per_group = ss_by_nu,   N_total = ss_by_nu * 2 )  kable(result_df_nu,       caption = \"Effect of Dispersion Parameter on Sample Size\",       digits = c(1, 2, 0, 0),       col.names = c(\"ŒΩ\", \"VMR\", \"n per group\", \"N total\"))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"example-4-unbalanced-allocation","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 4: Unbalanced Allocation","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Calculate sample size 2:1 allocation ratio: Comparison: Balanced vs Unbalanced Allocation","code":"# Balanced design (r = 1) result_balanced <- ss2MixedCountContinuous(   r1 = 1.0, r2 = 1.25, nu = 0.8, t = 1,   mu1 = -50, mu2 = 0, sd = 250,   r = 1,   rho1 = 0.5, rho2 = 0.5,   alpha = 0.025,   beta = 0.2 )  # Unbalanced design (r = 2, i.e., n1 = 2*n2) result_unbalanced <- ss2MixedCountContinuous(   r1 = 1.0, r2 = 1.25, nu = 0.8, t = 1,   mu1 = -50, mu2 = 0, sd = 250,   r = 2,   rho1 = 0.5, rho2 = 0.5,   alpha = 0.025,   beta = 0.2 )  comparison_allocation <- data.frame(   Design = c(\"Balanced (1:1)\", \"Unbalanced (2:1)\"),   n_treatment = c(result_balanced$n1, result_unbalanced$n1),   n_control = c(result_balanced$n2, result_unbalanced$n2),   N_total = c(result_balanced$N, result_unbalanced$N) )  kable(comparison_allocation,       caption = \"Comparison: Balanced vs Unbalanced Allocation\",       col.names = c(\"Design\", \"n‚ÇÅ\", \"n‚ÇÇ\", \"N total\")) cat(\"\\nIncrease in total sample size:\",      round((result_unbalanced$N - result_balanced$N) / result_balanced$N * 100, 1), \"%\\n\") #>  #> Increase in total sample size: 11.1 %"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"power-verification","dir":"Articles","previous_headings":"","what":"Power Verification","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Verify calculated sample sizes achieve target power:","code":"# Use result from Example 1 power_result <- power2MixedCountContinuous(   n1 = result_balanced$n1,   n2 = result_balanced$n2,   r1 = 1.0,   r2 = 1.25,   nu = 0.8,   t = 1,   mu1 = -50,   mu2 = 0,   sd = 250,   rho1 = 0.5,   rho2 = 0.5,   alpha = 0.025 )  cat(\"Target power: 0.80\\n\") #> Target power: 0.80 cat(\"Achieved power (Count endpoint):\", round(as.numeric(power_result$power1), 4), \"\\n\") #> Achieved power (Count endpoint): cat(\"Achieved power (Continuous endpoint):\", round(as.numeric(power_result$power2), 4), \"\\n\") #> Achieved power (Continuous endpoint): cat(\"Achieved power (Co-primary):\", round(as.numeric(power_result$powerCoprimary), 4), \"\\n\") #> Achieved power (Co-primary): 0.8003"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"design-considerations","dir":"Articles","previous_headings":"Practical Recommendations","what":"Design Considerations","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Estimating dispersion parameter: Use pilot data historical studies estimate ŒΩ\\nu. Underestimating ŒΩ\\nu (overestimating overdispersion) leads conservative sample sizes. Estimating correlation: Use pilot data; conservative uncertain (œÅ=0\\rho = 0 conservative). Direction benefit: COPD/asthma trials, ensure test directions correct (lower better endpoints). Balanced allocation: Generally efficient (r=1r = 1) unless practical constraints require otherwise. Sensitivity analysis: Calculate sample sizes range plausible ŒΩ\\nu, œÅ\\rho, effect sizes.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"when-to-use-this-method","dir":"Articles","previous_headings":"Practical Recommendations","what":"When to Use This Method","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Use mixed count-continuous methods : One endpoint overdispersed count (exacerbations, events) endpoint continuous (lung function, quality life) endpoints clinically meaningful co-primary endpoints Negative binomial distribution appropriate count data","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"challenges-and-considerations","dir":"Articles","previous_headings":"Practical Recommendations","what":"Challenges and Considerations","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Overdispersion estimation: Requires historical data pilot studies; misspecification affects sample size Correlation estimation: Correlation count continuous outcomes challenging estimate Direction specification: Ensure treatment benefit direction correctly specified endpoints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/mixed-count-continuous.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Mixed Count and Continuous Co-Primary Endpoints","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation clinical trials two co-primary endpoints including overdispersed count continuous outcomes. Pharmaceutical Statistics, 23(1), 46-59.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Overview of Two Co-Primary Endpoints Analysis","text":"twoCoprimary package provides comprehensive tools sample size calculation power analysis clinical trials two co-primary endpoints. package implements methodologies multiple publications supports various endpoint types.","code":"library(twoCoprimary)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"what-are-co-primary-endpoints","dir":"Articles","previous_headings":"","what":"What are Co-Primary Endpoints?","title":"Overview of Two Co-Primary Endpoints Analysis","text":"clinical trials, co-primary endpoints multiple primary endpoints must show statistically significant treatment effects trial considered successful. contrast multiple primary endpoints demonstrating effect one endpoint sufficient.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"statistical-properties","dir":"Articles","previous_headings":"What are Co-Primary Endpoints?","what":"Statistical Properties","title":"Overview of Two Co-Primary Endpoints Analysis","text":"multiplicity adjustment needed Type error control overall Type error rate controlled level Œ±\\alpha without Bonferroni correction overall power joint probability: Power = Pr(Reject H01 Reject H02)\\Pr(\\text{Reject } \\text{H}_{01} \\text{ Reject } \\text{H}_{02}) Accounting correlation endpoints can improve efficiency","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"hypotheses-structure","dir":"Articles","previous_headings":"What are Co-Primary Endpoints?","what":"Hypotheses Structure","title":"Overview of Two Co-Primary Endpoints Analysis","text":"two co-primary endpoints, test: Null hypothesis: H0=H01‚à™H02\\text{H}_{0} = \\text{H}_{01} \\cup \\text{H}_{02} (least one null hypothesis true) Alternative hypothesis: H1=H11‚à©H12\\text{H}_{1} = \\text{H}_{11} \\cap \\text{H}_{12} (alternative hypotheses true) reject H0\\text{H}_{0} H01\\text{H}_{01} H02\\text{H}_{02} rejected level Œ±\\alpha.","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"intersection-union-test-iut","dir":"Articles","previous_headings":"Statistical Framework","what":"Intersection-Union Test (IUT)","title":"Overview of Two Co-Primary Endpoints Analysis","text":"co-primary endpoint framework based intersection-union test principle. Let Z1Z_{1} Z2Z_{2} test statistics endpoints 1 2, respectively. Decision rule: Reject H0\\text{H}_{0} : Z1>z1‚àíŒ± Z2>z1‚àíŒ±Z_{1} > z_{1-\\alpha} \\text{ } Z_{2} > z_{1-\\alpha} z1‚àíŒ±z_{1-\\alpha} (1‚àíŒ±)(1-\\alpha)-th quantile standard normal distribution.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"type-i-error-control","dir":"Articles","previous_headings":"Statistical Framework","what":"Type I Error Control","title":"Overview of Two Co-Primary Endpoints Analysis","text":"overall Type error rate : Œ±overall=Pr(Reject H0‚à£H0 true)\\alpha_{\\text{overall}} = \\Pr(\\text{Reject } \\text{H}_{0} \\mid \\text{H}_{0} \\text{ true}) intersection-union test, automatically controlled level Œ±\\alpha without adjustment: Œ±overall‚â§Œ±\\alpha_{\\text{overall}} \\leq \\alpha rejecting statistics exceed threshold conservative rejecting either statistic exceeds threshold.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"overall-power","dir":"Articles","previous_headings":"Statistical Framework","what":"Overall Power","title":"Overview of Two Co-Primary Endpoints Analysis","text":"alternative hypothesis H1\\text{H}_{1}, overall power : 1‚àíŒ≤=Pr(Z1>z1‚àíŒ± Z2>z1‚àíŒ±‚à£H1)1 - \\beta = \\Pr(Z_{1} > z_{1-\\alpha} \\text{ } Z_{2} > z_{1-\\alpha} \\mid \\text{H}_{1}) (Z1,Z2)(Z_{1}, Z_{2}) follow bivariate normal distribution correlation œÅ\\rho: 1‚àíŒ≤=Œ¶2(‚àíz1‚àíŒ±+œâ1,‚àíz1‚àíŒ±+œâ2‚à£œÅ)1 - \\beta = \\Phi_{2}(-z_{1-\\alpha} + \\omega_{1}, -z_{1-\\alpha} + \\omega_{2} \\mid \\rho) : Œ¶2(‚ãÖ,‚ãÖ‚à£œÅ)\\Phi_{2}(\\cdot, \\cdot \\mid \\rho) bivariate normal cumulative distribution function correlation œÅ\\rho œâ1\\omega_{1} œâ2\\omega_{2} non-centrality parameters H1\\text{H}_{1}","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"impact-of-correlation","dir":"Articles","previous_headings":"Statistical Framework","what":"Impact of Correlation","title":"Overview of Two Co-Primary Endpoints Analysis","text":"correlation œÅ\\rho test statistics affects overall power: Positive correlation (œÅ>0\\rho > 0): Increases power reduces required sample size Zero correlation (œÅ=0\\rho = 0): Test statistics independent Negative correlation (œÅ<0\\rho < 0): Decreases power increases required sample size Key insight: Accounting positive correlation endpoints can lead substantial sample size reductions (typically 5-15% œÅ=0.5\\rho = 0.5-0.8) compared assuming independence.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"supported-endpoint-types","dir":"Articles","previous_headings":"","what":"Supported Endpoint Types","title":"Overview of Two Co-Primary Endpoints Analysis","text":"package supports five combinations co-primary endpoints:","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"two-continuous-endpoints","dir":"Articles","previous_headings":"Supported Endpoint Types","what":"1. Two Continuous Endpoints","title":"Overview of Two Co-Primary Endpoints Analysis","text":"Use case: Trials measuring two continuous outcomes (e.g., systolic diastolic blood pressure) Statistical model: endpoints follow normal distributions Key functions: ss2Continuous(): Sample size calculation power2Continuous(): Power calculation twoCoprimary2Continuous(): Unified interface Reference: Sozu et al.¬†(2011)","code":"# Example: Two continuous endpoints with correlation rho = 0.5 ss2Continuous(   delta1 = 0.5,  # Standardized effect size for endpoint 1   delta2 = 0.5,  # Standardized effect size for endpoint 2   sd1 = 1,       # Standard deviation for endpoint 1   sd2 = 1,       # Standard deviation for endpoint 2   rho = 0.5,     # Correlation between endpoints   r = 1,         # Balanced allocation   alpha = 0.025,   beta = 0.2,   known_var = TRUE ) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 79 #>              n2 = 79 #>               N = 158 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>       known_var = TRUE"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"two-binary-endpoints-asymptotic-approximation","dir":"Articles","previous_headings":"Supported Endpoint Types","what":"2. Two Binary Endpoints (Asymptotic Approximation)","title":"Overview of Two Co-Primary Endpoints Analysis","text":"Use case: Trials two binary outcomes using normal approximation (large sample) Statistical model: Binary endpoints asymptotic normal approximation Key functions: ss2BinaryApprox(): Sample size calculation power2BinaryApprox(): Power calculation twoCoprimary2BinaryApprox(): Unified interface Reference: Sozu et al.¬†(2010) Supported test methods: : Asymptotic normal test without continuity correction ANc: Asymptotic normal test continuity correction : Arcsine transformation without continuity correction ASc: Arcsine transformation continuity correction use: Large sample sizes (typically N>200N > 200) probabilities extreme (0.1<p<0.90.1 < p < 0.9)","code":"# Example: Two binary endpoints ss2BinaryApprox(   p11 = 0.7, p12 = 0.6,  # Endpoint 1 and 2 in treatment group   p21 = 0.4, p22 = 0.3,  # Endpoint 1 and 2 in control group   rho1 = 0.5,            # Correlation in treatment group   rho2 = 0.5,            # Correlation in control group   r = 1,                 # Balanced allocation   alpha = 0.025,   beta = 0.2,   Test = \"AN\" ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 52 #>              n2 = 52 #>               N = 104 #>     p (group 1) = 0.7, 0.6 #>     p (group 2) = 0.4, 0.3 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"two-binary-endpoints-exact-methods","dir":"Articles","previous_headings":"Supported Endpoint Types","what":"3. Two Binary Endpoints (Exact Methods)","title":"Overview of Two Co-Primary Endpoints Analysis","text":"Use case: Small medium sample sizes requiring exact inference Statistical model: Binary endpoints exact tests Key functions: ss2BinaryExact(): Sample size calculation using exact tests power2BinaryExact(): Exact power calculation twoCoprimary2BinaryExact(): Unified interface Reference: Homma Yoshida (2025) Supported tests: Chisq: Chi-squared test Fisher: Fisher‚Äôs exact test (conditional test) Fisher-midP: Fisher‚Äôs mid-p test Z-pool: Z-pooled exact unconditional test Boschloo: Boschloo‚Äôs exact unconditional test use: Small/medium samples (N<200N < 200), extreme probabilities (p<0.1p < 0.1 p>0.9p > 0.9), strict Type error control required","code":"# Example: Exact methods for small samples ss2BinaryExact(   p11 = 0.7, p12 = 0.6,   p21 = 0.4, p22 = 0.3,   rho1 = 0.5, rho2 = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"Fisher\"  # or \"Chisq\", \"Fisher-midP\", \"Z-pool\", \"Boschloo\" ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 59 #>              n2 = 59 #>               N = 118 #>     p (group 1) = 0.7, 0.6 #>     p (group 2) = 0.4, 0.3 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = Fisher"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"mixed-continuous-and-binary-endpoints","dir":"Articles","previous_headings":"Supported Endpoint Types","what":"4. Mixed Continuous and Binary Endpoints","title":"Overview of Two Co-Primary Endpoints Analysis","text":"Use case: Trials one continuous one binary outcome Statistical model: Normal distribution continuous endpoint, Bernoulli binary endpoint, biserial correlation Key functions: ss2MixedContinuousBinary(): Sample size calculation power2MixedContinuousBinary(): Power calculation twoCoprimary2MixedContinuousBinary(): Unified interface Reference: Sozu et al.¬†(2012) Supported test methods binary endpoint: : Asymptotic normal test without continuity correction ANc: Asymptotic normal test continuity correction : Arcsine transformation without continuity correction ASc: Arcsine transformation continuity correction Fisher: Fisher‚Äôs exact test (simulation-based) Correlation structure: Uses biserial correlation observed continuous variable latent continuous variable underlying binary outcome","code":"# Example: Continuous + Binary endpoints ss2MixedContinuousBinary(   delta = 0.5,           # Effect size for continuous endpoint   sd = 1,                # Standard deviation   p1 = 0.7,              # Success probability in treatment group   p2 = 0.4,              # Success probability in control group   rho = 0.5,             # Biserial correlation   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"AN\" ) #>  #> Sample size calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 68 #>              n2 = 68 #>               N = 136 #>           delta = 0.5 #>              sd = 1 #>               p = 0.7, 0.4 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"mixed-count-and-continuous-endpoints","dir":"Articles","previous_headings":"Supported Endpoint Types","what":"5. Mixed Count and Continuous Endpoints","title":"Overview of Two Co-Primary Endpoints Analysis","text":"Use case: Trials overdispersed count data (e.g., exacerbations) continuous outcomes (e.g., lung function) Statistical model: Negative binomial distribution count endpoint, normal distribution continuous endpoint Key functions: ss2MixedCountContinuous(): Sample size calculation power2MixedCountContinuous(): Power calculation twoCoprimary2MixedCountContinuous(): Unified interface corrbound2MixedCountContinuous(): Calculate valid correlation bounds Reference: Homma Yoshida (2024) Special considerations: negative binomial distribution accommodates overdispersion (variance >> mean) common count data Treatment effects must negative direction endpoints: Lower event rate (count endpoint) lower/better continuous values indicate treatment benefit. example, reduction exacerbation rate (r1 < r2) improvement lung function (e.g., mu1 < mu2 lower better, larger negative change baseline)","code":"# Example: Count (exacerbations) + Continuous (FEV1) ss2MixedCountContinuous(   r1 = 1.0, r2 = 1.25,   # Count rates (events per unit time)   nu = 0.8,              # Dispersion parameter   t = 1,                 # Follow-up time   mu1 = -50, mu2 = 0,    # Continuous means   sd = 250,              # Standard deviation   rho1 = 0.5, rho2 = 0.5, # Correlations   r = 1,   alpha = 0.025,   beta = 0.2 ) #>  #> Sample size calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 705 #>              n2 = 705 #>               N = 1410 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"impact-of-correlation-1","dir":"Articles","previous_headings":"","what":"Impact of Correlation","title":"Overview of Two Co-Primary Endpoints Analysis","text":"key advantage accounting correlation co-primary endpoints potential sample size reduction. table illustrates two continuous endpoints: correlation increases, required sample size decreases. œÅ=0.8\\rho = 0.8, approximately 11% reduction sample size can achieved compared œÅ=0\\rho = 0.","code":"# Sample size at different correlation levels correlations <- c(0, 0.3, 0.5, 0.8) results <- sapply(correlations, function(rho) {   ss2Continuous(     delta1 = 0.5, delta2 = 0.5,     sd1 = 1, sd2 = 1,     rho = rho, r = 1,     alpha = 0.025, beta = 0.2,     known_var = TRUE   )$N })  data.frame(   Correlation = correlations,   Total_N = results,   Reduction = paste0(round((1 - results/results[1]) * 100, 1), \"%\") ) #>   Correlation Total_N Reduction #> 1         0.0     166        0% #> 2         0.3     162      2.4% #> 3         0.5     158      4.8% #> 4         0.8     148     10.8%"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"why-does-correlation-matter","dir":"Articles","previous_headings":"Impact of Correlation","what":"Why Does Correlation Matter?","title":"Overview of Two Co-Primary Endpoints Analysis","text":"correlation endpoints affects joint distribution test statistics. endpoints positively correlated: Test statistics tend move together: Z1Z_{1} large, Z2Z_{2} also likely large Higher probability rejecting nulls: Pr(Z1>c,Z2>c)\\Pr(Z_{1} > c, Z_{2} > c) increases œÅ\\rho Sample size reduction: Fewer subjects needed achieve target power Mathematically, bivariate normal (Z1,Z2)(Z_{1}, Z_{2}) correlation œÅ\\rho: Pr(Z1>c,Z2>c‚à£œÅ)>Pr(Z1>c,Z2>c‚à£œÅ=0)\\Pr(Z_{1} > c, Z_{2} > c \\mid \\rho) > \\Pr(Z_{1} > c, Z_{2} > c \\mid \\rho = 0) œÅ>0\\rho > 0 endpoints positive treatment effects.","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"decision-guidelines","dir":"Articles","previous_headings":"Choosing the Right Method","what":"Decision Guidelines","title":"Overview of Two Co-Primary Endpoints Analysis","text":"binary endpoints: Use asymptotic methods : N>200N > 200, 0.1<p<0.90.1 < p < 0.9, computational efficiency important Use exact methods : N<200N < 200, extreme probabilities (p<0.1p < 0.1 p>0.9p > 0.9), regulatory requirements exact tests mixed endpoint types: Ensure correlation structure appropriate (e.g., biserial continuous-binary) Consider clinical plausibility correlation magnitude Use conservative estimates correlation uncertain","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"sample-size-calculation-approach","dir":"Articles","previous_headings":"","what":"Sample Size Calculation Approach","title":"Overview of Two Co-Primary Endpoints Analysis","text":"methods package follow similar computational approach: Specify design parameters: Effect sizes, probabilities, standard deviations, etc. Specify correlation: endpoints Specify error rates: Type error Œ±\\alpha (typically 0.025 one-sided) Type II error Œ≤\\beta (typically 0.2 80% power) Calculate sample size: Using iterative algorithms Verify power: Confirm calculated sample size achieves target power","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"detailed-vignettes","dir":"Articles","previous_headings":"","what":"Detailed Vignettes","title":"Overview of Two Co-Primary Endpoints Analysis","text":"detailed methodology, examples, validation published results, please see: vignette(\"two-continuous-endpoints\"): Two continuous endpoints vignette(\"two-binary-endpoints-approx\"): Two binary endpoints (asymptotic) vignette(\"two-binary-endpoints-exact\"): Two binary endpoints (exact) vignette(\"mixed-continuous-binary\"): Mixed continuous binary vignette(\"mixed-count-continuous\"): Mixed count continuous","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/overview.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Overview of Two Co-Primary Endpoints Analysis","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation clinical trials two co-primary endpoints including overdispersed count continuous outcomes. Pharmaceutical Statistics, 23(1), 46-59. Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19. Sozu, T., Sugimoto, T., & Hamasaki, T. (2010). Sample size determination clinical trials multiple co-primary binary endpoints. Statistics Medicine, 29(21), 2169-2179. Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination superiority clinical trials multiple co-primary correlated endpoints. Journal Biopharmaceutical Statistics, 21(4), 650-668. Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination clinical trials multiple co-primary endpoints including mixed continuous binary variables. Biometrical Journal, 54(5), 716-729.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"vignette demonstrates sample size calculation clinical trials two co-primary binary endpoints using asymptotic normal approximation methods. methodology based Sozu et al.¬†(2010).","code":"library(twoCoprimary) library(dplyr) library(tidyr) library(knitr)"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"clinical-context","dir":"Articles","previous_headings":"Background","what":"Clinical Context","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Binary co-primary endpoints common : Migraine trials: Relief headache (yes/) + Relief bothersome migraine-related symptom (yes/) Psoriasis trials: least 75% improvement score psoriasis area--severity index (PASI) (yes/) + Score physician‚Äôs global assessment 0 1 (yes/) Primary myelofibrosis trials: Clinically relevant complete haematological response (yes/) + Lack progression clinical symptoms (yes/)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"when-to-use-asymptotic-methods","dir":"Articles","previous_headings":"Background","what":"When to Use Asymptotic Methods","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Asymptotic (normal approximation) methods appropriate : Sample sizes large (typically N>200N > 200) Probabilities extreme (0.10<p<0.900.10 < p < 0.90) Computational efficiency important small medium sample sizes extreme probabilities, use exact methods based Homma Yoshida (2025), can computed using exact approaches without approximations (see vignette(\"two-binary-endpoints-exact\")).","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"model-and-assumptions","dir":"Articles","previous_headings":"Statistical Framework","what":"Model and Assumptions","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Consider two-arm parallel-group superiority trial comparing treatment (group 1) control (group 2). Let n1n_{1} n2n_{2} denote sample sizes two groups, allocation ratio r=n1/n2r = n_{1}/n_{2} (.e., total sample size N=n1+n2N=n_{1}+n_{2}). subject ii (=1,‚Ä¶,nji = 1, \\ldots, n_j) group jj (j=1j = 1: treatment, j=2j = 2: control), observe two binary outcomes: Xi,j,k‚àà{0,1},k=1,2X_{,j,k} \\\\{0, 1\\}, \\quad k = 1, 2 Xi,j,k=1X_{,j,k} = 1 indicates success Xi,j,k=0X_{,j,k} = 0 indicates failure outcome kk. Marginal probabilities: Let pj,kp_{j,k} denote success probability outcome kk group jj: pj,k=P(Xi,j,k=1),k=1,2p_{j,k} = \\text{P}(X_{,j,k} = 1), \\quad k = 1, 2 details joint distribution (Xi,j,1,Xi,j,2)(X_{,j,1}, X_{,j,2}), see Homma Yoshida (2025) Section 2.1 Sozu et al.¬†(2010).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"correlation-structure","dir":"Articles","previous_headings":"Statistical Framework","what":"Correlation Structure","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"correlation œÅj\\rho_{j} two binary outcomes group jj defined (Homma Yoshida, 2025): œÅj=Cor(Xi,j,1,Xi,j,2)=œïj‚àípj,1pj,2pj,1(1‚àípj,1)pj,2(1‚àípj,2)\\rho_j = \\text{Cor}(X_{,j,1}, X_{,j,2}) = \\frac{\\phi_j - p_{j,1}p_{j,2}}{\\sqrt{p_{j,1}(1-p_{j,1})p_{j,2}(1-p_{j,2})}} œïj=P(Xi,j,1=1,Xi,j,2=1)\\phi_j = \\text{P}(X_{,j,1} = 1, X_{,j,2} = 1) joint probability outcomes successful. Practical interpretation: œÅj>0\\rho_{j} > 0 means subjects succeed outcome 1 likely succeed outcome 2. Valid correlation range: 0<pj,k<10 < p_{j,k} < 1, correlation œÅj\\rho_{j} free range [‚àí1,1][-1, 1], bounded (Homma Yoshida, 2025, Equation 2): œÅj‚àà[L(pj,1,pj,2),U(pj,1,pj,2)]‚äÜ[‚àí1,1]\\rho_j \\[L(p_{j,1}, p_{j,2}), U(p_{j,1}, p_{j,2})] \\subseteq [-1, 1] : L(pj,1,pj,2)=max{‚àípj,1pj,2(1‚àípj,1)(1‚àípj,2),‚àí(1‚àípj,1)(1‚àípj,2)pj,1pj,2}L(p_{j,1}, p_{j,2}) = \\max\\left\\{-\\sqrt{\\frac{p_{j,1}p_{j,2}}{(1-p_{j,1})(1-p_{j,2})}}, -\\sqrt{\\frac{(1-p_{j,1})(1-p_{j,2})}{p_{j,1}p_{j,2}}}\\right\\} U(pj,1,pj,2)=min{pj,1(1‚àípj,2)pj,2(1‚àípj,1),pj,2(1‚àípj,1)pj,1(1‚àípj,2)}U(p_{j,1}, p_{j,2}) = \\min\\left\\{\\sqrt{\\frac{p_{j,1}(1-p_{j,2})}{p_{j,2}(1-p_{j,1})}}, \\sqrt{\\frac{p_{j,2}(1-p_{j,1})}{p_{j,1}(1-p_{j,2})}}\\right\\} pj,1=pj,2p_{j,1} = p_{j,2}, U(pj,1,pj,2)=1U(p_{j,1}, p_{j,2}) = 1, whereas L(pj,1,pj,2)=‚àí1L(p_{j,1}, p_{j,2}) = -1 pj,1+pj,2=1p_{j,1} + p_{j,2} = 1. bounds can computed using corrbound2Binary() function package.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"hypothesis-testing","dir":"Articles","previous_headings":"Statistical Framework","what":"Hypothesis Testing","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"test superiority treatment control endpoints. endpoints testing risk differences: endpoint kk: H0k:p1,k‚àíp2,k‚â§0 vs. H1k:p1,k‚àíp2,k>0\\text{H}_{0k}: p_{1,k} - p_{2,k} \\leq 0 \\text{ vs. } \\text{H}_{1k}: p_{1,k} - p_{2,k} > 0 co-primary endpoints (intersection-union test): Null hypothesis: H0=H01‚à™H02\\text{H}_{0} = \\text{H}_{01} \\cup \\text{H}_{02} (least one null true) Alternative hypothesis: H1=H11‚à©H12\\text{H}_{1} = \\text{H}_{11} \\cap \\text{H}_{12} (alternatives true) Decision rule: Reject H0\\text{H}_{0} level Œ±\\alpha H01\\text{H}_{01} H02\\text{H}_{02} rejected level Œ±\\alpha.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"test-statistics","dir":"Articles","previous_headings":"Statistical Framework","what":"Test Statistics","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Several test statistics available binary endpoints. focus asymptotic normal approximation methods following Sozu et al.¬†(2010).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"method-1-standard-normal-approximation-an","dir":"Articles","previous_headings":"Statistical Framework > Test Statistics","what":"Method 1: Standard Normal Approximation (AN)","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"endpoint k, test statistic without continuity correction (Equation 3 Sozu et al., 2010): Zk=pÃÇ1,k‚àípÃÇ2,ksek0Z_k = \\frac{\\hat{p}_{1,k} - \\hat{p}_{2,k}}{se_{k0}} : sek0=(1n1+1n2)p‚Äæk(1‚àíp‚Äæk)se_{k0} = \\sqrt{\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right) \\bar{p}_k(1 - \\bar{p}_k)} p‚Äæk=n1pÃÇ1,k+n2pÃÇ2,kn1+n2\\bar{p}_k = \\frac{n_1 \\hat{p}_{1,k} + n_2 \\hat{p}_{2,k}}{n_1 + n_2} pooled proportion null hypothesis. H0k\\text{H}_{0k}, ZkZ_{k} asymptotically follows N(0,1)\\text{N}(0, 1). Power formula (Equation 4 Sozu et al., 2010): H1k\\text{H}_{1k} true probabilities p1,kp_{1,k} p2,kp_{2,k}, power single endpoint : Powerk=Œ¶(Œ¥k‚àísek0z1‚àíŒ±sek)\\text{Power}_k = \\Phi\\left(\\frac{\\delta_k - se_{k0} z_{1-\\alpha}}{se_k}\\right) : Œ¥k=p1,k‚àíp2,k\\delta_k = p_{1,k} - p_{2,k} true risk difference sek=v1,kn1+v2,kn2se_k = \\sqrt{\\frac{v_{1,k}}{n_1} + \\frac{v_{2,k}}{n_2}} vj,k=pj,k(1‚àípj,k)v_{j,k} = p_{j,k}(1 - p_{j,k}) z1‚àíŒ±z_{1-\\alpha} (1‚àíŒ±)(1-\\alpha) quantile standard normal distribution","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"method-2-normal-approximation-with-continuity-correction-anc","dir":"Articles","previous_headings":"Statistical Framework > Test Statistics","what":"Method 2: Normal Approximation with Continuity Correction (ANc)","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"improve finite-sample performance, Yates‚Äôs continuity correction applied (Equation 5 Sozu et al., 2010): Zk=pÃÇ1,k‚àípÃÇ2,k‚àícsek0Z_k = \\frac{\\hat{p}_{1,k} - \\hat{p}_{2,k} - c}{se_{k0}} : c=12(1n1+1n2)c = \\frac{1}{2}\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right) Power formula: Powerk=Œ¶(Œ¥k‚àísek0z1‚àíŒ±‚àícsek)\\text{Power}_k = \\Phi\\left(\\frac{\\delta_k - se_{k0} z_{1-\\alpha} - c}{se_k}\\right)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"method-3-arcsine-transformation-as","dir":"Articles","previous_headings":"Statistical Framework > Test Statistics","what":"Method 3: Arcsine Transformation (AS)","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"arcsine-square-root transformation stabilizes variance (Equation 6 Sozu et al., 2010): Zk=arcsin(pÃÇ1,k)‚àíarcsin(pÃÇ2,k)seZ_k = \\frac{\\arcsin(\\sqrt{\\hat{p}_{1,k}}) - \\arcsin(\\sqrt{\\hat{p}_{2,k}})}{se} : se=121n1+1n2se = \\frac{1}{2}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} Power formula: Let Œ¥kAS=arcsin(p1k)‚àíarcsin(p2k)\\delta_k^\\text{} = \\arcsin(\\sqrt{p_{1k}}) - \\arcsin(\\sqrt{p_{2k}}), : Powerk=Œ¶(Œ¥kASse‚àíz1‚àíŒ±)\\text{Power}_k = \\Phi\\left(\\frac{\\delta_k^\\text{}}{se} - z_{1-\\alpha}\\right)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"method-4-arcsine-transformation-with-continuity-correction-asc","dir":"Articles","previous_headings":"Statistical Framework > Test Statistics","what":"Method 4: Arcsine Transformation with Continuity Correction (ASc)","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Walters‚Äô continuity correction arcsine method (Equation 7 Sozu et al., 2010): Zk=arcsin(pÃÇ1,k+c1)‚àíarcsin(pÃÇ2,k+c2)seZ_k = \\frac{\\arcsin(\\sqrt{\\hat{p}_{1,k} + c_1}) - \\arcsin(\\sqrt{\\hat{p}_{2,k} + c_2})}{se} : c1=‚àí12n1,c2=12n2c_1 = -\\frac{1}{2n_1}, \\quad c_2 = \\frac{1}{2n_2} se=121n1+1n2se = \\frac{1}{2}\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} Power formula: Let: Œ¥kASc=arcsin(p1,k+c1)‚àíarcsin(p2,k+c2)\\delta_k^{ASc} = \\arcsin(\\sqrt{p_{1,k} + c_1}) - \\arcsin(\\sqrt{p_{2,k} + c_2}) vj,kc=(pj,k+cj)(1‚àípj,k‚àícj)v_{j,k}^c = (p_{j,k} + c_j)(1 - p_{j,k} - c_j) sek=v1,k4n1v1,kc+v2,k4n2v2,kcse_k = \\sqrt{\\frac{v_{1,k}}{4n_1 v_{1,k}^c} + \\frac{v_{2,k}}{4n_2 v_{2,k}^c}} : Powerk=Œ¶(Œ¥kASc‚àíse‚ãÖz1‚àíŒ±sek)\\text{Power}_k = \\Phi\\left(\\frac{\\delta_k^{ASc} - se \\cdot z_{1-\\alpha}}{se_k}\\right)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"joint-distribution-and-correlation","dir":"Articles","previous_headings":"Statistical Framework","what":"Joint Distribution and Correlation","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"H1\\text{H}_{1}, (Z1,Z2)(Z_{1}, Z_{2}) asymptotically follows bivariate normal distribution: (Z1Z2)‚àºBN((œâ1œâ2),(1Œ≥Œ≥1))\\begin{pmatrix} Z_1 \\\\ Z_2 \\end{pmatrix} \\sim \\text{BN}\\left(\\begin{pmatrix} \\omega_1 \\\\ \\omega_2 \\end{pmatrix}, \\begin{pmatrix} 1 & \\gamma \\\\ \\gamma & 1 \\end{pmatrix}\\right) correlation Œ≥\\gamma test statistics depends œÅ1\\rho_{1}, œÅ2\\rho_{2}, marginal probabilities. details derivation approximation formulas, see Sozu et al.¬†(2010) Homma Yoshida (2025). approximation implemented package functions.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"power-calculation","dir":"Articles","previous_headings":"Statistical Framework","what":"Power Calculation","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"overall power (probability rejecting null hypotheses) : 1‚àíŒ≤=P(Z1>z1‚àíŒ± Z2>z1‚àíŒ±‚à£H1)1 - \\beta = \\text{P}(Z_1 > z_{1-\\alpha} \\text{ } Z_2 > z_{1-\\alpha} \\mid \\text{H}_1) Using bivariate normal distribution: 1‚àíŒ≤=Œ¶2(‚àíz1‚àíŒ±+œâ1,‚àíz1‚àíŒ±+œâ2‚à£Œ≥)1 - \\beta = \\Phi_2(-z_{1-\\alpha} + \\omega_1, -z_{1-\\alpha} + \\omega_2 \\mid \\gamma) Œ¶2(,b‚à£Œ≥)\\Phi_{2}(, b \\mid \\gamma) CDF standard bivariate normal distribution correlation Œ≥\\gamma.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"sample-size-calculation","dir":"Articles","previous_headings":"Statistical Framework","what":"Sample Size Calculation","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"target power 1‚àíŒ≤1 - \\beta balanced design (n1=n2=nn_{1} = n_{2} = n), solve power formula shown numerically n2n_{2}. , total sample size obtained N=(1+r)n2N = (1+r)n_{2}.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"replicating-sozu-et-al--2010-table-iii","dir":"Articles","previous_headings":"","what":"Replicating Sozu et al.¬†(2010) Table III","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Table III Sozu et al.¬†(2010) shows sample sizes various probability combinations correlations using , ANc, , ASc test methods. Note exact methods based Fisher‚Äôs exact test (Homma Yoshida, 2025) can provide accurate sample sizes small medium sample sizes, included table available Sozu et al.¬†(2010). notation used function : p11 = p1,1p_{1,1}, p12 = p1,2p_{1,2}, p21 = p2,1p_{2,1}, p22 = p2,2p_{2,2}, first subscript denotes group (1 = treatment, 2 = control) second subscript denotes endpoint (1 2). Table III: Sample Size per Group (n) Two Co-Primary Binary Endpoints (Œ± = 0.025, 1-Œ≤ = 0.80),b : Asymptotic normal test without continuity correction; ANc: Asymptotic normal test continuity correction; : Arcsine transformation without continuity correction; ASc: Arcsine transformation continuity correction. b values may differ 1-2 subjects Sozu et al.¬†(2010) Table III due numerical differences computing bivariate normal cumulative distribution function SAS R implementations. Power calculations reported sample sizes confirm accuracy values presented .","code":"# Recreate Sozu et al. (2010) Table III library(dplyr) library(tidyr) library(readr)  param_grid_bin_ss <- tibble(   p11 = c(0.70, 0.87, 0.90, 0.95),    p12 = c(0.70, 0.70, 0.90, 0.95),   p21 = c(0.50, 0.70, 0.70, 0.90),   p22 = c(0.50, 0.50, 0.70, 0.90) )  result_bin_ss <- do.call(   bind_rows,   lapply(c(\"AN\", \"ANc\", \"AS\", \"ASc\"), function(test) {     do.call(       bind_rows,       design_table(         param_grid = param_grid_bin_ss,         rho_values = c(-0.3, 0, 0.3, 0.5, 0.8),         r = 1,         alpha = 0.025,         beta = 0.2,         endpoint_type = \"binary\",         Test = test       ) %>%          mutate(Test = test)     )   }) ) %>%    mutate_at(vars(starts_with(\"rho_\")), ~ . / 2) %>%    pivot_longer(     cols = starts_with(\"rho_\"),     names_to = \"rho\",     values_to = \"N\",     names_transform = list(rho = parse_number)   ) %>%    pivot_wider(names_from = Test,  values_from = N) %>%    drop_na(AN, ANc, AS, ASc) %>%    as.data.frame()  kable(result_bin_ss,       caption = \"Table III: Sample Size per Group (n) for Two Co-Primary Binary Endpoints (Œ± = 0.025, 1-Œ≤ = 0.80)^a,b^\",       digits = 0,       col.names = c(\"p‚ÇÅ,‚ÇÅ\", \"p‚ÇÅ,‚ÇÇ\", \"p‚ÇÇ,‚ÇÅ\", \"p‚ÇÇ,‚ÇÇ\", \"œÅ\", \"AN\", \"ANc\", \"AS\", \"ASc\"))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"key-findings","dir":"Articles","previous_headings":"Replicating Sozu et al.¬†(2010) Table III","what":"Key Findings","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Effect correlation: Positive correlation (œÅ>0\\rho > 0) reduces required sample size Negative correlation (œÅ<0\\rho < 0) increases required sample size Zero correlation (œÅ=0\\rho = 0) provides intermediate sample size Test method comparison: : Generally smallest sample size, efficient ANc: Slightly larger due continuity correction : Similar moderate probabilities ASc: Largest sample size, conservative","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"example-1-equal-effect-sizes","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 1: Equal Effect Sizes","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Calculate sample size endpoints equal effect sizes: Note: function, p11 corresponds p1,1p_{1,1} (success probability endpoint 1 treatment group), p12 p1,2p_{1,2}, p21 p2,1p_{2,1}, p22 p2,2p_{2,2}.","code":"# Both endpoints: 70% vs 50% (20% difference) # p_{1,1} = p_{1,2} = 0.7 (treatment group) # p_{2,1} = p_{2,2} = 0.5 (control group) ss_equal <- ss2BinaryApprox(   p11 = 0.7, p12 = 0.7,  # Treatment group   p21 = 0.5, p22 = 0.5,  # Control group   rho1 = 0.5,            # Correlation in treatment group   rho2 = 0.5,            # Correlation in control group   r = 1,                 # Balanced allocation   alpha = 0.025,   beta = 0.2,   Test = \"AN\" )  print(ss_equal) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 116 #>              n2 = 116 #>               N = 232 #>     p (group 1) = 0.7, 0.7 #>     p (group 2) = 0.5, 0.5 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"example-2-unequal-effect-sizes","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 2: Unequal Effect Sizes","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"effect sizes differ, endpoint smaller effect dominates: co-primary design requires approximately sample size endpoint smaller effect size.","code":"# Endpoint 1: 75% vs 65% (10% difference) # Endpoint 2: 80% vs 60% (20% difference) ss_unequal <- ss2BinaryApprox(   p11 = 0.75, p12 = 0.80,   p21 = 0.65, p22 = 0.60,   rho1 = 0.3, rho2 = 0.3,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"AN\" )  print(ss_unequal) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 329 #>              n2 = 329 #>               N = 658 #>     p (group 1) = 0.75, 0.8 #>     p (group 2) = 0.65, 0.6 #>             rho = 0.3, 0.3 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN  # Compare with individual endpoint sample sizes ss_ep1 <- ss1BinaryApprox(p1 = 0.75, p2 = 0.65, r = 1,                            alpha = 0.025, beta = 0.2, Test = \"AN\") ss_ep2 <- ss1BinaryApprox(p1 = 0.80, p2 = 0.60, r = 1,                           alpha = 0.025, beta = 0.2, Test = \"AN\")  cat(\"Single endpoint 1 sample size:\", ss_ep1$n2, \"\\n\") #> Single endpoint 1 sample size: 329 cat(\"Single endpoint 2 sample size:\", ss_ep2$n2, \"\\n\") #> Single endpoint 2 sample size: 82 cat(\"Co-primary sample size:\", ss_unequal$n2, \"\\n\") #> Co-primary sample size: 329"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"example-3-effect-of-correlation","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 3: Effect of Correlation","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Demonstrate correlation affects sample size: Sample Size vs Correlation (p‚ÇÅ,‚ÇÅ = p‚ÇÅ,‚ÇÇ = 0.7, p‚ÇÇ,‚ÇÅ = p‚ÇÇ,‚ÇÇ = 0.5)  Interpretation: Higher positive correlation substantially reduces required sample size.","code":"# Fixed effect sizes: p_{1,1} = p_{1,2} = 0.7, p_{2,1} = p_{2,2} = 0.5 p11 <- 0.7 p21 <- 0.5 p12 <- 0.7 p22 <- 0.5  # Range of correlations rho_values <- c(-0.3, 0, 0.3, 0.5, 0.8)  ss_by_rho <- sapply(rho_values, function(rho) {   ss <- ss2BinaryApprox(     p11 = p11, p12 = p12,     p21 = p21, p22 = p22,     rho1 = rho, rho2 = rho,     r = 1,     alpha = 0.025,     beta = 0.2,     Test = \"AN\"   )   ss$n2 })  result_df <- data.frame(   rho = rho_values,   n_per_group = ss_by_rho,   N_total = ss_by_rho * 2 )  kable(result_df,       caption = \"Sample Size vs Correlation (p‚ÇÅ,‚ÇÅ = p‚ÇÅ,‚ÇÇ = 0.7, p‚ÇÇ,‚ÇÅ = p‚ÇÇ,‚ÇÇ = 0.5)\",       col.names = c(\"œÅ\", \"n per group\", \"N total\")) # Plot plot(rho_values, ss_by_rho,       type = \"b\", pch = 19,      xlab = \"Correlation (œÅ)\",       ylab = \"Sample size per group (n)\",      main = \"Effect of Correlation on Sample Size\",      ylim = c(min(ss_by_rho) * 0.9, max(ss_by_rho) * 1.1)) grid()"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"example-4-unbalanced-allocation","dir":"Articles","previous_headings":"Basic Usage Examples","what":"Example 4: Unbalanced Allocation","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Calculate sample size unequal group allocation:","code":"# 2:1 allocation (treatment:control) ss_unbalanced <- ss2BinaryApprox(   p11 = 0.7, p12 = 0.7,   p21 = 0.5, p22 = 0.5,   rho1 = 0.5, rho2 = 0.5,   r = 2,  # 2:1 allocation   alpha = 0.025,   beta = 0.2,   Test = \"AN\" )  print(ss_unbalanced) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 172 #>              n2 = 86 #>               N = 258 #>     p (group 1) = 0.7, 0.7 #>     p (group 2) = 0.5, 0.5 #>             rho = 0.5, 0.5 #>      allocation = 2 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN cat(\"Total sample size:\", ss_unbalanced$N, \"\\n\") #> Total sample size: 258"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"power-verification","dir":"Articles","previous_headings":"","what":"Power Verification","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Verify calculated sample sizes achieve target power:","code":"# Use result from Example 1 power_result <- power2BinaryApprox(   n1 = ss_equal$n1,   n2 = ss_equal$n2,   p11 = 0.7, p12 = 0.7,   p21 = 0.5, p22 = 0.5,   rho1 = 0.5, rho2 = 0.5,   alpha = 0.025,   Test = \"AN\" )  cat(\"Target power: 0.80\\n\") #> Target power: 0.80 cat(\"Achieved power (Endpoint 1):\", round(power_result$power1, 4), \"\\n\") #> Achieved power (Endpoint 1): 0.8798 cat(\"Achieved power (Endpoint 2):\", round(power_result$power2, 4), \"\\n\") #> Achieved power (Endpoint 2): 0.8798 cat(\"Achieved power (Co-primary):\", round(power_result$powerCoprimary, 4), \"\\n\") #> Achieved power (Co-primary): 0.8016"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"comparison-of-test-methods","dir":"Articles","previous_headings":"","what":"Comparison of Test Methods","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Compare four asymptotic test methods: Comparison Test Methods (p‚ÇÅ,‚ÇÅ = p‚ÇÅ,‚ÇÇ = 0.7, p‚ÇÇ,‚ÇÅ = p‚ÇÇ,‚ÇÇ = 0.5, œÅ = 0.5)","code":"# Fixed design parameters p11 <- 0.80 p12 <- 0.70 p21 <- 0.55 p22 <- 0.45 rho <- 0.7  # Calculate for each method methods <- c(\"AN\", \"ANc\", \"AS\", \"ASc\") comparison <- lapply(methods, function(method) {     ss <- ss2BinaryApprox(         p11 = p11, p12 = p12,         p21 = p21, p22 = p22,         rho1 = rho, rho2 = rho,         r = 1,         alpha = 0.025,         beta = 0.2,         Test = method     )          data.frame(         Method = method,         n_per_group = ss$n2,         N_total = ss$N     ) })  comparison_table <- bind_rows(comparison)  kable(comparison_table,       caption = \"Comparison of Test Methods (p‚ÇÅ,‚ÇÅ = p‚ÇÅ,‚ÇÇ = 0.7, p‚ÇÇ,‚ÇÅ = p‚ÇÇ,‚ÇÇ = 0.5, œÅ = 0.5)\")"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"design-considerations","dir":"Articles","previous_headings":"Practical Recommendations","what":"Design Considerations","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Estimate correlation: Use pilot data historical information; conservative uncertain Consider asymmetric effects: Use actual effect sizes rather assuming equality Balanced allocation: Generally efficient unless practical constraints require otherwise Test method selection: common; use continuity correction added conservatism Sample size sensitivity: Calculate range plausible correlations effect sizes","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"when-to-use-exact-methods-instead","dir":"Articles","previous_headings":"Practical Recommendations","what":"When to Use Exact Methods Instead","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Use exact methods (ss2BinaryExact) based Homma Yoshida (2025) : Small medium sample sizes (N<200N < 200) Extreme probabilities (p<0.1p < 0.1 p>0.9p > 0.9) Strict Type error control required Regulatory preference exact tests Exact methods using Fisher‚Äôs exact test can provide accurate sample sizes better Type error control situations.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"asymptotic-validity","dir":"Articles","previous_headings":"Practical Recommendations","what":"Asymptotic Validity","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"asymptotic methods appropriate : N>200N > 200 0.1<p<0.90.1 < p < 0.9 Computational efficiency important","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-approx.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Two Binary Co-Primary Endpoints (Asymptotic Methods)","text":"Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19. Sozu, T., Sugimoto, T., & Hamasaki, T. (2010). Sample size determination clinical trials multiple co-primary binary endpoints. Statistics Medicine, 29(21), 2169-2179.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"vignette demonstrates exact sample size calculation power analysis clinical trials two co-primary binary endpoints. methodology based Homma Yoshida (2025), provides exact inference methods using bivariate binomial distribution.","code":"library(twoCoprimary) library(dplyr) library(tidyr) library(knitr)"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"when-to-use-exact-methods","dir":"Articles","previous_headings":"Background","what":"When to Use Exact Methods","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Exact methods recommended : Small medium sample sizes (N<200N < 200) Extreme probabilities (p<0.10p < 0.10 p>0.90p > 0.90) Strict Type error control required Regulatory requirements exact inference Asymptotic methods may maintain nominal Type error rate situations.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"advantages-of-exact-methods","dir":"Articles","previous_headings":"Background","what":"Advantages of Exact Methods","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Accurate Type error control: Exact tests guarantee Œ±‚â§\\alpha \\leq nominal level Better small-sample performance: reliance asymptotic approximations Valid extreme probabilities: restrictions pp values Regulatory acceptance: Often preferred regulatory agencies","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"disadvantages","dir":"Articles","previous_headings":"Background","what":"Disadvantages","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Computational intensity: Requires enumeration possible outcomes Conservatism: Discrete nature can lead conservatism Implementation complexity: complex asymptotic methods","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"model-and-assumptions","dir":"Articles","previous_headings":"Statistical Framework","what":"Model and Assumptions","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Consider two-arm parallel-group superiority trial comparing treatment (group 1) control (group 2). Let n1n_{1} n2n_{2} denote sample sizes groups 1 2, respectively. patient ii group jj (j=1j = 1: treatment, j=2j = 2: control), observe two binary outcomes: Endpoint kk (k=1,2k = 1, 2): Xi,j,k‚àà{0,1}X_{,j,k} \\\\{0, 1\\} Xi,j,k=1X_{,j,k} = 1 patient ii group jj responder endpoint kk, 0 otherwise. True response probabilities: pj,k=P(Xi,j,k=1)p_{j,k} = \\text{P}(X_{,j,k} = 1) 0<pj,k<10 < p_{j,k} < 1 jj kk.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"joint-distribution-of-binary-outcomes","dir":"Articles","previous_headings":"Statistical Framework","what":"Joint Distribution of Binary Outcomes","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"paired binary outcomes (Xi,j,1,Xi,j,2)(X_{,j,1}, X_{,j,2}) patient ii group jj follow multinomial distribution four possible outcomes: Per-trial probabilities: pj(1,1)=œïjp_{j}^{(1,1)} = \\phi_{j}: endpoints successful pj(1,0)=pj,1‚àíœïjp_{j}^{(1,0)} = p_{j,1} - \\phi_{j}: endpoint 1 successful pj(0,1)=pj,2‚àíœïjp_{j}^{(0,1)} = p_{j,2} - \\phi_{j}: endpoint 2 successful pj(0,0)=1‚àípj,1‚àípj,2+œïjp_{j}^{(0,0)} = 1 - p_{j,1} - p_{j,2} + \\phi_{j}: endpoints unsuccessful œïj=P(Xi,j,1=1,Xi,j,2=1)\\phi_{j} = \\text{P}(X_{,j,1} = 1, X_{,j,2} = 1). Let Zj(‚Ñì,m)Z_{j}^{(\\ell,m)} denote random variable representing number times {(Xi,j,1,Xi,j,2):=1,‚Ä¶,nj}\\{(X_{,j,1}, X_{,j,2}) : = 1, \\ldots, n_{j}\\} takes value (‚Ñì,m)(\\ell, m) ‚Ñì,m‚àà{0,1}\\ell, m \\\\{0, 1\\}. : (Zj(0,0),Zj(1,0),Zj(0,1),Zj(1,1))‚àºMultinomial(nj;pj(0,0),pj(1,0),pj(0,1),pj(1,1))(Z_{j}^{(0,0)}, Z_{j}^{(1,0)}, Z_{j}^{(0,1)}, Z_{j}^{(1,1)}) \\sim \\text{Multinomial}(n_{j}; p_{j}^{(0,0)}, p_{j}^{(1,0)}, p_{j}^{(0,1)}, p_{j}^{(1,1)})","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"number-of-responders","dir":"Articles","previous_headings":"Statistical Framework","what":"Number of Responders","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Let Yj,k=‚àë=1njXi,j,kY_{j,k} = \\sum_{=1}^{n_{j}} X_{,j,k} represent number responders group jj endpoint kk. : Yj,1=Zj(1,1)+Zj(1,0)Y_{j,1} = Z_{j}^{(1,1)} + Z_{j}^{(1,0)} Yj,2=Zj(1,1)+Zj(0,1)Y_{j,2} = Z_{j}^{(1,1)} + Z_{j}^{(0,1)}","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"bivariate-binomial-distribution","dir":"Articles","previous_headings":"Statistical Framework","what":"Bivariate Binomial Distribution","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Following Homma Yoshida (2025), joint distribution (Yj,1,Yj,2)(Y_{j,1}, Y_{j,2}) can expressed bivariate binomial distribution: (Yj,1,Yj,2)‚àºBiBin(nj,pj,1,pj,2,Œ≥j)(Y_{j,1}, Y_{j,2}) \\sim \\text{BiBin}(n_{j}, p_{j,1}, p_{j,2}, \\gamma_{j}) Œ≥j\\gamma_{j} dependence parameter related correlation œÅj\\rho_{j} Xi,j,1X_{,j,1} Xi,j,2X_{,j,2}. Probability mass function (Equation 3 Homma Yoshida, 2025): P(Yj,1=yj,1,Yj,2=yj,2‚à£nj,pj,1,pj,2,Œ≥j)=f(yj,1‚à£nj,pj,1)√óg(yj,2‚à£yj,1,nj,pj,1,pj,2,Œ≥j)\\text{P}(Y_{j,1} = y_{j,1}, Y_{j,2} = y_{j,2} \\mid n_{j}, p_{j,1}, p_{j,2}, \\gamma_{j}) = f(y_{j,1} \\mid n_{j}, p_{j,1}) \\times g(y_{j,2} \\mid y_{j,1}, n_{j}, p_{j,1}, p_{j,2}, \\gamma_{j}) details, please see Homma Yoshida (2025).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"correlation-structure","dir":"Articles","previous_headings":"Statistical Framework","what":"Correlation Structure","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"correlation œÅj\\rho_{j} Xi,j,1X_{,j,1} Xi,j,2X_{,j,2} : œÅj=Cor(Xi,j,1,Xi,j,2)=œïj‚àípj,1pj,2pj,1(1‚àípj,1)pj,2(1‚àípj,2)\\rho_{j} = \\text{Cor}(X_{,j,1}, X_{,j,2}) = \\frac{\\phi_{j} - p_{j,1} p_{j,2}}{\\sqrt{p_{j,1}(1 - p_{j,1}) p_{j,2}(1 - p_{j,2})}} dependence parameter Œ≥j\\gamma_{j} related œÅj\\rho_{j} (Equation 4 Homma Yoshida, 2025): Œ≥j=Œ≥(œÅj,pj,1,pj,2)=œÅjpj,2(1‚àípj,2)pj,1(1‚àípj,1)(1‚àíœÅjpj,2(1‚àípj,2)pj,1(1‚àípj,1))‚àí1\\gamma_{j} = \\gamma(\\rho_{j}, p_{j,1}, p_{j,2}) = \\rho_{j} \\sqrt{\\frac{p_{j,2}(1 - p_{j,2})}{p_{j,1}(1 - p_{j,1})}} \\left(1 - \\rho_{j} \\sqrt{\\frac{p_{j,2}(1 - p_{j,2})}{p_{j,1}(1 - p_{j,1})}}\\right)^{-1} Important property: correlation Yj,1Y_{j,1} Yj,2Y_{j,2} equals œÅj\\rho_{j}, correlation Xi,j,1X_{,j,1} Xi,j,2X_{,j,2}. Marginal distributions: Yj,k‚àºBin(nj,pj,k)Y_{j,k} \\sim \\text{Bin}(n_{j}, p_{j,k}) Correlation bounds: Due 0<pj,k<10 < p_{j,k} < 1, correlation œÅj\\rho_{j} bounded: œÅj‚àà[L(pj,1,pj,2),U(pj,1,pj,2)]‚äÜ[‚àí1,1]\\rho_{j} \\[L(p_{j,1}, p_{j,2}), U(p_{j,1}, p_{j,2})] \\subseteq [-1, 1] : L(pj,1,pj,2)=max{‚àípj,1pj,2(1‚àípj,1)(1‚àípj,2),‚àí(1‚àípj,1)(1‚àípj,2)pj,1pj,2}L(p_{j,1}, p_{j,2}) = \\max\\left\\{-\\sqrt{\\frac{p_{j,1} p_{j,2}}{(1 - p_{j,1})(1 - p_{j,2})}}, -\\sqrt{\\frac{(1 - p_{j,1})(1 - p_{j,2})}{p_{j,1} p_{j,2}}}\\right\\} U(pj,1,pj,2)=min{pj,1(1‚àípj,2)pj,2(1‚àípj,1),pj,2(1‚àípj,1)pj,1(1‚àípj,2)}U(p_{j,1}, p_{j,2}) = \\min\\left\\{\\sqrt{\\frac{p_{j,1}(1 - p_{j,2})}{p_{j,2}(1 - p_{j,1})}}, \\sqrt{\\frac{p_{j,2}(1 - p_{j,1})}{p_{j,1}(1 - p_{j,2})}}\\right\\} Special cases: - pj,1=pj,2p_{j,1} = p_{j,2}, U(pj,1,pj,2)=1U(p_{j,1}, p_{j,2}) = 1 - pj,1+pj,2=1p_{j,1} + p_{j,2} = 1, L(pj,1,pj,2)=‚àí1L(p_{j,1}, p_{j,2}) = -1","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"superiority-hypotheses","dir":"Articles","previous_headings":"Hypothesis Testing","what":"Superiority Hypotheses","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Since higher values endpoints indicate treatment benefit, test: endpoint 1: H0(1):p1,1‚â§p2,1 vs. H1(1):p1,1>p2,1\\text{H}_{0}^{(1)}: p_{1,1} \\leq p_{2,1} \\text{ vs. } \\text{H}_{1}^{(1)}: p_{1,1} > p_{2,1} endpoint 2: H0(2):p1,2‚â§p2,2 vs. H1(2):p1,2>p2,2\\text{H}_{0}^{(2)}: p_{1,2} \\leq p_{2,2} \\text{ vs. } \\text{H}_{1}^{(2)}: p_{1,2} > p_{2,2}","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"co-primary-endpoints-intersection-union-test","dir":"Articles","previous_headings":"Hypothesis Testing","what":"Co-Primary Endpoints (Intersection-Union Test)","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"trial succeeds superiority demonstrated endpoints simultaneously: Null hypothesis: H0=H0(1)‚à™H0(2)\\text{H}_{0} = \\text{H}_{0}^{(1)} \\cup \\text{H}_{0}^{(2)} (least one null true) Alternative hypothesis: H1=H1(1)‚à©H1(2)\\text{H}_{1} = \\text{H}_{1}^{(1)} \\cap \\text{H}_{1}^{(2)} (alternatives true) Decision rule: Reject H0\\text{H}_{0} level Œ±\\alpha H0(1)\\text{H}_{0}^{(1)} H0(2)\\text{H}_{0}^{(2)} rejected level Œ±\\alpha without multiplicity adjustment.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"statistical-tests","dir":"Articles","previous_headings":"","what":"Statistical Tests","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Homma Yoshida (2025) consider five exact test methods:","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"method-1-one-sided-pearson-chi-squared-test-chisq","dir":"Articles","previous_headings":"Statistical Tests","what":"Method 1: One-sided Pearson Chi-squared Test (Chisq)","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"endpoint kk, test statistic : Z(y1,k,y2,k)=pÃÇ1,k‚àípÃÇ2,kpÃÇk(1‚àípÃÇk)(1n1+1n2)Z(y_{1,k}, y_{2,k}) = \\frac{\\hat{p}_{1,k} - \\hat{p}_{2,k}}{\\sqrt{\\hat{p}_{k}(1 - \\hat{p}_{k})\\left(\\frac{1}{n_{1}} + \\frac{1}{n_{2}}\\right)}} : pÃÇj,k=yj,k/nj\\hat{p}_{j,k} = y_{j,k} / n_{j} sample proportion pÃÇk=n1pÃÇ1,k+n2pÃÇ2,kn1+n2\\hat{p}_{k} = \\frac{n_{1} \\hat{p}_{1,k} + n_{2} \\hat{p}_{2,k}}{n_{1} + n_{2}} pooled proportion Reject H0(k)\\text{H}_{0}^{(k)} Z(y1,k,y2,k)>z1‚àíŒ±Z(y_{1,k}, y_{2,k}) > z_{1-\\alpha}, z1‚àíŒ±z_{1-\\alpha} (1‚àíŒ±)(1-\\alpha)-quantile standard normal distribution.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"method-2-fishers-exact-test-fisher","dir":"Articles","previous_headings":"Statistical Tests","what":"Method 2: Fisher‚Äôs Exact Test (Fisher)","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Conditional test: Conditions total number successes y1,k+y2,ky_{1,k} + y_{2,k}. H0(k)\\text{H}_{0}^{(k)}, Y1,kY_{1,k} follows hypergeometric distribution given Y1,k+Y2,k=ykY_{1,k} + Y_{2,k} = y_{k}. One-sided p-value: pkFisher=‚àëy=y1,kmin(n1,yk)(n1y)(n2yk‚àíy)(n1+n2yk)p_{k}^{\\text{Fisher}} = \\sum_{y=y_{1,k}}^{\\min(n_{1}, y_{k})} \\frac{\\binom{n_{1}}{y} \\binom{n_{2}}{y_{k} - y}}{\\binom{n_{1} + n_{2}}{y_{k}}} Reject H0(k)\\text{H}_{0}^{(k)} pkFisher<Œ±p_{k}^{\\text{Fisher}} < \\alpha.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"method-3-fishers-mid-p-test-fisher-midp","dir":"Articles","previous_headings":"Statistical Tests","what":"Method 3: Fisher‚Äôs Mid-P Test (Fisher-midP)","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Reduces conservatism adding half probability observed outcome: pkmid-p=pkFisher‚àí12√ó(n1y1,k)(n2yk‚àíy1,k)(n1+n2yk)p_{k}^{\\text{mid-p}} = p_{k}^{\\text{Fisher}} - \\frac{1}{2} \\times \\frac{\\binom{n_{1}}{y_{1,k}} \\binom{n_{2}}{y_{k} - y_{1,k}}}{\\binom{n_{1} + n_{2}}{y_{k}}} Note: twoCoprimary package can implement Fisher‚Äôs Mid-P Test, Homma Yoshida (2025) investigated test.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"method-4-z-pooled-exact-unconditional-test-z-pool","dir":"Articles","previous_headings":"Statistical Tests","what":"Method 4: Z-pooled Exact Unconditional Test (Z-pool)","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Unconditional test: Maximizes p-value possible values nuisance parameter (common success probability pkp_{k} H0\\text{H}_{0}). Uses ZZ-test statistic finds maximum pp-value across possible values pkp_{k}.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"method-5-boschloos-exact-unconditional-test-boschloo","dir":"Articles","previous_headings":"Statistical Tests","what":"Method 5: Boschloo‚Äôs Exact Unconditional Test (Boschloo)","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Similar Z-pooled, based Fisher‚Äôs exact pp-values. Maximizes Fisher‚Äôs exact pp-value nuisance parameter space. powerful exact unconditional tests, computationally intensive.","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"power-formula","dir":"Articles","previous_headings":"Exact Power Calculation","what":"Power Formula","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"exact power test method AA (Equation 9 Homma Yoshida, 2025): powerA(ùõâ)=P[‚ãÇk=12{pA(y1,k,y2,k)<Œ±}‚à£H1]\\text{power}_{}(\\boldsymbol{\\theta}) = \\text{P}\\left[\\bigcap_{k=1}^{2} \\{p_{}(y_{1,k}, y_{2,k}) < \\alpha\\} \\mid \\text{H}_{1}\\right] =‚àë(a1,1,a2,1)‚ààùíú1‚àë(a1,2,a2,2)‚ààùíú2f(a1,1‚à£n1,p1,1)√óf(a2,1‚à£n2,p2,1)√óg(a1,2‚à£a1,1,n1,p1,1,p1,2,Œ≥1)√óg(a2,2‚à£a2,1,n2,p2,1,p2,2,Œ≥2)= \\sum_{(a_{1,1}, a_{2,1}) \\\\mathcal{}_{1}} \\sum_{(a_{1,2}, a_{2,2}) \\\\mathcal{}_{2}} f(a_{1,1} \\mid n_{1}, p_{1,1}) \\times f(a_{2,1} \\mid n_{2}, p_{2,1}) \\times g(a_{1,2} \\mid a_{1,1}, n_{1}, p_{1,1}, p_{1,2}, \\gamma_{1}) \\times g(a_{2,2} \\mid a_{2,1}, n_{2}, p_{2,1}, p_{2,2}, \\gamma_{2}) : ùõâ=(p1,1,p2,1,p1,2,p2,2,n1,n2,Œ≥1,Œ≥2)\\boldsymbol{\\theta} = (p_{1,1}, p_{2,1}, p_{1,2}, p_{2,2}, n_{1}, n_{2}, \\gamma_{1}, \\gamma_{2}) parameter vector ùíúk\\mathcal{}_{k} rejection region endpoint kk ùíúk={(y1,k,y2,k):pA(y1,k,y2,k)<Œ±}\\mathcal{}_{k} = \\{(y_{1,k}, y_{2,k}) : p_{}(y_{1,k}, y_{2,k}) < \\alpha\\}","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"sample-size-calculation","dir":"Articles","previous_headings":"Exact Power Calculation","what":"Sample Size Calculation","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"required sample size n2n_{2} achieve target power 1‚àíŒ≤1 - \\beta (Equation 10 Homma Yoshida, 2025): n2=argminn2‚àà‚Ñ§{powerA(ùõâ)‚â•1‚àíŒ≤}n_{2} = \\arg\\min_{n_{2} \\\\mathbb{Z}} \\{\\text{power}_{}(\\boldsymbol{\\theta}) \\geq 1 - \\beta\\} expressed closed-form formula due : Discreteness binary outcomes Non-monotonic ‚Äúsawtooth‚Äù power curve Algorithm: Sequential search starting asymptotic normal approximation (method) initial value.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"replicating-homma-and-yoshida-2025-table-4","dir":"Articles","previous_headings":"","what":"Replicating Homma and Yoshida (2025) Table 4","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Table 4 Homma Yoshida (2025) shows sample sizes various correlations using Chisq, Fisher, Z-pool, Boschloo. Note following sample code compute scenario Œ±=0.025\\alpha=0.025. notation used function : p11 = p1,1p_{1,1}, p12 = p1,2p_{1,2}, p21 = p2,1p_{2,1}, p22 = p2,2p_{2,2}, first subscript denotes group (1 = treatment, 2 = control) second subscript denotes endpoint (1 2). Table 4: Total Sample Size (N) Two Co-Primary Binary Endpoints (Œ± = 0.025, 1-Œ≤ = 0.90),b Chisq denotes one-sided Pearson chi-squared test. Fisher stands Fisher‚Äôs exact test. Z-pool represents Z-pooled exact unconditional test. Boschloo signifies Boschloo‚Äôs exact unconditional test. b required sample sizes obtained assuming p1,1=p1,2=0.54p_{1,1} = p_{1,2} = 0.54 p2,1=p2,2=0.25p_{2,1} = p_{2,2} = 0.25.","code":"# Recreate Homma and Yoshida (2025) Table 4 library(dplyr) library(tidyr) library(readr)  param_grid_bin_exact_ss <- tibble(   p11 = 0.54,    p12 = 0.54,   p21 = 0.25,   p22 = 0.25 )  result_bin_exact_ss <- do.call(   bind_rows,   lapply(c(\"Chisq\", \"Fisher\", \"Z-pool\", \"Boschloo\"), function(test) {     do.call(       bind_rows,       lapply(1:2, function(r) {         design_table(           param_grid = param_grid_bin_exact_ss,           rho_values = c(0, 0.3, 0.5, 0.8),           r = r,           alpha = 0.025,           beta = 0.1,           endpoint_type = \"binary\",           Test = test         ) %>%            mutate(alpha = 0.025, r = r, Test = test)       })     )   }) ) %>%    pivot_longer(     cols = starts_with(\"rho_\"),     names_to = \"rho\",     values_to = \"N\",     names_transform = list(rho = parse_number)   ) %>%    select(r, rho, Test, N) %>%    pivot_wider(names_from = Test,  values_from = N) %>%    as.data.frame()  kable(result_bin_exact_ss,       caption = \"Table 4: Total Sample Size (N) for Two Co-Primary Binary Endpoints (Œ± = 0.025, 1-Œ≤ = 0.90)^a,b^\",       digits = 1,       col.names = c(\"r\", \"œÅ\", \"Chisq\", \"Fisher\", \"Z-pool\", \"Boschloo\"))"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"example-1-basic-exact-power-calculation","dir":"Articles","previous_headings":"Practical Examples","what":"Example 1: Basic Exact Power Calculation","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Interpretation: power1: Power endpoint 1 alone power2: Power endpoint 2 alone powerCoprimary: Exact power co-primary endpoints","code":"# Calculate exact power using Fisher's exact test result_fisher <- power2BinaryExact(   n1 = 50,   n2 = 50,   p11 = 0.70, p12 = 0.65,   p21 = 0.50, p22 = 0.45,   rho1 = 0.5, rho2 = 0.5,   alpha = 0.025,   Test = \"Fisher\" )  print(result_fisher) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 50 #>              n2 = 50 #>     p (group 1) = 0.7, 0.65 #>     p (group 2) = 0.5, 0.45 #>             rho = 0.5, 0.5 #>           alpha = 0.025 #>            Test = Fisher #>          power1 = 0.46345 #>          power2 = 0.46196 #>  powerCoprimary = 0.297231"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"example-2-sample-size-calculation","dir":"Articles","previous_headings":"Practical Examples","what":"Example 2: Sample Size Calculation","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"","code":"# Calculate required sample size using Boschloo's test result_ss <- ss2BinaryExact(   p11 = 0.70, p12 = 0.65,   p21 = 0.50, p22 = 0.45,   rho1 = 0.5, rho2 = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"Boschloo\" )  print(result_ss) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 120 #>              n2 = 120 #>               N = 240 #>     p (group 1) = 0.7, 0.65 #>     p (group 2) = 0.5, 0.45 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = Boschloo"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"example-3-comparison-of-test-methods","dir":"Articles","previous_headings":"Practical Examples","what":"Example 3: Comparison of Test Methods","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Sample Size Comparison Across Test Methods","code":"# Compare different exact test methods test_methods <- c(\"Chisq\", \"Fisher\", \"Fisher-midP\", \"Z-pool\", \"Boschloo\")  comparison <- lapply(test_methods, function(test) {     result <- ss2BinaryExact(         p11 = 0.50, p12 = 0.40,         p21 = 0.20, p22 = 0.10,         rho1 = 0.7, rho2 = 0.6,         r = 1,         alpha = 0.025,         beta = 0.2,         Test = test     )     data.frame(         Test = test,         n2 = result$n2,         N = result$N     ) })  comparison_table <- bind_rows(comparison)  kable(comparison_table,       caption = \"Sample Size Comparison Across Test Methods\",       col.names = c(\"Test Method\", \"n per group\", \"N total\"))"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"example-4-correlation-effect","dir":"Articles","previous_headings":"Impact of Correlation","what":"Example 4: Correlation Effect","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Impact Correlation Sample Size (Fisher‚Äôs Test) Key finding: Higher positive correlation reduces required sample size.","code":"# Calculate sample size for different correlation values rho_values <- c(0, 0.3, 0.5, 0.8)  correlation_effect <- lapply(rho_values, function(rho) {     result <- ss2BinaryExact(         p11 = 0.70, p12 = 0.60,         p21 = 0.40, p22 = 0.30,         rho1 = rho, rho2 = rho,         r = 1,         alpha = 0.025,         beta = 0.2,         Test = \"Fisher\"     )     data.frame(         rho = rho,         n2 = result$n2,         N = result$N     ) })  rho_table <- bind_rows(correlation_effect)  kable(rho_table,       caption = \"Impact of Correlation on Sample Size (Fisher's Test)\",       col.names = c(\"œÅ\", \"n per group\", \"N total\"))"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"example-5-exact-vs-an-method","dir":"Articles","previous_headings":"Comparison: Exact vs Asymptotic","what":"Example 5: Exact vs AN Method","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Comparison: Exact vs Asymptotic Methods","code":"# Exact method (Chisq) exact_result <- ss2BinaryExact(     p11 = 0.60, p12 = 0.40,     p21 = 0.30, p22 = 0.10,     rho1 = 0.5, rho2 = 0.5,     r = 1,     alpha = 0.025,     beta = 0.1,     Test = \"Chisq\" )  # Asymptotic method (AN) asymp_result <- ss2BinaryApprox(     p11 = 0.60, p12 = 0.40,     p21 = 0.30, p22 = 0.10,     rho1 = 0.5, rho2 = 0.5,     r = 1,     alpha = 0.025,     beta = 0.1,     Test = \"AN\" )  comparison_exact_asymp <- data.frame(   Method = c(\"Exact (Chisq)\", \"Asymptotic (AN)\"),   n_per_group = c(exact_result$n2, asymp_result$n2),   N_total = c(exact_result$N, asymp_result$N),   Difference = c(0, asymp_result$N - exact_result$N) )  kable(comparison_exact_asymp,       caption = \"Comparison: Exact vs Asymptotic Methods\",       col.names = c(\"Method\", \"n per group\", \"N total\", \"Difference\"))"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"test-method-selection","dir":"Articles","previous_headings":"Practical Recommendations","what":"Test Method Selection","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"widely used accepted Conservative guarantees Type error control Recommended regulatory submissions powerful among exact tests Best choice computational resources permit Recommended final analysis Less conservative Fisher May anti-conservative small samples Use caution N<200N < 200 Intermediate Fisher chi-squared Reduce conservatism maintaining validity","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"when-to-use-each-method","dir":"Articles","previous_headings":"Practical Recommendations","what":"When to Use Each Method","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Sample size guidelines: N<100N < 100: Always use exact methods 100‚â§N<200100 \\leq N < 200: Exact methods preferred, especially : Extreme probabilities (p<0.1p < 0.1 p>0.9p > 0.9) Strict Type error control required N‚â•200N \\geq 200 0.1<p<0.90.1 < p < 0.9: Asymptotic methods acceptable","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"correlation-estimation","dir":"Articles","previous_headings":"Practical Recommendations","what":"Correlation Estimation","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Use pilot data historical information conservative uncertain (use œÅ=0\\rho = 0) Consider sensitivity analysis across plausible range","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"allocation-ratio","dir":"Articles","previous_headings":"Practical Recommendations","what":"Allocation Ratio","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Balanced design (r=1r = 1) generally efficient Limited control group availability Ethical considerations Cost constraints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"computational-considerations","dir":"Articles","previous_headings":"","what":"Computational Considerations","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Modern computers handle methods efficiently typical clinical trial sample sizes (N<300N < 300).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"software-implementation","dir":"Articles","previous_headings":"Computational Considerations","what":"Software Implementation","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"twoCoprimary package implements methods efficiently using: Bivariate binomial distribution (dbibinom) Rejection region calculation (rr1Binary) Vectorized computations speed","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-binary-endpoints-exact.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Two Binary Co-Primary Endpoints (Exact Methods)","text":"Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Two Continuous Co-Primary Endpoints","text":"vignette demonstrates sample size calculation power analysis clinical trials two co-primary continuous endpoints using asymptotic normal approximation methods. methodology based Sozu et al.¬†(2011).","code":"library(twoCoprimary) library(dplyr) library(tidyr) library(knitr)"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"what-are-co-primary-endpoints","dir":"Articles","previous_headings":"Background and Motivation","what":"What are Co-Primary Endpoints?","title":"Two Continuous Co-Primary Endpoints","text":"clinical trials, co-primary endpoints require demonstrating statistically significant treatment effects endpoints simultaneously. Unlike multiple primary endpoints (success one endpoint sufficient), co-primary endpoints require: Rejecting null hypotheses level Œ±\\alpha multiplicity adjustment needed Type error control Correlation consideration can improve efficiency","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"clinical-examples","dir":"Articles","previous_headings":"Background and Motivation","what":"Clinical Examples","title":"Two Continuous Co-Primary Endpoints","text":"Co-primary continuous endpoints common : Alzheimer‚Äôs disease trials: Cognitive function (ADAS-cog) + Clinical global impression (CIBIC-plus) Irritable bowel syndrome (IBS) trials: Pain intensity stool frequency IBS constipation (IBS-C) + Pain intensity stool consistency IBS diarrhea (IBS-D)","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"model-and-assumptions","dir":"Articles","previous_headings":"Statistical Framework","what":"Model and Assumptions","title":"Two Continuous Co-Primary Endpoints","text":"Consider two-arm parallel-group superiority trial comparing treatment (group 1) control (group 2). Let n1n_{1} n2n_{2} denote sample sizes two groups (.e., total sample size N=n1+n2N=n_{1}+n_{2}), define allocation ratio r=n1/n2r = n_{1}/n_{2}. subject ii group jj (j=1j = 1: treatment, j=2j = 2: control), observe two continuous outcomes: Endpoint kk (k=1,2k = 1, 2): Xi,j,k‚àºN(Œºj,k,œÉk2)X_{,j,k} \\sim \\text{N}(\\mu_{j,k}, \\sigma_{k}^{2}) : Œºj,k\\mu_{j,k} population mean outcome kk group jj œÉk2\\sigma_{k}^{2} common variance outcome kk across groups Within-subject correlation: two outcomes correlated within subject: Cor(Xi,j,1,Xi,j,2)=œÅj\\text{Cor}(X_{,j,1}, X_{,j,2}) = \\rho_{j} assume common correlation across groups: œÅ1=œÅ2=œÅ\\rho_{1} = \\rho_{2} = \\rho.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"effect-size-parameterization","dir":"Articles","previous_headings":"Statistical Framework","what":"Effect Size Parameterization","title":"Two Continuous Co-Primary Endpoints","text":"treatment effect endpoint kk measured : Absolute difference: Œ¥k=Œº1,k‚àíŒº2,k\\delta_{k} = \\mu_{1,k} - \\mu_{2,k} Standardized effect size: Œ¥k*=Œ¥k/œÉk\\delta_{k}^{\\ast} = \\delta_{k} / \\sigma_{k} standardized effect size preferred scale-free facilitates comparison across studies.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"hypothesis-testing","dir":"Articles","previous_headings":"Statistical Framework","what":"Hypothesis Testing","title":"Two Continuous Co-Primary Endpoints","text":"two co-primary endpoints, test: Null hypothesis: H0=H01‚à™H02\\text{H}_{0} = \\text{H}_{01} \\cup \\text{H}_{02} (least one null hypothesis true) H0k:Œ¥k=0\\text{H}_{0k}: \\delta_{k} = 0 k=1,2k = 1, 2. Alternative hypothesis: H1=H11‚à©H12\\text{H}_{1} = \\text{H}_{11} \\cap \\text{H}_{12} (alternative hypotheses true) H1k:Œ¥k>0\\text{H}_{1k}: \\delta_{k} > 0 k=1,2k = 1, 2. Decision rule: Reject H0\\text{H}_{0} H01\\text{H}_{01} H02\\text{H}_{02} rejected significance level Œ±\\alpha.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"test-statistics","dir":"Articles","previous_headings":"Statistical Framework","what":"Test Statistics","title":"Two Continuous Co-Primary Endpoints","text":"endpoint kk, test statistic : Known variance case: Zk=X‚Äæ1k‚àíX‚Äæ2kœÉk1n1+1n2Z_{k} = \\frac{\\bar{X}_{1k} - \\bar{X}_{2k}}{\\sigma_{k}\\sqrt{\\frac{1}{n_{1}} + \\frac{1}{n_{2}}}} Unknown variance case: Tk=X‚Äæ1k‚àíX‚Äæ2ksk1n1+1n2T_{k} = \\frac{\\bar{X}_{1k} - \\bar{X}_{2k}}{s_{k}\\sqrt{\\frac{1}{n_{1}} + \\frac{1}{n_{2}}}} sks_{k} pooled sample standard deviation endpoint kk.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"joint-distribution","dir":"Articles","previous_headings":"Statistical Framework","what":"Joint Distribution","title":"Two Continuous Co-Primary Endpoints","text":"H1\\text{H}_{1}, variances known, (Z1,Z2)(Z_{1}, Z_{2}) asymptotically follows bivariate normal distribution: (Z1Z2)‚àºBN((œâ1œâ2),(1Œ≥Œ≥1))\\begin{pmatrix} Z_{1} \\\\ Z_{2} \\end{pmatrix} \\sim \\text{BN}\\left(\\begin{pmatrix} \\omega_{1} \\\\ \\omega_{2} \\end{pmatrix}, \\begin{pmatrix} 1 & \\gamma \\\\ \\gamma & 1 \\end{pmatrix}\\right) : œâk=Œ¥krn21+r\\omega_{k} = \\delta_{k}\\sqrt{\\frac{r n_{2}}{1 + r}} non-centrality parameter endpoint kk Œ≥=œÅ\\gamma = \\rho correlation test statistics","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"power-formula","dir":"Articles","previous_headings":"Statistical Framework","what":"Power Formula","title":"Two Continuous Co-Primary Endpoints","text":"overall power : 1‚àíŒ≤=Pr(Z1>z1‚àíŒ± Z2>z1‚àíŒ±‚à£H1)1 - \\beta = \\Pr(Z_{1} > z_{1-\\alpha} \\text{ } Z_{2} > z_{1-\\alpha} \\mid \\text{H}_{1}) Using bivariate normal CDF: 1‚àíŒ≤=Œ¶2(‚àíz1‚àíŒ±+œâ1,‚àíz1‚àíŒ±+œâ2‚à£œÅ)1 - \\beta = \\Phi_{2}(-z_{1-\\alpha} + \\omega_{1}, -z_{1-\\alpha} + \\omega_{2} \\mid \\rho) Œ¶2(‚ãÖ,‚ãÖ‚à£œÅ)\\Phi_{2}(\\cdot, \\cdot \\mid \\rho) bivariate normal CDF correlation œÅ\\rho.","code":""},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"basic-example","dir":"Articles","previous_headings":"Sample Size Calculation","what":"Basic Example","title":"Two Continuous Co-Primary Endpoints","text":"Calculate sample size balanced design (Œ∫=1\\kappa = 1) known variance:","code":"# Design parameters result <- ss2Continuous(   delta1 = 0.5,      # Effect size for endpoint 1   delta2 = 0.5,      # Effect size for endpoint 2   sd1 = 1,           # Standard deviation for endpoint 1   sd2 = 1,           # Standard deviation for endpoint 2   rho = 0.5,         # Correlation between endpoints   r = 1,             # Balanced allocation   alpha = 0.025,     # One-sided significance level   beta = 0.2,        # Type II error (80% power)   known_var = TRUE )  print(result) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 79 #>              n2 = 79 #>               N = 158 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>       known_var = TRUE"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"impact-of-correlation","dir":"Articles","previous_headings":"Sample Size Calculation","what":"Impact of Correlation","title":"Two Continuous Co-Primary Endpoints","text":"Examine correlation affects sample size: Sample Size vs Correlation (delta = 0.5, alpha = 0.025, power = 0.8) Key finding: œÅ=0.8\\rho = 0.8, approximately 11% reduction sample size compared œÅ=0\\rho = 0.","code":"# Calculate sample sizes for different correlations correlations <- c(0, 0.3, 0.5, 0.8) sample_sizes <- sapply(correlations, function(rho) {   ss2Continuous(     delta1 = 0.5, delta2 = 0.5,     sd1 = 1, sd2 = 1,     rho = rho, r = 1,     alpha = 0.025, beta = 0.2,     known_var = TRUE   )$N })  # Create summary table correlation_table <- data.frame(   Correlation = correlations,   Total_N = sample_sizes,   Reduction = c(0, round((1 - sample_sizes[-1]/sample_sizes[1]) * 100, 1)) )  kable(correlation_table,       caption = \"Sample Size vs Correlation (delta = 0.5, alpha = 0.025, power = 0.8)\",       col.names = c(\"Correlation (rho)\", \"Total N\", \"Reduction (%)\"))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"visualization-with-plot","dir":"Articles","previous_headings":"Sample Size Calculation","what":"Visualization with plot()","title":"Two Continuous Co-Primary Endpoints","text":"Visualize relationship correlation sample size:  Visualize power contours different effect sizes:","code":"# Use plot method to visualize sample size vs correlation plot(result, type = \"sample_size_rho\") # Create contour plot for effect sizes plot(result, type = \"effect_contour\")"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"replicating-sozu-et-al--2011-table-1","dir":"Articles","previous_headings":"","what":"Replicating Sozu et al.¬†(2011) Table 1","title":"Two Continuous Co-Primary Endpoints","text":"replicate Table 1 Sozu et al.¬†(2011) using design_table() function. table shows sample sizes per group various combinations standardized effect sizes. Table 1: Sample Sizes Per Group (Sozu et al.¬†2011, alpha = 0.025, power = 0.8) Interpretation: row represents combination standardized effect sizes (Œ¥1*,Œ¥2*\\delta_{1}^{\\ast}, \\delta_{2}^{\\ast}) Columns show sample size per group different correlations (œÅ=0,0.3,0.5,0.8\\rho = 0, 0.3, 0.5, 0.8) Higher correlation leads smaller required sample sizes Œ¥1=Œ¥2\\delta_{1} = \\delta_{2} (equal effect sizes), benefit correlation pronounced","code":"# Create parameter grid (delta1 <= delta2) param_grid <- expand.grid(   delta1 = c(0.2, 0.25, 0.3, 0.35, 0.4),   delta2 = c(0.2, 0.25, 0.3, 0.35, 0.4),   sd1 = 1,   sd2 = 1 ) %>%    arrange(delta1, delta2) %>%    filter(delta2 >= delta1)  # Calculate sample sizes for different correlations result_table <- design_table(   param_grid = param_grid,   rho_values = c(0, 0.3, 0.5, 0.8),   r = 1,   alpha = 0.025,   beta = 0.2,   endpoint_type = \"continuous\" ) %>%    mutate_at(vars(starts_with(\"rho_\")), ~ . / 2)  # Per-group sample size  # Display table kable(result_table,       caption = \"Table 1: Sample Sizes Per Group (Sozu et al. 2011, alpha = 0.025, power = 0.8)\",       digits = 2)"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"power-for-a-given-sample-size","dir":"Articles","previous_headings":"Power Calculation","what":"Power for a Given Sample Size","title":"Two Continuous Co-Primary Endpoints","text":"Calculate power specific sample size:","code":"# Calculate power with n1 = n2 = 100 power_result <- power2Continuous(   n1 = 100, n2 = 100,   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5,   alpha = 0.025,   known_var = TRUE )  print(power_result) #>  #> Power calculation for two continuous co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.5 #>           alpha = 0.025 #>       known_var = TRUE #>          power1 = 0.942438 #>          power2 = 0.942438 #>  powerCoprimary = 0.899732"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"power-verification","dir":"Articles","previous_headings":"Power Calculation","what":"Power Verification","title":"Two Continuous Co-Primary Endpoints","text":"Verify calculated sample size achieves target power:","code":"# Calculate sample size ss_result <- ss2Continuous(   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5, r = 1,   alpha = 0.025, beta = 0.2,   known_var = TRUE )  # Verify power with calculated sample size power_check <- power2Continuous(   n1 = ss_result$n1, n2 = ss_result$n2,   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5,   alpha = 0.025,   known_var = TRUE )  cat(\"Calculated sample size per group:\", ss_result$n2, \"\\n\") #> Calculated sample size per group: 79 cat(\"Target power: 0.80\\n\") #> Target power: 0.80 cat(\"Achieved power:\", round(power_check$powerCoprimary, 4), \"\\n\") #> Achieved power: 0.8042"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"unified-interface","dir":"Articles","previous_headings":"","what":"Unified Interface","title":"Two Continuous Co-Primary Endpoints","text":"package provides unified interface similar power.prop.test():","code":"# Sample size calculation mode twoCoprimary2Continuous(   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5, power = 0.8, r = 1,   alpha = 0.025, known_var = TRUE ) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 79 #>              n2 = 79 #>               N = 158 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>       known_var = TRUE  # Power calculation mode twoCoprimary2Continuous(   n1 = 100, n2 = 100,   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5,   alpha = 0.025, known_var = TRUE ) #>  #> Power calculation for two continuous co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.5 #>           alpha = 0.025 #>       known_var = TRUE #>          power1 = 0.942438 #>          power2 = 0.942438 #>  powerCoprimary = 0.899732"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"unknown-variance-case","dir":"Articles","previous_headings":"","what":"Unknown Variance Case","title":"Two Continuous Co-Primary Endpoints","text":"variances unknown, use tt-test Monte Carlo simulation: Note: unknown variance case requires computation time due Monte Carlo simulation.","code":"# Sample size calculation with unknown variance ss_unknown <- ss2Continuous(   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5, r = 1,   alpha = 0.025, beta = 0.2,   known_var = FALSE,   nMC = 10000  # Number of Monte Carlo simulations )  print(ss_unknown) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 80 #>              n2 = 80 #>               N = 160 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>       known_var = FALSE #>             nMC = 10000"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"correlation-estimation","dir":"Articles","previous_headings":"Practical Considerations","what":"Correlation Estimation","title":"Two Continuous Co-Primary Endpoints","text":"Methods estimate correlation œÅ\\rho: Pilot studies: Small preliminary studies Historical data: Previous trials disease area Literature review: Published studies similar endpoints Expert opinion: Clinical judgment data unavailable Conservative approach: Use lower correlation estimates ensure adequate power.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"sensitivity-analysis","dir":"Articles","previous_headings":"Practical Considerations","what":"Sensitivity Analysis","title":"Two Continuous Co-Primary Endpoints","text":"Always perform sensitivity analysis: Sensitivity Analysis: Impact Correlation Misspecification","code":"# Test robustness to correlation misspecification assumed_rho <- 0.5 true_rhos <- c(0, 0.3, 0.5, 0.7, 0.9)  # Calculate sample size assuming rho = 0.5 ss_assumed <- ss2Continuous(   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = assumed_rho, r = 1,   alpha = 0.025, beta = 0.2,   known_var = TRUE )  # Calculate achieved power under different true correlations sensitivity_results <- data.frame(   Assumed_rho = assumed_rho,   True_rho = true_rhos,   n_per_group = ss_assumed$n2,   Achieved_power = sapply(true_rhos, function(true_rho) {     power2Continuous(       n1 = ss_assumed$n1, n2 = ss_assumed$n2,       delta1 = 0.5, delta2 = 0.5,       sd1 = 1, sd2 = 1,       rho = true_rho,       alpha = 0.025,       known_var = TRUE     )$powerCoprimary   }) )  kable(sensitivity_results,       caption = \"Sensitivity Analysis: Impact of Correlation Misspecification\",       digits = 3,       col.names = c(\"Assumed rho\", \"True rho\", \"n per group\", \"Achieved Power\"))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/articles/two-continuous-endpoints.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Two Continuous Co-Primary Endpoints","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination superiority clinical trials multiple co-primary correlated endpoints. Journal Biopharmaceutical Statistics, 21(4), 650-668.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gosuke Homma. Author, maintainer.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Homma G (2025). twoCoprimary: Sample Size Power Calculation Two Co-Primary Endpoints. R package version 1.0.0, https://gosukehommaex.github.io/twoCoprimary/.","code":"@Manual{,   title = {twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints},   author = {Gosuke Homma},   year = {2025},   note = {R package version 1.0.0},   url = {https://gosukehommaex.github.io/twoCoprimary/}, }"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"twoCoprimary provides comprehensive tools sample size power calculation clinical trials two co-primary endpoints. co-primary endpoint trials, treatment success requires demonstrating statistically significant effects primary endpoints simultaneously. package implements state---art methodologies properly account correlation endpoints, leading efficient trial designs. üìñ Documentation Website","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"key-features","dir":"","previous_headings":"","what":"Key Features","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"package supports five combinations co-primary endpoints: Two continuous endpoints - Normal distribution correlation (Sozu et al., 2011) Two binary endpoints (asymptotic) - Large sample approximation methods (Sozu et al., 2010) Two binary endpoints (exact) - Exact inference small medium samples (Homma & Yoshida, 2025) Mixed continuous binary - Biserial correlation structure (Sozu et al., 2012) Mixed count continuous - Negative binomial overdispersed counts (Homma & Yoshida, 2024) methods provide: - ‚úÖ Sample size calculation given target power - ‚úÖ Power calculation given sample size - ‚úÖ Proper Type error control without multiplicity adjustment - ‚úÖ Accounting correlation endpoints - ‚úÖ Support unbalanced allocation ratios","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"Install CRAN: install development version GitHub:","code":"install.packages(\"twoCoprimary\") # install.packages(\"pak\") pak::pak(\"gosukehommaEX/twoCoprimary\")"},{"path":[]},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"example-1-two-continuous-endpoints","dir":"","previous_headings":"Quick Start","what":"Example 1: Two Continuous Endpoints","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"Calculate sample size trial two continuous co-primary endpoints:","code":"library(twoCoprimary)  # Sample size calculation result <- ss2Continuous(   delta1 = 0.5,      # Standardized effect size for endpoint 1   delta2 = 0.4,      # Standardized effect size for endpoint 2   rho = 0.3,         # Correlation between endpoints   alpha = 0.025,     # One-sided significance level   power = 0.80,      # Target power   r = 1              # Allocation ratio (1:1) )  print(result) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #> Parameters: #>   Effect sizes: delta1 = 0.5, delta2 = 0.4 #>   Correlation: rho = 0.3 #>   Significance level: alpha = 0.025 (one-sided) #>   Target power: 1 - beta = 0.8 #>   Allocation ratio: r = 1 #>  #> Results: #>   Sample size per group: n1 = n2 = 130 #>   Total sample size: N = 260"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"example-2-two-binary-endpoints-exact-method","dir":"","previous_headings":"Quick Start","what":"Example 2: Two Binary Endpoints (Exact Method)","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"small medium sample sizes, use exact methods:","code":"# Sample size with exact inference result_exact <- ss2BinaryExact(   p11 = 0.30, p12 = 0.15,    # Response rates for endpoint 1   p21 = 0.50, p22 = 0.30,    # Response rates for endpoint 2   rho1 = 0.3, rho2 = 0.3,    # Within-group correlations   alpha = 0.025,             # One-sided significance level   power = 0.80,              # Target power   r = 1,                     # Allocation ratio   test_method = \"Fisher\"     # Exact test method )  print(result_exact)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"example-3-mixed-count-and-continuous-endpoints","dir":"","previous_headings":"Quick Start","what":"Example 3: Mixed Count and Continuous Endpoints","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"COPD/asthma trials exacerbation count lung function:","code":"# Exacerbation rates (events per year) r1 <- 0.80  # Treatment group r2 <- 1.25  # Control group  # Sample size calculation result_mixed <- ss2MixedCountContinuous(   r1 = r1, r2 = r2,          # Event rates   nu = 1.0,                  # Dispersion parameter   t = 1,                     # Follow-up period (years)   mu1 = 250, mu2 = 200,      # Mean FEV1 (mL)   sd = 300,                  # Common SD   rho1 = 0.5, rho2 = 0.5,    # Correlations   alpha = 0.025,   power = 0.80,   r = 1 )  print(result_mixed)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"Comprehensive vignettes available: Overview co-primary endpoints Two continuous endpoints Two binary endpoints (asymptotic) Two binary endpoints (exact) Mixed continuous binary Mixed count continuous","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation clinical trials co‚Äêprimary outcomes: Negative binomial continuous outcomes. Pharmaceutical Statistics, 23(3), 368-392. https://doi.org/10.1002/pst.2337 Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1). https://doi.org/10.1177/09622802251368697 Sozu, T., Sugimoto, T., Hamasaki, T., & Evans, S. R. (2010). Sample size determination superiority clinical trials multiple co-primary correlated endpoints. Statistics Medicine, 29(21), 2219-2227. https://doi.org/10.1002/sim.3972 Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination superiority clinical trials multiple co-primary correlated endpoints. Journal Biopharmaceutical Statistics, 21(4), 650-668. https://doi.org/10.1080/10543406.2011.551329 Sozu, T., Sugimoto, T., Hamasaki, T., & Evans, S. R. (2012). Sample size determination clinical trials multiple co-primary binary endpoints including mixed binary continuous endpoints. Biometrical Journal, 54(5), 716-729. https://doi.org/10.1002/bimj.201100221","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"","code":"citation(\"twoCoprimary\")"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting Help","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"bug reports feature requests, please use GitHub issue tracker questions usage, see documentation website","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"twoCoprimary: Sample Size and Power Calculation for Two Co-Primary Endpoints","text":"MIT ¬© Gosuke Homma","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"Computes lower upper bounds correlation coefficient two binary outcomes based marginal probabilities, described Prentice (1988).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"","code":"corrbound2Binary(p1, p2)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"p1 True probability responders first outcome (0 < p1 < 1) p2 True probability responders second outcome (0 < p2 < 1)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"named numeric vector two elements: L_bound Lower bound correlation U_bound Upper bound correlation","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"two binary outcomes marginal probabilities p1 p2, correlation coefficient rho bounded : $$\\rho \\[L(p_1, p_2), U(p_1, p_2)]$$ $$L(p_1, p_2) = \\max\\left\\{-\\sqrt{\\frac{p_1 p_2}{(1-p_1)(1-p_2)}},       -\\sqrt{\\frac{(1-p_1)(1-p_2)}{p_1 p_2}}\\right\\}$$ $$U(p_1, p_2) = \\min\\left\\{\\sqrt{\\frac{p_1(1-p_2)}{p_2(1-p_1)}},       \\sqrt{\\frac{p_2(1-p_1)}{p_1(1-p_2)}}\\right\\}$$","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"Prentice, R. L. (1988). Correlated binary regression covariates specific binary observation. Biometrics, 44(4), 1033-1048.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2Binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Correlation Bounds Between Two Binary Outcomes ‚Äî corrbound2Binary","text":"","code":"# Calculate correlation bounds for two binary outcomes corrbound2Binary(p1 = 0.3, p2 = 0.5) #>    L_bound    U_bound  #> -0.6546537  0.6546537   # When probabilities are equal, upper bound is 1 corrbound2Binary(p1 = 0.4, p2 = 0.4) #>    L_bound    U_bound  #> -0.6666667  1.0000000   # When p1 + p2 = 1, lower bound is -1 corrbound2Binary(p1 = 0.3, p2 = 0.7) #>    L_bound    U_bound  #> -1.0000000  0.4285714"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"Computes lower upper bounds correlation coefficient overdispersed count outcome (negative binomial) continuous outcome (normal), described Homma Yoshida (2024).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"","code":"corrbound2MixedCountContinuous(lambda, nu, mu, sd)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"lambda Mean parameter negative binomial distribution (lambda > 0) nu Dispersion parameter negative binomial distribution (nu > 0) mu Mean continuous outcome sd Standard deviation continuous outcome (sd > 0)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"named numeric vector two elements: L_bound Lower bound correlation U_bound Upper bound correlation","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"correlation bounds calculated using Frechet-Hoeffding bounds copulas, described Trivedi Zimmer (2007). negative binomial distribution mean lambda variance: $$Var(Y_1) = \\lambda + \\frac{\\lambda^2}{\\nu}$$ variance negative binomial distribution : Var(Y1) = lambda + lambda^2/nu","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation clinical trials two co-primary endpoints including overdispersed count continuous outcomes. Pharmaceutical Statistics, 23(1), 46-59. Trivedi, P. K., & Zimmer, D. M. (2007). Copula modeling: introduction practitioners. Foundations Trends Econometrics, 1(1), 1-111.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/corrbound2MixedCountContinuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Correlation Bounds Between Count and Continuous Outcomes ‚Äî corrbound2MixedCountContinuous","text":"","code":"# Calculate correlation bounds for NB(1.25, 0.8) and N(0, 250) corrbound2MixedCountContinuous(lambda = 1.25, nu = 0.8, mu = 0, sd = 250) #>    L_bound    U_bound  #> -0.8457747  0.8457747   # Higher dispersion parameter corrbound2MixedCountContinuous(lambda = 2.0, nu = 2.0, mu = 50, sd = 200) #>    L_bound    U_bound  #> -0.9209669  0.9209671   # Different follow-up time corrbound2MixedCountContinuous(lambda = 1.0 * 2, nu = 1.0, mu = 0, sd = 300) #>    L_bound    U_bound  #> -0.8812028  0.8812028"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"Calculates probability mass function bivariate binomial distribution given parameters, described Homma Yoshida (2025).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"","code":"dbibinom(N, y1, y2, p1, p2, rho)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"N Sample size (number trials) y1 Observed value(s) first random variable (0 N) y2 Observed value(s) second random variable (0 N) p1 True probability responders first outcome (0 < p1 < 1) p2 True probability responders second outcome (0 < p2 < 1) rho Correlation coefficient two binary outcomes","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"Probability mass function value(s) bivariate binomial distribution. y1 y2 vectors, returns vector probabilities.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"bivariate binomial distribution BiBin(N, p1, p2, gamma) probability mass function given equation (3) Homma Yoshida (2025): $$P(Y_1 = y_1, Y_2 = y_2) = f(y_1|N, p_1) \\times g(y_2|y_1, N, p_1, p_2, \\gamma)$$ $$g(y_2|y_1, N, p_1, p_2, \\gamma) = \\frac{1}{(1+\\gamma)^N}       \\sum_{m \\\\mathcal{M}} \\binom{y_1}{m} \\binom{N-y_1}{y_2-m}       (\\xi+\\gamma)^m (1-\\xi)^{y_1-m} \\xi^{y_2-m} (1-\\xi+\\gamma)^{N-y_1-(y_2-m)}$$ \\(\\xi = p_2 + \\gamma(p_2 - p_1)\\) \\(\\mathcal{M} = \\{m : m = \\max(0, y_2-(N-y_1)), \\ldots, \\min(y_1, y_2)\\}\\).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/dbibinom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Probability Mass Function of Bivariate Binomial Distribution ‚Äî dbibinom","text":"","code":"# Calculate single probability mass dbibinom(N = 100, y1 = 30, y2 = 50, p1 = 0.3, p2 = 0.5, rho = 0.5) #> [1] 0.007981836  # Verify that probabilities sum to 1 N <- 20 p1 <- 0.3 p2 <- 0.5 rho <- 0.5 sum(outer(0:N, 0:N, function(x, y) dbibinom(N, x, y, p1, p2, rho))) #> [1] 1"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"Generates comprehensive table comparing sample sizes power across different parameter combinations correlation values. function useful sensitivity analyses exploring design parameters affect statistical properties.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"","code":"design_table(   param_grid,   rho_values = c(0, 0.3, 0.5, 0.8),   r = 1,   alpha = 0.025,   beta = 0.2,   endpoint_type = c(\"continuous\", \"binary\", \"mixed_cont_binary\", \"mixed_count_cont\"),   Test = \"AN\",   known_var = TRUE,   nMC = 1000,   output_var = NULL )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"param_grid data.frame containing parameter combinations. Required columns depend endpoint_type calculation_mode: continuous endpoints (sample size): delta1, delta2, sd1, sd2 continuous endpoints (power): n1, n2, delta1, delta2, sd1, sd2 binary endpoints (sample size): p11, p12, p21, p22 binary endpoints (power): n1, n2, p11, p12, p21, p22 mixed continuous-binary (sample size): delta, sd, p1, p2 mixed continuous-binary (power): n1, n2, delta, sd, p1, p2 mixed count-continuous (sample size): r1, r2, nu, t, mu1, mu2, sd mixed count-continuous (power): n1, n2, r1, r2, nu, t, mu1, mu2, sd rho_values Numeric vector correlation values evaluate. Default c(0, 0.3, 0.5, 0.8). r Allocation ratio (n1/n2). Required sample size calculation. Default 1. alpha One-sided significance level. Default 0.025. beta Type II error rate (1 - power). Required sample size calculation. Default 0.2 (power = 0.8). endpoint_type Character string specifying endpoint type: \"continuous\", \"binary\", \"mixed_cont_binary\", \"mixed_count_cont\". Test Test method binary endpoints: \"\" (asymptotic normal), \"ANc\" (continuity correction), \"\" (arcsine), \"ASc\". Default \"\". used binary mixed_cont_binary endpoints. known_var Logical indicating whether variance known continuous endpoints. Default TRUE. nMC Number Monte Carlo simulations certain calculations. Default 1000. output_var Character string specifying variable output result columns: \"N\" (total sample size, default sample size calculation) \"powerCoprimary\" (co-primary power, default power calculation).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"data.frame class \"twoCoprimary_table\" : Parameter columns (param_grid) Result columns correlation value (rho_0.0, rho_0.3, etc.)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"function performs systematic calculations across combinations parameters specified param_grid correlation values rho_values. calculation mode (sample size vs power) automatically determined: param_grid contains n1 n2: calculates power Otherwise: calculates sample size (requires r, alpha, beta) binary endpoints two correlations (rho1, rho2), set value rho_values calculation. output format follows style Sozu et al. (2011), parameters displayed leftmost columns results correlation subsequent columns.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"Sozu, T., Kanou, T., Hamada, C., & Yoshimura, . (2011). Power sample size calculations clinical trials multiple primary variables. Japanese Journal Biometrics, 27, 83-96.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/design_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Design Comparison Table for Two Co-Primary Endpoints ‚Äî design_table","text":"","code":"# Sample size calculation for continuous endpoints param_grid <- expand.grid(   delta1 = c(0.3, 0.5),   delta2 = c(0.1, 0.2, 0.3),   sd1 = c(1.0, 1.5),   sd2 = c(1.0, 1.5) )  result <- design_table(   param_grid = param_grid,   rho_values = c(0, 0.3, 0.5, 0.8),   r = 1,   alpha = 0.025,   beta = 0.2,   endpoint_type = \"continuous\" ) print(result) #>  #> Design Comparison Table for Two Co-Primary Endpoints #> ====================================================== #>  #>  delta1 delta2 sd1 sd2 rho_0.0 rho_0.3 rho_0.5 rho_0.8 #>     0.3    0.1 1.0 1.0    3140    3140    3140    3140 #>     0.5    0.1 1.0 1.0    3140    3140    3140    3140 #>     0.3    0.2 1.0 1.0     804     798     794     786 #>     0.5    0.2 1.0 1.0     786     786     786     786 #>     0.3    0.3 1.0 1.0     460     448     436     408 #>     0.5    0.3 1.0 1.0     352     352     350     350 #>     0.3    0.1 1.5 1.0    3142    3140    3140    3140 #>     0.5    0.1 1.5 1.0    3140    3140    3140    3140 #>     0.3    0.2 1.5 1.0    1032    1006     980     916 #>     0.5    0.2 1.5 1.0     792     790     788     786 #>     0.3    0.3 1.5 1.0     804     798     794     786 #>     0.5    0.3 1.5 1.0     418     408     398     374 #>     0.3    0.1 1.0 1.5    7064    7064    7064    7064 #>     0.5    0.1 1.0 1.5    7064    7064    7064    7064 #>     0.3    0.2 1.0 1.5    1768    1768    1766    1766 #>     0.5    0.2 1.0 1.5    1766    1766    1766    1766 #>     0.3    0.3 1.0 1.5     804     798     794     786 #>     0.5    0.3 1.0 1.5     786     786     786     786 #>     0.3    0.1 1.5 1.5    7064    7064    7064    7064 #>     0.5    0.1 1.5 1.5    7064    7064    7064    7064 #>     0.3    0.2 1.5 1.5    1808    1794    1784    1768 #>     0.5    0.2 1.5 1.5    1766    1766    1766    1766 #>     0.3    0.3 1.5 1.5    1032    1006     980     916 #>     0.5    0.3 1.5 1.5     792     790     788     786  # Power calculation for continuous endpoints param_grid_power <- expand.grid(   n1 = c(50, 100),   n2 = c(50, 100),   delta1 = 0.5,   delta2 = 0.5,   sd1 = 1.0,   sd2 = 1.0 )  result_power <- design_table(   param_grid = param_grid_power,   rho_values = c(0, 0.3, 0.5, 0.8),   alpha = 0.025,   endpoint_type = \"continuous\" ) print(result_power) #>  #> Design Comparison Table for Two Co-Primary Endpoints #> ====================================================== #>  #>   n1  n2 delta1 delta2 sd1 sd2   rho_0.0   rho_0.3   rho_0.5   rho_0.8 #>   50  50    0.5    0.5   1   1 0.4976088 0.5352018 0.5634879 0.6173565 #>  100  50    0.5    0.5   1   1 0.6772986 0.7002326 0.7190959 0.7573394 #>   50 100    0.5    0.5   1   1 0.6772986 0.7002326 0.7190959 0.7573394 #>  100 100    0.5    0.5   1   1 0.8881885 0.8938066 0.8997323 0.9141060  # Binary endpoints param_grid_binary <- expand.grid(   p11 = c(0.6, 0.7),   p12 = c(0.4, 0.5),   p21 = c(0.4, 0.5),   p22 = c(0.2, 0.3) )  result_binary <- design_table(   param_grid = param_grid_binary,   rho_values = c(0.3, 0.5, 0.7),   r = 1,   alpha = 0.025,   beta = 0.2,   endpoint_type = \"binary\",   Test = \"AN\" ) print(result_binary) #>  #> Design Comparison Table for Two Co-Primary Endpoints #> ====================================================== #>  #>  p11 p12 p21 p22 rho_0.3 rho_0.5 rho_0.7 #>  0.6 0.4 0.4 0.2     230     224      NA #>  0.7 0.4 0.4 0.2     168     166      NA #>  0.6 0.5 0.4 0.2     196     196      NA #>  0.7 0.5 0.4 0.2     104     100      NA #>  0.6 0.4 0.5 0.2     776     776      NA #>  0.7 0.4 0.5 0.2     224     218      NA #>  0.6 0.5 0.5 0.2     776     776      NA #>  0.7 0.5 0.5 0.2     188     188      NA #>  0.6 0.4 0.4 0.3     714     712      NA #>  0.7 0.4 0.4 0.3     712     712      NA #>  0.6 0.5 0.4 0.3     244     238     228 #>  0.7 0.5 0.4 0.3     190     188      NA #>  0.6 0.4 0.5 0.3     952     928      NA #>  0.7 0.4 0.5 0.3     714     712      NA #>  0.6 0.5 0.5 0.3     776     776      NA #>  0.7 0.5 0.5 0.3     238     232      NA"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/plot.twoCoprimary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","title":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","text":"Visualizes power sample size relationships two co-primary endpoints designs. function automatically determines appropriate plot based input object.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/plot.twoCoprimary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","text":"","code":"# S3 method for class 'twoCoprimary' plot(   x,   type = NULL,   n_points = 50,   n_range = NULL,   rho_range = NULL,   col = \"steelblue\",   lwd = 2,   main = NULL,   xlab = NULL,   ylab = NULL,   show_reference = TRUE,   ... )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/plot.twoCoprimary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","text":"x object class \"twoCoprimary\" power sample size calculation functions type Type plot generate: \"power_curve\" Power function sample size (default power calculation results) \"sample_size_rho\" Sample size function correlation (default sample size calculation results) \"effect_contour\" Contour plot showing combinations effect sizes achieving target power n_points Number points compute curve. Default 50. n_range Sample size range power_curve plot. NULL, automatically determined object. rho_range Correlation range sample_size_rho plot. Default seq(0, 0.9, length.= n_points). col Line color. Default \"steelblue\". lwd Line width. Default 2. main Plot title. NULL, automatically generated. xlab X-axis label. NULL, automatically generated. ylab Y-axis label. NULL, automatically generated. show_reference Logical. TRUE, shows reference lines (e.g., target power, current values). Default TRUE. ... Additional graphical parameters passed plot()","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/plot.twoCoprimary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","text":"Invisibly returns data used create plot data frame.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/plot.twoCoprimary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","text":"function creates publication-quality plots visualize relationship design parameters statistical properties. plot type automatically selected based input object, can overridden using type argument. power calculation results (n1 n2 specified), default show power changes sample size. sample size calculation results (power specified), default show required sample size changes correlation. function works endpoint types (continuous, binary, mixed) automatically detecting appropriate parameters input object.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/plot.twoCoprimary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Method for twoCoprimary Objects ‚Äî plot.twoCoprimary","text":"","code":"# Power calculation result result_power <- power2Continuous(   n1 = 100, n2 = 100,   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5, alpha = 0.025,   known_var = TRUE ) plot(result_power)  # Shows power curve   # Sample size calculation result result_ss <- ss2Continuous(   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.5, r = 1,   alpha = 0.025, beta = 0.2,   known_var = TRUE ) plot(result_ss)  # Shows sample size vs correlation   # Custom plot with specified type plot(result_power, type = \"power_curve\", n_range = c(50, 200))"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"Calculates power two-arm superiority trial two co-primary binary endpoints using various asymptotic normal approximation methods, described Sozu et al. (2010).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"","code":"power2BinaryApprox(n1, n2, p11, p12, p21, p22, rho1, rho2, alpha, Test)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"n1 Sample size group 1 (test group) n2 Sample size group 2 (control group) p11 True probability responders group 1 first outcome (0 < p11 < 1) p12 True probability responders group 1 second outcome (0 < p12 < 1) p21 True probability responders group 2 first outcome (0 < p21 < 1) p22 True probability responders group 2 second outcome (0 < p22 < 1) rho1 Correlation two outcomes group 1 rho2 Correlation two outcomes group 2 alpha One-sided significance level (typically 0.025 0.05) Test Statistical testing method. One : \"\": Asymptotic normal method without continuity correction \"ANc\": Asymptotic normal method continuity correction \"\": Arcsine method without continuity correction \"ASc\": Arcsine method continuity correction","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"data frame following columns: n1 Sample size group 1 n2 Sample size group 2 p11, p12, p21, p22 Response probabilities rho1, rho2 Correlations alpha One-sided significance level Test Testing method used power1 Power first endpoint alone power2 Power second endpoint alone powerCoprimary Power co-primary endpoints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"function implements four approximate power calculation methods: Asymptotic Normal (): Uses standard normal approximation without continuity correction (equations 3-4 Sozu et al. 2010). Asymptotic Normal Continuity Correction (ANc): Includes Yates's continuity correction (equation 5 Sozu et al. 2010). Arcsine (): Uses arcsine transformation without continuity correction (equation 6 Sozu et al. 2010). Arcsine Continuity Correction (ASc): Arcsine method continuity correction (equation 7 Sozu et al. 2010). correlation test statistics two endpoints depends method: ANc methods: $$\\rho_{nml} = \\frac{\\sum_{j=1}^{2} \\rho_j \\sqrt{\\nu_{j1}\\nu_{j2}}/n_j}       {se_1 \\times se_2}$$ \\(\\nu_{jk} = p_{jk}(1-p_{jk})\\). method: $$\\rho_{arc} = \\frac{n_2 \\rho_1 + n_1 \\rho_2}{n_1 + n_2}$$ weighted average correlations groups. ASc method: $$\\rho_{arc,c} = \\frac{1}{se_1 \\times se_2}       \\left(\\frac{\\rho_1 \\sqrt{\\nu_{11}\\nu_{12}}}{4n_1\\sqrt{\\nu_{11,c}\\nu_{12,c}}} +       \\frac{\\rho_2 \\sqrt{\\nu_{21}\\nu_{22}}}{4n_2\\sqrt{\\nu_{21,c}\\nu_{22,c}}}\\right)$$ \\(\\nu_{jk,c} = (p_{jk} + c_j)(1 - p_{jk} - c_j)\\), \\(c_1 = -1/(2n_1)\\), \\(c_2 = 1/(2n_2)\\). correlation bounds automatically checked using corrbound2Binary.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2010). Sample size determination clinical trials multiple co-primary binary endpoints. Statistics Medicine, 29(21), 2169-2179.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryApprox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Calculation for Two Co-Primary Binary Endpoints (Approximate) ‚Äî power2BinaryApprox","text":"","code":"# Power calculation using asymptotic normal method power2BinaryApprox(   n1 = 200,   n2 = 100,   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.7,   rho2 = 0.7,   alpha = 0.025,   Test = 'AN' ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 200 #>              n2 = 100 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.7, 0.7 #>           alpha = 0.025 #>            Test = AN #>          power1 = 0.91929 #>          power2 = 0.949617 #>  powerCoprimary = 0.894946 #>   # Power calculation with continuity correction power2BinaryApprox(   n1 = 200,   n2 = 100,   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.7,   rho2 = 0.7,   alpha = 0.025,   Test = 'ANc' ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 200 #>              n2 = 100 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.7, 0.7 #>           alpha = 0.025 #>            Test = ANc #>          power1 = 0.898088 #>          power2 = 0.933117 #>  powerCoprimary = 0.867311 #>   # Power calculation using arcsine method power2BinaryApprox(   n1 = 150,   n2 = 150,   p11 = 0.6,   p12 = 0.5,   p21 = 0.4,   p22 = 0.3,   rho1 = 0.5,   rho2 = 0.5,   alpha = 0.025,   Test = 'AS' ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 150 #>              n2 = 150 #>     p (group 1) = 0.6, 0.5 #>     p (group 2) = 0.4, 0.3 #>             rho = 0.5, 0.5 #>           alpha = 0.025 #>            Test = AS #>          power1 = 0.936701 #>          power2 = 0.945629 #>  powerCoprimary = 0.897574 #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":null,"dir":"Reference","previous_headings":"","what":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"Calculates exact power two-arm superiority trial two co-primary binary endpoints using bivariate binomial distribution, described Homma Yoshida (2025).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"","code":"power2BinaryExact(n1, n2, p11, p12, p21, p22, rho1, rho2, alpha, Test)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"n1 Sample size group 1 (test group) n2 Sample size group 2 (control group) p11 True probability responders group 1 first outcome (0 < p11 < 1) p12 True probability responders group 1 second outcome (0 < p12 < 1) p21 True probability responders group 2 first outcome (0 < p21 < 1) p22 True probability responders group 2 second outcome (0 < p22 < 1) rho1 Correlation two outcomes group 1 rho2 Correlation two outcomes group 2 alpha One-sided significance level (typically 0.025 0.05) Test Statistical testing method. One : \"Chisq\": One-sided Pearson chi-squared test \"Fisher\": Fisher exact test \"Fisher-midP\": Fisher mid-p test \"Z-pool\": Z-pooled exact unconditional test \"Boschloo\": Boschloo exact unconditional test","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"data frame following columns: n1 Sample size group 1 n2 Sample size group 2 p11, p12, p21, p22 Response probabilities rho1, rho2 Correlations alpha One-sided significance level Test Testing method used power1 Power first endpoint alone power2 Power second endpoint alone powerCoprimary Exact power co-primary endpoints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"function calculates exact power using equation (9) Homma Yoshida (2025): $$power_A(\\theta) = \\sum_{(a_{1,1},a_{2,1})\\\\mathcal{}_1}       \\sum_{(a_{1,2},a_{2,2})\\\\mathcal{}_2} f(a_{1,1}|N_1,p_{1,1}) \\times       f(a_{2,1}|N_2,p_{2,1}) \\times g(a_{1,2}|a_{1,1},N_1,p_{1,1},p_{1,2},\\gamma_1)       \\times g(a_{2,2}|a_{2,1},N_2,p_{2,1},p_{2,2},\\gamma_2)$$ \\(\\mathcal{}_k\\) rejection region endpoint k, \\((Y_{j,1}, Y_{j,2}) \\sim BiBin(N_j, p_{j,1}, p_{j,2}, \\gamma_j)\\) follows bivariate binomial distribution. correlation bounds automatically checked using corrbound2Binary.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2BinaryExact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exact Power Calculation for Two Co-Primary Binary Endpoints ‚Äî power2BinaryExact","text":"","code":"# Exact power calculation using Boschloo test power2BinaryExact(   n1 = 100,   n2 = 50,   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.7,   rho2 = 0.7,   alpha = 0.025,   Test = 'Boschloo' ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 100 #>              n2 = 50 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.7, 0.7 #>           alpha = 0.025 #>            Test = Boschloo #>          power1 = 0.651316 #>          power2 = 0.70332 #>  powerCoprimary = 0.563055 #>   # Exact power with Fisher exact test power2BinaryExact(   n1 = 80,   n2 = 80,   p11 = 0.6,   p12 = 0.5,   p21 = 0.4,   p22 = 0.3,   rho1 = 0.5,   rho2 = 0.5,   alpha = 0.025,   Test = 'Fisher' ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 80 #>              n2 = 80 #>     p (group 1) = 0.6, 0.5 #>     p (group 2) = 0.4, 0.3 #>             rho = 0.5, 0.5 #>           alpha = 0.025 #>            Test = Fisher #>          power1 = 0.658351 #>          power2 = 0.677271 #>  powerCoprimary = 0.517687 #>   # \\donttest{ # Larger sample sizes (computationally intensive) power2BinaryExact(   n1 = 200,   n2 = 100,   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.6,   rho2 = 0.6,   alpha = 0.025,   Test = 'Chisq' ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 200 #>              n2 = 100 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.6, 0.6 #>           alpha = 0.025 #>            Test = Chisq #>          power1 = 0.9219 #>          power2 = 0.949665 #>  powerCoprimary = 0.892527 #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"Calculates power two-arm superiority trial two co-primary continuous endpoints, described Sozu et al. (2011).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"","code":"power2Continuous(   n1,   n2,   delta1,   delta2,   sd1,   sd2,   rho,   alpha,   known_var = TRUE,   nMC = 10000 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"n1 Sample size group 1 (test group) n2 Sample size group 2 (control group) delta1 Mean difference first endpoint delta2 Mean difference second endpoint sd1 Common standard deviation first endpoint sd2 Common standard deviation second endpoint rho Common correlation two outcomes alpha One-sided significance level (typically 0.025 0.05) known_var Logical value indicating whether variance known (TRUE) unknown (FALSE). TRUE, power calculated analytically; otherwise, Monte Carlo simulation used unknown variance nMC Number Monte Carlo simulations known_var = FALSE (default 10000)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"data frame following columns: n1 Sample size group 1 n2 Sample size group 2 delta1 Mean difference endpoint 1 delta2 Mean difference endpoint 2 sd1 Standard deviation endpoint 1 sd2 Standard deviation endpoint 2 rho Correlation endpoints alpha One-sided significance level known_var Variance assumption nMC Number Monte Carlo simulations (NA known_var = TRUE) power1 Power first endpoint alone power2 Power second endpoint alone powerCoprimary Power co-primary endpoints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"known variance, power calculated using bivariate normal distribution described Sozu et al. (2011). test statistics : $$Z_k = \\frac{\\delta_k}{\\sigma_k \\sqrt{1/n_1 + 1/n_2}}$$ k = 1, 2. co-primary power : $$1 - \\beta = \\Phi_2\\left(-z_{1-\\alpha} + Z_1, -z_{1-\\alpha} + Z_2 \\mid \\rho\\right)$$ \\(\\Phi_2\\) cumulative distribution function bivariate standard normal distribution. unknown variance, Monte Carlo simulation used Wishart-distributed variance-covariance matrices account variance estimation uncertainty, following equation (6) Sozu et al. (2011): $$\\text{Power} = E_W\\left[\\Phi_2(-c_1^*\\sqrt{w_{11}}, -c_2^*\\sqrt{w_{22}} | \\rho)\\right]$$ \\(c_k^* = t_{\\alpha,\\nu}\\sqrt{\\frac{1}{\\nu}} - \\frac{Z_k}{\\sqrt{w_{kk}}}\\) \\(W\\) follows Wishart distribution \\(\\nu = n_1 + n_2 - 2\\) degrees freedom.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination superiority clinical trials multiple co-primary correlated endpoints. Journal Biopharmaceutical Statistics, 21(4), 650-668.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2Continuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Calculation for Two Co-Primary Continuous Endpoints ‚Äî power2Continuous","text":"","code":"# Example parameters for comparison across methods n1_ex <- 100 n2_ex <- 100 delta1_ex <- 0.5 delta2_ex <- 0.5 sd1_ex <- 1 sd2_ex <- 1 rho_ex <- 0.3 alpha_ex <- 0.025  # Power calculation with known variance power2Continuous(   n1 = n1_ex,   n2 = n2_ex,   delta1 = delta1_ex,   delta2 = delta2_ex,   sd1 = sd1_ex,   sd2 = sd2_ex,   rho = rho_ex,   alpha = alpha_ex,   known_var = TRUE ) #>  #> Power calculation for two continuous co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.3 #>           alpha = 0.025 #>       known_var = TRUE #>          power1 = 0.942438 #>          power2 = 0.942438 #>  powerCoprimary = 0.893807 #>   # \\donttest{ # Power calculation with unknown variance (Monte Carlo) power2Continuous(   n1 = n1_ex,   n2 = n2_ex,   delta1 = delta1_ex,   delta2 = delta2_ex,   sd1 = sd1_ex,   sd2 = sd2_ex,   rho = rho_ex,   alpha = alpha_ex,   known_var = FALSE,   nMC = 10000 ) #>  #> Power calculation for two continuous co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.3 #>           alpha = 0.025 #>       known_var = FALSE #>             nMC = 10000 #>          power1 = 0.940427 #>          power2 = 0.940427 #>  powerCoprimary = 0.890195 #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"Calculates power two-arm superiority trial two co-primary endpoints one continuous one binary, described Sozu et al. (2012).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"","code":"power2MixedContinuousBinary(   n1,   n2,   delta,   sd,   p1,   p2,   rho,   alpha,   Test,   nMC = 10000 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"n1 Sample size group 1 (test group) n2 Sample size group 2 (control group) delta Mean difference continuous endpoint (group 1 - group 2) sd Common standard deviation continuous endpoint p1 Probability response group 1 binary endpoint (0 < p1 < 1) p2 Probability response group 2 binary endpoint (0 < p2 < 1) rho Biserial correlation latent continuous variable underlying binary endpoint observed continuous endpoint alpha One-sided significance level (typically 0.025 0.05) Test Statistical testing method binary endpoint. One : \"\": Asymptotic normal method without continuity correction \"ANc\": Asymptotic normal method continuity correction \"\": Arcsine method without continuity correction \"ASc\": Arcsine method continuity correction \"Fisher\": Fisher's exact test (Monte Carlo simulation required) nMC Number Monte Carlo replications Test = \"Fisher\" (default: 10000)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"data frame following columns: n1 Sample size group 1 n2 Sample size group 2 delta Mean difference continuous endpoint sd Standard deviation continuous endpoint p1 Response probability group 1 binary endpoint p2 Response probability group 2 binary endpoint rho Biserial correlation alpha One-sided significance level Test Testing method used binary endpoint powerCont Power continuous endpoint alone powerBin Power binary endpoint alone powerCoprimary Power co-primary endpoints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"function implements power calculation mixed endpoints (one continuous one binary) described Sozu et al. (2012). method assumes binary variable derived latent continuous variable via dichotomization threshold point. Fisher's exact test, Monte Carlo simulation used exact calculation computationally intensive. continuous endpoint analyzed using t-test, binary endpoint uses Fisher's exact test. asymptotic methods (, ANc, , ASc), analytical formulas used based bivariate normal approximation. correlation test statistics depends biserial correlation rho specific testing method. Biserial Correlation: biserial correlation rho represents correlation latent continuous variable underlying binary endpoint observed continuous endpoint. point-biserial correlation observed data.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination clinical trials multiple co-primary endpoints including mixed continuous binary variables. Biometrical Journal, 54(5), 716-729.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedContinuousBinary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Calculation for Two Co-Primary Mixed Endpoints ‚Äî power2MixedContinuousBinary","text":"","code":"# Power calculation using asymptotic normal method power2MixedContinuousBinary(   n1 = 100,   n2 = 100,   delta = 0.5,   sd = 1,   p1 = 0.6,   p2 = 0.4,   rho = 0.5,   alpha = 0.025,   Test = 'AN' ) #>  #> Power calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>           alpha = 0.025 #>            Test = AN #>       powerCont = 0.942438 #>        powerBin = 0.812291 #>  powerCoprimary = 0.781111 #>   # \\donttest{ # Power calculation with Fisher's exact test (computationally intensive) power2MixedContinuousBinary(   n1 = 50,   n2 = 50,   delta = 0.5,   sd = 1,   p1 = 0.6,   p2 = 0.4,   rho = 0.5,   alpha = 0.025,   Test = 'Fisher',   nMC = 5000 ) #>  #> Power calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 50 #>              n2 = 50 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>           alpha = 0.025 #>            Test = Fisher #>       powerCont = 0.705414 #>        powerBin = 0.440109 #>  powerCoprimary = 0.364131 #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"Calculates power two-arm superiority trial one overdispersed count co-primary endpoint one continuous co-primary endpoint, described Homma Yoshida (2024).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"","code":"power2MixedCountContinuous(   n1,   n2,   r1,   r2,   nu,   t,   mu1,   mu2,   sd,   rho1,   rho2,   alpha )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"n1 Sample size group 1 (test group) n2 Sample size group 2 (control group) r1 Mean rate (events per unit time) treatment group (count endpoint) r2 Mean rate (events per unit time) control group (count endpoint) nu Common dispersion parameter negative binomial distribution (nu > 0) t Common follow-time period mu1 Mean group 1 (continuous endpoint) mu2 Mean group 2 (continuous endpoint) sd Common standard deviation continuous endpoint rho1 Correlation count continuous outcomes treatment group rho2 Correlation count continuous outcomes control group alpha One-sided significance level (typically 0.025 0.05)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"data frame following columns: n1 Sample size group 1 n2 Sample size group 2 r1 Mean rate group 1 count endpoint r2 Mean rate group 2 count endpoint nu Dispersion parameter t Follow-time mu1 Mean group 1 continuous endpoint mu2 Mean group 2 continuous endpoint sd Standard deviation continuous endpoint rho1 Correlation group 1 rho2 Correlation group 2 alpha One-sided significance level powerCount Power count endpoint alone powerCont Power continuous endpoint alone powerCoprimary Power co-primary endpoints","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"test statistics (equation 7 Homma Yoshida 2024): $$Z_1 = \\frac{\\hat{\\beta}_1}{\\sqrt{Var(\\hat{\\beta}_1)}}, \\quad       Z_2 = \\frac{\\hat{\\delta}}{\\sigma\\sqrt{(1+\\kappa)/(\\kappa n_0)}}$$ joint distribution (Z1, Z2) follows asymptotic bivariate normal distribution correlation gamma (equation 11): $$\\gamma = \\sum_{j=0,1} \\frac{n_0 \\rho_j \\sqrt{1+\\lambda_j/\\nu}}       {n_j \\sqrt{\\lambda_j V_a} \\sqrt{(1+\\kappa)/\\kappa}}$$ \\(\\lambda_j = r_j \\times t\\). correlation bounds automatically checked using corrbound2MixedCountContinuous.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation clinical trials two co-primary endpoints including overdispersed count continuous outcomes. Pharmaceutical Statistics, 23(1), 46-59.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/power2MixedCountContinuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Power Calculation for Two Co-Primary Endpoints (Count and Continuous) ‚Äî power2MixedCountContinuous","text":"","code":"# Power calculation with moderate correlation power2MixedCountContinuous(   n1 = 300,   n2 = 300,   r1 = 1.0,   r2 = 1.25,   nu = 0.8,   t = 1,   mu1 = -50,   mu2 = 0,   sd = 250,   rho1 = 0.5,   rho2 = 0.5,   alpha = 0.025 ) #>  #> Power calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 300 #>              n2 = 300 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.5, 0.5 #>           alpha = 0.025 #>       powerCont = 0.687765 #>      powerCount = 0.461715 #>  powerCoprimary = 0.389192 #>   # Power calculation with no correlation power2MixedCountContinuous(   n1 = 350,   n2 = 350,   r1 = 1.0,   r2 = 1.5,   nu = 1,   t = 1,   mu1 = -40,   mu2 = 0,   sd = 200,   rho1 = 0,   rho2 = 0,   alpha = 0.025 ) #>  #> Power calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 350 #>              n2 = 350 #>              sd = 200 #>            rate = 1, 1.5 #>              nu = 1 #>               t = 1 #>              mu = -40, 0 #>             rho = 0, 0 #>           alpha = 0.025 #>       powerCont = 0.753576 #>      powerCount = 0.977329 #>  powerCoprimary = 0.736492 #>   # Unbalanced design power2MixedCountContinuous(   n1 = 400,   n2 = 200,   r1 = 1,   r2 = 1.25,   nu = 1,   t = 1,   mu1 = -50,   mu2 = 0,   sd = 250,   rho1 = 0.6,   rho2 = 0.6,   alpha = 0.025 ) #>  #> Power calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 400 #>              n2 = 200 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 1 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.6, 0.6 #>           alpha = 0.025 #>       powerCont = 0.636619 #>      powerCount = 0.470483 #>  powerCoprimary = 0.393625 #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for twoCoprimary Objects ‚Äî print.twoCoprimary","title":"Print Method for twoCoprimary Objects ‚Äî print.twoCoprimary","text":"Provides clean, formatted display sample size power calculation results twoCoprimary package.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for twoCoprimary Objects ‚Äî print.twoCoprimary","text":"","code":"# S3 method for class 'twoCoprimary' print(x, ...)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for twoCoprimary Objects ‚Äî print.twoCoprimary","text":"x object class \"twoCoprimary\" ... Additional arguments (currently unused)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for twoCoprimary Objects ‚Äî print.twoCoprimary","text":"Invisibly returns original object","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Method for twoCoprimary Objects ‚Äî print.twoCoprimary","text":"print method provides formatted output displays key parameters results easy--read format. specific format adapts type calculation (sample size vs power) type endpoints involved.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Method for twoCoprimary_table Objects ‚Äî print.twoCoprimary_table","title":"Print Method for twoCoprimary_table Objects ‚Äî print.twoCoprimary_table","text":"Provides clean display design comparison tables","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Method for twoCoprimary_table Objects ‚Äî print.twoCoprimary_table","text":"","code":"# S3 method for class 'twoCoprimary_table' print(x, ...)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Method for twoCoprimary_table Objects ‚Äî print.twoCoprimary_table","text":"x object class \"twoCoprimary_table\" ... Additional arguments passed print.data.frame","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/print.twoCoprimary_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Method for twoCoprimary_table Objects ‚Äî print.twoCoprimary_table","text":"Invisibly returns original object","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"Calculates rejection region two-arm trials single binary endpoint using various exact statistical tests, described Homma Yoshida (2025).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"","code":"rr1Binary(n1, n2, alpha, Test)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"n1 Sample size group 1 (test group) n2 Sample size group 2 (control group) alpha One-sided significance level (typically 0.025) Test Type statistical test. One : \"Chisq\": One-sided Pearson chi-squared test \"Fisher\": Fisher exact test \"Fisher-midP\": Fisher mid-p test \"Z-pool\": Z-pooled exact unconditional test \"Boschloo\": Boschloo exact unconditional test","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"logical matrix dimensions (n1+1) x (n2+1), TRUE indicates rejection null hypothesis. Rows correspond number responders group 1 (0 n1), columns correspond number responders group 2 (0 n2).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"function computes rejection region five different one-sided tests: Chi-squared test: Uses asymptotic normal approximation chi-squared statistic. Fisher exact test: Uses hypergeometric distribution calculate exact p-values conditional total number successes. Fisher mid-p test: Modification Fisher's exact test adds half probability observed outcome reduce conservatism. Z-pooled test: Exact unconditional test maximizes p-values possible values nuisance parameter (common success probability H0). Boschloo test: Exact unconditional test similar Z-pooled based Fisher's exact p-values, maximizing nuisance parameter.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/rr1Binary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rejection Region for Two-Arm Trials with a Single Binary Endpoint ‚Äî rr1Binary","text":"","code":"# Simple example with small sample sizes n1 <- 5 n2 <- 5 alpha <- 0.025 RR <- rr1Binary(n1, n2, alpha, Test = 'Chisq') print(dim(RR))  # Should be (6, 6) #> [1] 6 6  # Fisher exact test RR_fisher <- rr1Binary(n1 = 10, n2 = 10, alpha = 0.025, Test = 'Fisher')  # \\donttest{ # More computationally intensive: Boschloo test n1 <- 20 n2 <- 10 alpha <- 0.025 RR <- rr1Binary(n1, n2, alpha, Test = 'Boschloo') print(RR) #>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] #>  [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [7,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [8,]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #>  [9,]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [10,]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [11,]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [12,]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13,]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [14,]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [15,]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [16,]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [17,]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE #> [18,]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE #> [19,]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE #> [20,]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE #> [21,]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"Calculates required sample size two-arm superiority trial single binary endpoint using various statistical testing methods.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"","code":"ss1BinaryApprox(p1, p2, r, alpha, beta, Test = \"AN\")"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"p1 True probability responders group 1 (0 < p1 < 1) p2 True probability responders group 2 (0 < p2 < 1) r Allocation ratio group 1 group 2 (group 1:group 2 = r:1, r > 0) alpha One-sided significance level (typically 0.025) beta Target type II error rate (typically 0.1 0.2) Test Statistical testing method. One : \"\": Asymptotic normal method without continuity correction (default) \"ANc\": Asymptotic normal method continuity correction \"\": Arcsine transformation without continuity correction \"ASc\": Arcsine transformation continuity correction \"Fisher\": Fisher's exact test iterative sample size determination","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"data frame following columns: p1 Probability responders group 1 p2 Probability responders group 2 r Allocation ratio alpha One-sided significance level beta Type II error rate Test Testing method used n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"function implements sample size calculations single binary endpoint trials using five different methods. Important: function designed single binary endpoint. co-primary endpoints, use ss2BinaryApprox (approximate methods) ss2BinaryExact (exact methods). Notation: r = n1/n2: allocation ratio (group 1 group 2) kappa = 1/r = n2/n1: inverse allocation ratio p1, p2: response probabilities theta1 = 1 - p1, theta2 = 1 - p2: non-response probabilities delta = p1 - p2: treatment effect (Asymptotic Normal) Method: Uses standard normal approximation pooled variance H0: $$n_2 = \\left\\lceil \\frac{(1 + \\kappa)}{(\\pi_1 - \\pi_2)^2}       \\left(z_{1-\\alpha} \\sqrt{\\bar{\\pi}(1-\\bar{\\pi})} +       z_{1-\\beta} \\sqrt{\\kappa\\pi_1\\theta_1 + \\pi_2\\theta_2}\\right)^2 / \\kappa \\right\\rceil$$ \\(\\bar{\\pi} = (r\\pi_1 + \\pi_2)/(1 + r)\\) pooled proportion. ANc Method: Adds continuity correction method. Uses iterative calculation correction term depends sample size. Converges difference successive iterations less equal 1. (Arcsine) Method: Uses variance-stabilizing arcsine transformation: $$n_2 = \\left\\lceil \\frac{(z_{1-\\alpha} + z_{1-\\beta})^2}{4(\\sin^{-1}\\sqrt{\\pi_1} - \\sin^{-1}\\sqrt{\\pi_2})^2} \\times \\frac{1 + \\kappa}{\\kappa} \\right\\rceil$$ ASc Method: Applies continuity correction arcsine method. Uses iterative procedure convergence criterion. Fisher Method: Fisher's exact test closed-form sample size formula. method: Starts method's sample size initial value Incrementally increases n2 1 Calculates exact power using hypergeometric distribution Stops power greater equal 1 - beta Note: Due saw-tooth nature exact power (power increase monotonically sample size), sequential search approach used. incremental approach ensures minimum sample size achieves target power.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2010). Sample size determination clinical trials multiple co-primary binary endpoints. Statistics Medicine, 29(21), 2169-2179.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1BinaryApprox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for a Single Binary Endpoint ‚Äî ss1BinaryApprox","text":"","code":"# Balanced design with 1:1 allocation (AN method) ss1BinaryApprox(p1 = 0.6, p2 = 0.4, r = 1, alpha = 0.025, beta = 0.1, Test = \"AN\") #>  #> Sample size calculation for single binary endpoint #>  #>              n1 = 130 #>              n2 = 130 #>               N = 260 #>               p = 0.6, 0.4 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = AN #>   # Unbalanced design with 2:1 allocation (ANc method) ss1BinaryApprox(p1 = 0.5, p2 = 0.3, r = 2, alpha = 0.025, beta = 0.2, Test = \"ANc\") #>  #> Sample size calculation for single binary endpoint #>  #>              n1 = 156 #>              n2 = 78 #>               N = 234 #>               p = 0.5, 0.3 #>      allocation = 2 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = ANc #>   # Arcsine transformation method ss1BinaryApprox(p1 = 0.55, p2 = 0.35, r = 1, alpha = 0.025, beta = 0.1, Test = \"AS\") #>  #> Sample size calculation for single binary endpoint #>  #>              n1 = 129 #>              n2 = 129 #>               N = 258 #>               p = 0.55, 0.35 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = AS #>   # Arcsine with continuity correction ss1BinaryApprox(p1 = 0.65, p2 = 0.45, r = 1, alpha = 0.025, beta = 0.1, Test = \"ASc\") #>  #> Sample size calculation for single binary endpoint #>  #>              n1 = 121 #>              n2 = 121 #>               N = 242 #>               p = 0.65, 0.45 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = ASc #>   # Fisher's exact test ss1BinaryApprox(p1 = 0.6, p2 = 0.4, r = 2, alpha = 0.025, beta = 0.1, Test = \"Fisher\") #>  #> Sample size calculation for single binary endpoint #>  #>              n1 = 206 #>              n2 = 103 #>               N = 309 #>               p = 0.6, 0.4 #>      allocation = 2 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = Fisher #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Continuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","title":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","text":"Calculates required sample size two-arm superiority trial single continuous endpoint using standard formula normally distributed outcomes.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Continuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","text":"","code":"ss1Continuous(delta, sd, r, alpha, beta)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Continuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","text":"delta Mean difference treatment groups (treatment effect) sd Common standard deviation continuous endpoint r Allocation ratio group 1 group 2 (group 1:group 2 = r:1, r > 0) alpha One-sided significance level (typically 0.025 0.05) beta Target type II error rate (typically 0.1 0.2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Continuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","text":"data frame following columns: delta Mean difference (treatment effect) sd Common standard deviation r Allocation ratio alpha One-sided significance level beta Type II error rate n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Continuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","text":"required sample size group 2 calculated using standard formula: $$n_2 = \\left\\lceil \\frac{(1 + 1/r) \\sigma^2 (z_\\alpha + z_\\beta)^2}{\\delta^2} \\right\\rceil$$ \\(z_\\alpha\\) \\(z_\\beta\\) quantiles standard normal distribution corresponding one-sided significance level \\(\\alpha\\) type II error rate \\(\\beta\\), respectively. sample size group 1 \\(n_1 = \\lceil r \\times n_2 \\rceil\\).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Continuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for a Single Continuous Endpoint ‚Äî ss1Continuous","text":"","code":"# Balanced design with 1:1 allocation ss1Continuous(delta = 0.4, sd = 1, r = 1, alpha = 0.025, beta = 0.1) #>  #> Sample size calculation for single continuous endpoint #>  #>              n1 = 132 #>              n2 = 132 #>               N = 264 #>           delta = 0.4 #>              sd = 1 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>   # Unbalanced design with 2:1 allocation ss1Continuous(delta = 0.5, sd = 1.2, r = 2, alpha = 0.025, beta = 0.2) #>  #> Sample size calculation for single continuous endpoint #>  #>              n1 = 136 #>              n2 = 68 #>               N = 204 #>           delta = 0.5 #>              sd = 1.2 #>      allocation = 2 #>           alpha = 0.025 #>            beta = 0.2 #>   # Large treatment effect ss1Continuous(delta = 0.8, sd = 1, r = 1, alpha = 0.025, beta = 0.1) #>  #> Sample size calculation for single continuous endpoint #>  #>              n1 = 33 #>              n2 = 33 #>               N = 66 #>           delta = 0.8 #>              sd = 1 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"Calculates required sample size two-arm superiority trial single overdispersed count endpoint following negative binomial distribution, described Homma Yoshida (2024).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"","code":"ss1Count(r1, r2, nu, t, r, alpha, beta)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"r1 Mean rate (events per unit time) treatment group r2 Mean rate (events per unit time) control group nu Common dispersion parameter negative binomial distribution (nu > 0) t Common follow-time period r Allocation ratio (treatment:control = r:1, r > 0) alpha One-sided significance level (typically 0.025 0.05) beta Target type II error rate (typically 0.1 0.2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"data frame following columns: r1 Mean rate treatment group r2 Mean rate control group nu Dispersion parameter t Follow-time r Allocation ratio alpha One-sided significance level beta Type II error rate n1 Required sample size treatment group n2 Required sample size control group N Total sample size (n2 + n1)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"test statistic negative binomial rate ratio : $$Z_1 = \\frac{\\hat{\\beta}_1}{\\sqrt{Var(\\hat{\\beta}_1)}}$$ \\(\\hat{\\beta}_1 = \\log(\\bar{Y}_1) - \\log(\\bar{Y}_2)\\) variance : $$Var(\\hat{\\beta}_1) = \\frac{1}{n_2}\\left[\\frac{1}{t}\\left(\\frac{1}{r_2} +       \\frac{1}{r \\cdot r_1}\\right) + \\frac{1+r}{\\nu \\cdot r}\\right]$$ equation (8) Homma Yoshida (2024).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation clinical trials two co-primary endpoints including overdispersed count continuous outcomes. Pharmaceutical Statistics, 23(1), 46-59.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss1Count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for a Single Count Endpoint (Negative Binomial) ‚Äî ss1Count","text":"","code":"# Sample size for count endpoint with nu = 0.8 ss1Count(r1 = 1.0, r2 = 1.25, nu = 0.8, t = 1, r = 1,          alpha = 0.025, beta = 0.1) #>  #> Sample size calculation for single count endpoint #>  #>              n1 = 908 #>              n2 = 908 #>               N = 1816 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>   # Unbalanced design with 2:1 allocation ss1Count(r1 = 1.0, r2 = 1.5, nu = 1.0, t = 1, r = 2,          alpha = 0.025, beta = 0.2) #>  #> Sample size calculation for single count endpoint #>  #>              n1 = 256 #>              n2 = 128 #>               N = 384 #>            rate = 1, 1.5 #>              nu = 1 #>               t = 1 #>      allocation = 2 #>           alpha = 0.025 #>            beta = 0.2 #>   # Higher dispersion ss1Count(r1 = 1.5, r2 = 2.0, nu = 3.0, t = 1, r = 1,          alpha = 0.025, beta = 0.1) #>  #> Sample size calculation for single count endpoint #>  #>              n1 = 233 #>              n2 = 233 #>               N = 466 #>            rate = 1.5, 2 #>              nu = 3 #>               t = 1 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"Calculates required sample size two-arm superiority trial two co-primary binary endpoints using asymptotic normal approximation arcsine transformation, described Sozu et al. (2010).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"","code":"ss2BinaryApprox(p11, p12, p21, p22, rho1, rho2, r, alpha, beta, Test)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"p11 True probability responders group 1 first outcome (0 < p11 < 1) p12 True probability responders group 1 second outcome (0 < p12 < 1) p21 True probability responders group 2 first outcome (0 < p21 < 1) p22 True probability responders group 2 second outcome (0 < p22 < 1) rho1 Correlation two outcomes group 1 rho2 Correlation two outcomes group 2 r Allocation ratio group 1 group 2 (group 1:group 2 = r:1, r > 0) alpha One-sided significance level (typically 0.025 0.05) beta Target type II error rate (typically 0.1 0.2) Test Statistical testing method. One : \"\": Asymptotic normal method without continuity correction \"ANc\": Asymptotic normal method continuity correction \"\": Arcsine method without continuity correction \"ASc\": Arcsine method continuity correction","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"data frame following columns: p11, p12, p21, p22 Response probabilities rho1, rho2 Correlations r Allocation ratio alpha One-sided significance level beta Type II error rate Test Testing method used n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"function uses sequential search algorithm (Homma Yoshida 2025, Algorithm 1) find minimum sample size: Step 1: Initialize sample sizes single endpoint formulas. Step 2: Use sequential search: Calculate power initial sample size power >= target: decrease n2 power < target, add 1 back power < target: increase n2 power >= target Step 3: Return final sample sizes. asymptotic normal () arcsine () methods use normal approximation without continuity correction. small sample sizes extreme probabilities, consider using exact methods via ss2BinaryExact.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2010). Sample size determination clinical trials multiple co-primary binary endpoints. Statistics Medicine, 29(21), 2169-2179. Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryApprox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for Two Co-Primary Binary Endpoints (Asymptotic Approximation) ‚Äî ss2BinaryApprox","text":"","code":"# Sample size calculation using asymptotic normal method ss2BinaryApprox(   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.5,   rho2 = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = 'AN' ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 109 #>              n2 = 109 #>               N = 218 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN #>   # With continuity correction ss2BinaryApprox(   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.5,   rho2 = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = 'ANc' ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 119 #>              n2 = 119 #>               N = 238 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = ANc #>   # Using arcsine transformation ss2BinaryApprox(   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.5,   rho2 = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = 'AS' ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 109 #>              n2 = 109 #>               N = 218 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AS #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":null,"dir":"Reference","previous_headings":"","what":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"Calculates required sample size two-arm superiority trial two co-primary binary endpoints using exact methods, described Homma Yoshida (2025).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"","code":"ss2BinaryExact(p11, p12, p21, p22, rho1, rho2, r, alpha, beta, Test)"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"p11 True probability responders group 1 first outcome (0 < p11 < 1) p12 True probability responders group 1 second outcome (0 < p12 < 1) p21 True probability responders group 2 first outcome (0 < p21 < 1) p22 True probability responders group 2 second outcome (0 < p22 < 1) rho1 Correlation two outcomes group 1 rho2 Correlation two outcomes group 2 r Allocation ratio group 1 group 2 (group 1:group 2 = r:1, r > 0) alpha One-sided significance level (typically 0.025 0.05) beta Target type II error rate (typically 0.1 0.2) Test Statistical testing method. One : \"Chisq\": One-sided Pearson chi-squared test \"Fisher\": Fisher exact test \"Fisher-midP\": Fisher mid-p test \"Z-pool\": Z-pooled exact unconditional test \"Boschloo\": Boschloo exact unconditional test","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"data frame following columns: p11, p12, p21, p22 Response probabilities rho1, rho2 Correlations r Allocation ratio alpha One-sided significance level beta Type II error rate Test Testing method used n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"function uses sequential search algorithm find minimum sample size achieves target power: Step 1: Initialize sample size approximate method (). provides good starting point exact calculation. Step 2: Use sequential search algorithm (Homma Yoshida 2025, Algorithm 1): Calculate power initial sample size power >= target: decrease n2 power < target, add 1 back power < target: increase n2 power >= target Step 3: Return final sample sizes. Note: Due saw-tooth nature exact power (power increase monotonically sample size), sequential search ensures minimum sample size achieves target power.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2BinaryExact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exact Sample Size Calculation for Two Co-Primary Binary Endpoints ‚Äî ss2BinaryExact","text":"","code":"# Quick example with Chi-squared test (faster) ss2BinaryExact(   p11 = 0.6,   p12 = 0.5,   p21 = 0.4,   p22 = 0.3,   rho1 = 0.3,   rho2 = 0.3,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"Chisq\" ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 123 #>              n2 = 123 #>               N = 246 #>     p (group 1) = 0.6, 0.5 #>     p (group 2) = 0.4, 0.3 #>             rho = 0.3, 0.3 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = Chisq #>   # \\donttest{ # More computationally intensive example with Fisher test ss2BinaryExact(   p11 = 0.5,   p12 = 0.4,   p21 = 0.3,   p22 = 0.2,   rho1 = 0.5,   rho2 = 0.5,   r = 1,   alpha = 0.025,   beta = 0.2,   Test = \"Fisher\" ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 117 #>              n2 = 117 #>               N = 234 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = Fisher #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"Calculates required sample size two-arm superiority trial two co-primary continuous endpoints using sequential search algorithm.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"","code":"ss2Continuous(   delta1,   delta2,   sd1,   sd2,   rho,   r,   alpha,   beta,   known_var = TRUE,   nMC = 10000 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"delta1 Mean difference first endpoint delta2 Mean difference second endpoint sd1 Common standard deviation first endpoint sd2 Common standard deviation second endpoint rho Common correlation two outcomes r Allocation ratio group 1 group 2 (group 1:group 2 = r:1, r > 0) alpha One-sided significance level (typically 0.025 0.05) beta Target type II error rate (typically 0.1 0.2) known_var Logical value indicating whether variance known (TRUE) unknown (FALSE). TRUE, power calculated analytically; FALSE, Monte Carlo simulation used nMC Number Monte Carlo simulations known_var = FALSE (default 10000)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"data frame following columns: delta1, delta2 Mean differences sd1, sd2 Standard deviations rho Correlation r Allocation ratio alpha One-sided significance level beta Type II error rate known_var Variance assumption nMC Number Monte Carlo simulations (NA known_var = TRUE) n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"function uses sequential search algorithm (Homma Yoshida 2025, Algorithm 1) known unknown variance cases: Step 1: Initialize sample sizes single endpoint formulas. Step 2: Use sequential search: Calculate power initial sample size power >= target: decrease n2 power < target, add 1 back power < target: increase n2 power >= target Step 3: Return final sample sizes. known variance, standardized test statistics : $$Z_k = \\frac{\\delta_k}{\\sigma_k \\sqrt{1/n_1 + 1/n_2}}$$ unknown variance, t-statistics \\(\\nu = n_1 + n_2 - 2\\) degrees freedom used, power calculated using Monte Carlo simulation following Sozu et al. (2011).","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination superiority clinical trials multiple co-primary correlated endpoints. Journal Biopharmaceutical Statistics, 21(4), 650-668. Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2Continuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for Two Co-Primary Continuous Endpoints (Approximate) ‚Äî ss2Continuous","text":"","code":"# Sample size calculation with known variance ss2Continuous(   delta1 = 0.2,   delta2 = 0.2,   sd1 = 1,   sd2 = 1,   rho = 0.5,   r = 1,   alpha = 0.025,   beta = 0.1,   known_var = TRUE ) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 626 #>              n2 = 626 #>               N = 1252 #>           delta = 0.2, 0.2 #>              sd = 1, 1 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>       known_var = TRUE #>   # Sample size calculation with unequal allocation ss2Continuous(   delta1 = 0.3,   delta2 = 0.25,   sd1 = 1,   sd2 = 1,   rho = 0.3,   r = 2,   alpha = 0.025,   beta = 0.2,   known_var = TRUE ) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 418 #>              n2 = 209 #>               N = 627 #>           delta = 0.3, 0.25 #>              sd = 1, 1 #>             rho = 0.3 #>      allocation = 2 #>           alpha = 0.025 #>            beta = 0.2 #>       known_var = TRUE #>   # \\donttest{ # Sample size calculation with unknown variance (uses sequential search) ss2Continuous(   delta1 = 0.5,   delta2 = 0.4,   sd1 = 1,   sd2 = 1,   rho = 0.4,   r = 1,   alpha = 0.025,   beta = 0.1,   known_var = FALSE,   nMC = 10000 ) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 138 #>              n2 = 138 #>               N = 276 #>           delta = 0.5, 0.4 #>              sd = 1, 1 #>             rho = 0.4 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>       known_var = FALSE #>             nMC = 10000 #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"Determines sample size two-arm superiority trial two co-primary endpoints one continuous one binary, achieve specified power given significance level.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"","code":"ss2MixedContinuousBinary(   delta,   sd,   p1,   p2,   rho,   r,   alpha,   beta,   Test,   nMC = 10000 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"delta Mean difference continuous endpoint (group 1 - group 2) sd Common standard deviation continuous endpoint p1 Probability response group 1 binary endpoint (0 < p1 < 1) p2 Probability response group 2 binary endpoint (0 < p2 < 1) rho Biserial correlation latent continuous variable underlying binary endpoint observed continuous endpoint r Allocation ratio n1/n2 n1 sample size group 1 alpha One-sided significance level (typically 0.025 0.05) beta Type II error rate (typically 0.1 0.2). Power = 1 - beta Test Statistical testing method binary endpoint. One : \"\": Asymptotic normal method without continuity correction \"ANc\": Asymptotic normal method continuity correction \"\": Arcsine method without continuity correction \"ASc\": Arcsine method continuity correction \"Fisher\": Fisher's exact test (uses sequential search) nMC Number Monte Carlo replications Test = \"Fisher\" (default: 10000)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"data frame following columns: delta Mean difference continuous endpoint sd Standard deviation continuous endpoint p1 Response probability group 1 binary endpoint p2 Response probability group 2 binary endpoint rho Biserial correlation r Allocation ratio alpha One-sided significance level beta Type II error rate Test Testing method used binary endpoint nMC Number Monte Carlo replications (NA Test != \"Fisher\") n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"function implements sample size calculation mixed continuous-binary co-primary endpoints following methodology Sozu et al. (2012). sequential search algorithm (Homma Yoshida 2025, Algorithm 1) used testing methods: Step 1: Initialize sample sizes single endpoint formulas. Step 2: Use sequential search: Calculate power initial sample size power >= target: decrease n2 power < target, add 1 back power < target: increase n2 power >= target Step 3: Return final sample sizes. Biserial Correlation: biserial correlation rho represents correlation latent continuous variable underlying binary endpoint observed continuous endpoint. point-biserial correlation observed data.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination clinical trials multiple co-primary endpoints including mixed continuous binary variables. Biometrical Journal, 54(5), 716-729. Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedContinuousBinary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary ‚Äî ss2MixedContinuousBinary","text":"","code":"# Sample size calculation using asymptotic normal method ss2MixedContinuousBinary(   delta = 0.5,   sd = 1,   p1 = 0.6,   p2 = 0.4,   rho = 0.5,   r = 1,   alpha = 0.025,   beta = 0.1,   Test = 'AN' ) #>  #> Sample size calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 135 #>              n2 = 135 #>               N = 270 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = AN #>   # With continuity correction ss2MixedContinuousBinary(   delta = 0.5,   sd = 1,   p1 = 0.6,   p2 = 0.4,   rho = 0.5,   r = 1,   alpha = 0.025,   beta = 0.1,   Test = 'ANc' ) #>  #> Sample size calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 143 #>              n2 = 143 #>               N = 286 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = ANc #>   # \\donttest{ # Fisher's exact test (computationally intensive) ss2MixedContinuousBinary(   delta = 0.5,   sd = 1,   p1 = 0.6,   p2 = 0.4,   rho = 0.5,   r = 1,   alpha = 0.025,   beta = 0.1,   Test = 'Fisher',   nMC = 5000 ) #>  #> Sample size calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 143 #>              n2 = 143 #>               N = 286 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.1 #>            Test = Fisher #>             nMC = 5000 #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"Determines sample size two-arm superiority trial two co-primary endpoints one count (negative binomial) one continuous (normal), achieve specified power given significance level.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"","code":"ss2MixedCountContinuous(   r1,   r2,   nu,   t,   mu1,   mu2,   sd,   r,   rho1,   rho2,   alpha,   beta )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"r1 Mean count rate group 1 count endpoint r2 Mean count rate group 2 count endpoint nu Dispersion parameter negative binomial distribution (nu > 0). Smaller values indicate greater overdispersion t Follow-time period mu1 Mean group 1 continuous endpoint mu2 Mean group 2 continuous endpoint sd Common standard deviation continuous endpoint r Allocation ratio n1/n2 n1 sample size group 1 rho1 Correlation count continuous endpoints group 1 rho2 Correlation count continuous endpoints group 2 alpha One-sided significance level (typically 0.025 0.05) beta Type II error rate (typically 0.1 0.2). Power = 1 - beta","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"data frame following columns: r1, r2 Count rates nu Dispersion parameter t Follow-time mu1, mu2 Means continuous endpoint sd Standard deviation continuous endpoint r Allocation ratio rho1, rho2 Correlations alpha One-sided significance level beta Type II error rate n1 Required sample size group 1 n2 Required sample size group 2 N Total sample size (n1 + n2)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"function implements sample size calculation mixed count-continuous co-primary endpoints following methodology Homma Yoshida (2024). sequential search algorithm (Homma Yoshida 2025, Algorithm 1) used: Step 1: Initialize sample sizes single endpoint formulas. Step 2: Use sequential search: Calculate power initial sample size power >= target: decrease n2 power < target, add 1 back power < target: increase n2 power >= target Step 3: Return final sample sizes. Negative Binomial Distribution: count endpoint follows negative binomial distribution NB(lambda, nu) : lambda = r * t mean count nu dispersion parameter Variance = lambda + lambda^2 / nu Correlation: correlations rho1 rho2 must satisfy feasibility constraints depend parameters. Use corrbound2MixedCountContinuous check valid correlation bounds.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"Homma, G., & Yoshida, T. (2024). Sample size calculation count continuous multiple co-primary endpoints. Pharmaceutical Statistics, 23(3), 372-388. Homma, G., & Yoshida, T. (2025). Exact power sample size clinical trials two co-primary binary endpoints. Statistical Methods Medical Research, 34(1), 1-19.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/ss2MixedCountContinuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample Size Calculation for Two Co-Primary Endpoints: One Count and One Continuous ‚Äî ss2MixedCountContinuous","text":"","code":"# Sample size calculation for count and continuous endpoints ss2MixedCountContinuous(   r1 = 1.0,   r2 = 1.25,   nu = 0.8,   t = 1,   mu1 = -50,   mu2 = 0,   sd = 250,   r = 1,   rho1 = 0.4,   rho2 = 0.4,   alpha = 0.025,   beta = 0.2 ) #>  #> Sample size calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 711 #>              n2 = 711 #>               N = 1422 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.4, 0.4 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>   # With different dispersion parameter (more overdispersion) ss2MixedCountContinuous(   r1 = 1.0,   r2 = 1.25,   nu = 0.5,   t = 1,   mu1 = -50,   mu2 = 0,   sd = 250,   r = 1,   rho1 = 0.4,   rho2 = 0.4,   alpha = 0.025,   beta = 0.2 ) #>  #> Sample size calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 924 #>              n2 = 924 #>               N = 1848 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.5 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.4, 0.4 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryApprox.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","title":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","text":"function provides unified interface power calculation sample size determination two co-primary binary endpoints using asymptotic normal approximation methods.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryApprox.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","text":"","code":"twoCoprimary2BinaryApprox(   n1 = NULL,   n2 = NULL,   p11,   p12,   p21,   p22,   rho1,   rho2,   power = NULL,   r = NULL,   alpha = 0.025,   Test = \"AN\" )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryApprox.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","text":"n1 Sample size group 1 (treatment group). NULL, calculated. n2 Sample size group 2 (control group). NULL, calculated. p11 True response probability endpoint 1 group 1 p12 True response probability endpoint 2 group 1 p21 True response probability endpoint 1 group 2 p22 True response probability endpoint 2 group 2 rho1 Correlation endpoints 1 2 group 1 rho2 Correlation endpoints 1 2 group 2 power Target power (1 - beta). NULL, calculated. r Allocation ratio (n1/n2). Required calculating sample size. alpha One-sided significance level (typically 0.025 0.05) Test Test method: \"\" (asymptotic normal), \"ANc\" (continuity correction), \"\" (arcsine), \"ASc\" (arcsine continuity correction)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryApprox.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","text":"object class \"twoCoprimary\" containing either: Power calculation results (n1 n2 specified) Sample size calculation results (power r specified)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryApprox.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","text":"function serves unified interface similar power.prop.test(). function determines operation mode based parameters NULL. Exactly one {(n1, n2), (power, r)} must NULL.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryApprox.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unified Interface for Two Co-Primary Binary Endpoints (Approximate Methods) ‚Äî twoCoprimary2BinaryApprox","text":"","code":"# Calculate power given sample sizes twoCoprimary2BinaryApprox(   n1 = 200, n2 = 100,   p11 = 0.5, p12 = 0.4,   p21 = 0.3, p22 = 0.2,   rho1 = 0.7, rho2 = 0.7,   alpha = 0.025, Test = \"AN\" ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 200 #>              n2 = 100 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.7, 0.7 #>           alpha = 0.025 #>            Test = AN #>          power1 = 0.91929 #>          power2 = 0.949617 #>  powerCoprimary = 0.894946 #>   # Calculate sample size given target power twoCoprimary2BinaryApprox(   p11 = 0.5, p12 = 0.4,   p21 = 0.3, p22 = 0.2,   rho1 = 0.7, rho2 = 0.7,   power = 0.8, r = 1,   alpha = 0.025, Test = \"AN\" ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 105 #>              n2 = 105 #>               N = 210 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.7, 0.7 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryExact.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","title":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","text":"function provides unified interface power calculation sample size determination two co-primary binary endpoints using exact inference methods.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryExact.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","text":"","code":"twoCoprimary2BinaryExact(   n1 = NULL,   n2 = NULL,   p11,   p12,   p21,   p22,   rho1,   rho2,   power = NULL,   r = NULL,   alpha = 0.025,   Test = \"Fisher\" )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryExact.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","text":"n1 Sample size group 1 (treatment group). NULL, calculated. n2 Sample size group 2 (control group). NULL, calculated. p11 True response probability endpoint 1 group 1 p12 True response probability endpoint 2 group 1 p21 True response probability endpoint 1 group 2 p22 True response probability endpoint 2 group 2 rho1 Correlation endpoints 1 2 group 1 rho2 Correlation endpoints 1 2 group 2 power Target power (1 - beta). NULL, calculated. r Allocation ratio (n1/n2). Required calculating sample size. alpha One-sided significance level (typically 0.025 0.05) Test Test method: \"Fisher\" (Fisher's exact test), \"Chisq\" (Chi-squared test), \"Z-pooled\" (Z-pooled exact unconditional test), \"Boschloo\" (Boschloo's exact unconditional test)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryExact.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","text":"object class \"twoCoprimary\" containing either: Power calculation results (n1 n2 specified) Sample size calculation results (power r specified)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryExact.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","text":"function serves unified interface similar power.prop.test(). function determines operation mode based parameters NULL. Exactly one {(n1, n2), (power, r)} must NULL. Note: Exact methods computationally intensive may take considerable time, especially large sample sizes.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2BinaryExact.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unified Interface for Two Co-Primary Binary Endpoints (Exact Methods) ‚Äî twoCoprimary2BinaryExact","text":"","code":"# \\donttest{ # Calculate power given sample sizes twoCoprimary2BinaryExact(   n1 = 50, n2 = 50,   p11 = 0.5, p12 = 0.4,   p21 = 0.3, p22 = 0.2,   rho1 = 0.5, rho2 = 0.5,   alpha = 0.025, Test = \"Fisher\" ) #>  #> Power calculation for two binary co-primary endpoints #>  #>              n1 = 50 #>              n2 = 50 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.5, 0.5 #>           alpha = 0.025 #>            Test = Fisher #>          power1 = 0.46345 #>          power2 = 0.515232 #>  powerCoprimary = 0.321793 #>   # Calculate sample size given target power twoCoprimary2BinaryExact(   p11 = 0.5, p12 = 0.4,   p21 = 0.3, p22 = 0.2,   rho1 = 0.5, rho2 = 0.5,   power = 0.8, r = 1,   alpha = 0.025, Test = \"Chisq\" ) #>  #> Sample size calculation for two binary co-primary endpoints #>  #>              n1 = 109 #>              n2 = 109 #>               N = 218 #>     p (group 1) = 0.5, 0.4 #>     p (group 2) = 0.3, 0.2 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = Chisq #>  # }"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2Continuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","title":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","text":"function provides unified interface power calculation sample size determination two co-primary continuous endpoints. Depending parameters provided (sample sizes power), function automatically determines whether calculate power sample size.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2Continuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","text":"","code":"twoCoprimary2Continuous(   n1 = NULL,   n2 = NULL,   delta1,   delta2,   sd1,   sd2,   rho,   power = NULL,   r = NULL,   alpha = 0.025,   known_var = TRUE,   nMC = 10000 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2Continuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","text":"n1 Sample size group 1 (treatment group). NULL, calculated. n2 Sample size group 2 (control group). NULL, calculated. delta1 Mean difference first endpoint delta2 Mean difference second endpoint sd1 Common standard deviation first endpoint sd2 Common standard deviation second endpoint rho Common correlation two outcomes power Target power (1 - beta). NULL, calculated. r Allocation ratio (n1/n2). Required calculating sample size. alpha One-sided significance level (typically 0.025 0.05) known_var Logical indicating whether variance known (TRUE) unknown (FALSE). Default TRUE. nMC Number Monte Carlo simulations known_var = FALSE. Default 10000.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2Continuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","text":"object class \"twoCoprimary\" containing either: Power calculation results (n1 n2 specified) Sample size calculation results (power r specified)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2Continuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","text":"function serves unified interface similar power.prop.test(). function determines operation mode based parameters NULL: n1 n2 provided power NULL: calculates power power r provided n1/n2 NULL: calculates sample size Exactly one {(n1, n2), (power, r)} must NULL.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2Continuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unified Interface for Two Co-Primary Continuous Endpoints ‚Äî twoCoprimary2Continuous","text":"","code":"# Calculate power given sample sizes twoCoprimary2Continuous(   n1 = 100, n2 = 100,   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.3, alpha = 0.025,   known_var = TRUE ) #>  #> Power calculation for two continuous co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.3 #>           alpha = 0.025 #>       known_var = TRUE #>          power1 = 0.942438 #>          power2 = 0.942438 #>  powerCoprimary = 0.893807 #>   # Calculate sample size given target power twoCoprimary2Continuous(   delta1 = 0.5, delta2 = 0.5,   sd1 = 1, sd2 = 1,   rho = 0.3, power = 0.8,   r = 1, alpha = 0.025,   known_var = TRUE ) #>  #> Sample size calculation for two continuous co-primary endpoints #>  #>              n1 = 81 #>              n2 = 81 #>               N = 162 #>           delta = 0.5, 0.5 #>              sd = 1, 1 #>             rho = 0.3 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>       known_var = TRUE #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedContinuousBinary.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","title":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","text":"function provides unified interface power calculation sample size determination trials one continuous one binary co-primary endpoint.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedContinuousBinary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","text":"","code":"twoCoprimary2MixedContinuousBinary(   n1 = NULL,   n2 = NULL,   delta,   sd,   p1,   p2,   rho,   power = NULL,   r = NULL,   alpha = 0.025,   Test = \"AN\",   nMC = 10000 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedContinuousBinary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","text":"n1 Sample size group 1 (treatment group). NULL, calculated. n2 Sample size group 2 (control group). NULL, calculated. delta Mean difference continuous endpoint sd Common standard deviation continuous endpoint p1 True response probability binary endpoint group 1 p2 True response probability binary endpoint group 2 rho Biserial correlation continuous endpoint latent continuous variable underlying binary endpoint power Target power (1 - beta). NULL, calculated. r Allocation ratio (n1/n2). Required calculating sample size. alpha One-sided significance level (typically 0.025 0.05) Test Test method binary endpoint: \"\" (asymptotic normal), \"ANc\" (continuity correction), \"\" (arcsine), \"ASc\" (arcsine continuity correction), \"Fisher\" (Fisher's exact test) nMC Number Monte Carlo simulations Test = \"Fisher\". Default 10000.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedContinuousBinary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","text":"object class \"twoCoprimary\" containing either: Power calculation results (n1 n2 specified) Sample size calculation results (power r specified)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedContinuousBinary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","text":"function serves unified interface similar power.prop.test(). function determines operation mode based parameters NULL. Exactly one {(n1, n2), (power, r)} must NULL. biserial correlation rho represents correlation observed continuous endpoint latent continuous variable underlying binary endpoint.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedContinuousBinary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unified Interface for Mixed Continuous and Binary Co-Primary Endpoints ‚Äî twoCoprimary2MixedContinuousBinary","text":"","code":"# Calculate power given sample sizes twoCoprimary2MixedContinuousBinary(   n1 = 100, n2 = 100,   delta = 0.5, sd = 1,   p1 = 0.6, p2 = 0.4,   rho = 0.5,   alpha = 0.025, Test = \"AN\" ) #>  #> Power calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 100 #>              n2 = 100 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>           alpha = 0.025 #>            Test = AN #>       powerCont = 0.942438 #>        powerBin = 0.812291 #>  powerCoprimary = 0.781111 #>   # Calculate sample size given target power twoCoprimary2MixedContinuousBinary(   delta = 0.5, sd = 1,   p1 = 0.6, p2 = 0.4,   rho = 0.5,   power = 0.8, r = 1,   alpha = 0.025, Test = \"AN\" ) #>  #> Sample size calculation for mixed continuous and binary co-primary endpoints #>  #>              n1 = 105 #>              n2 = 105 #>               N = 210 #>           delta = 0.5 #>              sd = 1 #>               p = 0.6, 0.4 #>             rho = 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>            Test = AN #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedCountContinuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","title":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","text":"function provides unified interface power calculation sample size determination trials one count endpoint (modeled negative binomial distribution) one continuous endpoint.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedCountContinuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","text":"","code":"twoCoprimary2MixedCountContinuous(   n1 = NULL,   n2 = NULL,   r1,   r2,   nu,   t,   mu1,   mu2,   sd,   rho1,   rho2,   power = NULL,   r = NULL,   alpha = 0.025 )"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedCountContinuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","text":"n1 Sample size group 1 (treatment group). NULL, calculated. n2 Sample size group 2 (control group). NULL, calculated. r1 Event rate per unit time count endpoint group 1 r2 Event rate per unit time count endpoint group 2 nu Dispersion parameter negative binomial distribution (nu > 0). nu approaches infinity, distribution converges Poisson. t Follow-period (time unit) mu1 Mean continuous endpoint group 1 mu2 Mean continuous endpoint group 2 sd Common standard deviation continuous endpoint rho1 Correlation count continuous endpoints group 1 rho2 Correlation count continuous endpoints group 2 power Target power (1 - beta). NULL, calculated. r Allocation ratio (n1/n2). Required calculating sample size. alpha One-sided significance level (typically 0.025 0.05)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedCountContinuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","text":"object class \"twoCoprimary\" containing either: Power calculation results (n1 n2 specified) Sample size calculation results (power r specified)","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedCountContinuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","text":"function serves unified interface similar power.prop.test(). function determines operation mode based parameters NULL. Exactly one {(n1, n2), (power, r)} must NULL. count endpoint modeled using negative binomial distribution account overdispersion. dispersion parameter nu controls variance: Var = lambda + lambda^2/nu.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/reference/twoCoprimary2MixedCountContinuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unified Interface for Mixed Count and Continuous Co-Primary Endpoints ‚Äî twoCoprimary2MixedCountContinuous","text":"","code":"# Calculate power given sample sizes twoCoprimary2MixedCountContinuous(   n1 = 300, n2 = 300,   r1 = 1.0, r2 = 1.25,   nu = 0.8, t = 1,   mu1 = -50, mu2 = 0, sd = 250,   rho1 = 0.5, rho2 = 0.5,   alpha = 0.025 ) #>  #> Power calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 300 #>              n2 = 300 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.5, 0.5 #>           alpha = 0.025 #>       powerCont = 0.687765 #>      powerCount = 0.461715 #>  powerCoprimary = 0.389192 #>   # Calculate sample size given target power twoCoprimary2MixedCountContinuous(   r1 = 1.0, r2 = 1.25,   nu = 0.8, t = 1,   mu1 = -50, mu2 = 0, sd = 250,   rho1 = 0.5, rho2 = 0.5,   power = 0.8, r = 1,   alpha = 0.025 ) #>  #> Sample size calculation for mixed count and continuous co-primary endpoints #>  #>              n1 = 705 #>              n2 = 705 #>               N = 1410 #>              sd = 250 #>            rate = 1, 1.25 #>              nu = 0.8 #>               t = 1 #>              mu = -50, 0 #>             rho = 0.5, 0.5 #>      allocation = 1 #>           alpha = 0.025 #>            beta = 0.2 #>"},{"path":"https://gosukehommaEX.github.io/twoCoprimary/news/index.html","id":"twocoprimary-100","dir":"Changelog","previous_headings":"","what":"twoCoprimary 1.0.0","title":"twoCoprimary 1.0.0","text":"CRAN release: 2025-11-21","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/news/index.html","id":"initial-release-1-0-0","dir":"Changelog","previous_headings":"","what":"Initial Release","title":"twoCoprimary 1.0.0","text":"first release twoCoprimary, providing comprehensive tools sample size power calculation clinical trials two co-primary endpoints.","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/news/index.html","id":"features-1-0-0","dir":"Changelog","previous_headings":"Initial Release","what":"Features","title":"twoCoprimary 1.0.0","text":"ss2Continuous(), power2Continuous(), twoCoprimary2Continuous() Based Sozu et al.¬†(2011) Supports known unknown variance cases ss2BinaryApprox(), power2BinaryApprox(), twoCoprimary2BinaryApprox() Based Sozu et al.¬†(2010) Four test methods: , ANc, , ASc ss2BinaryExact(), power2BinaryExact(), twoCoprimary2BinaryExact() Based Homma Yoshida (2025) Five exact tests: Chisq, Fisher, Fisher-midP, Z-pool, Boschloo ss2MixedContinuousBinary(), power2MixedContinuousBinary(), twoCoprimary2MixedContinuousBinary() Based Sozu et al.¬†(2012) Supports biserial correlation structure ss2MixedCountContinuous(), power2MixedCountContinuous(), twoCoprimary2MixedCountContinuous() Based Homma Yoshida (2024) Handles overdispersed count data negative binomial distribution","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/news/index.html","id":"utility-functions-1-0-0","dir":"Changelog","previous_headings":"Initial Release","what":"Utility Functions","title":"twoCoprimary 1.0.0","text":"corrbound2Binary() - Calculate valid correlation bounds binary endpoints corrbound2MixedCountContinuous() - Calculate valid correlation bounds count continuous endpoints design_table() - Create comprehensive design comparison tables plot.twoCoprimary() - Visualize sample size vs correlation relationships","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/news/index.html","id":"documentation-1-0-0","dir":"Changelog","previous_headings":"Initial Release","what":"Documentation","title":"twoCoprimary 1.0.0","text":"Six comprehensive vignettes covering methodologies Complete function documentation examples Validation published results","code":""},{"path":"https://gosukehommaEX.github.io/twoCoprimary/news/index.html","id":"testing-1-0-0","dir":"Changelog","previous_headings":"Initial Release","what":"Testing","title":"twoCoprimary 1.0.0","text":"Comprehensive test suite testthat Tests major functions Validation published tables results","code":""}]
