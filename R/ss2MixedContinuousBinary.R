#' Sample Size Calculation for Two Co-Primary Endpoints: One Continuous and One Binary
#'
#' Determines the sample size for a two-arm superiority trial with two co-primary
#' endpoints where one is continuous and one is binary, to achieve a specified
#' power at a given significance level. This function is specifically designed
#' for mixed continuous-binary endpoint combinations.
#'
#' @param delta Mean difference for the continuous endpoint (group 1 - group 2)
#' @param sd Common standard deviation for the continuous endpoint
#' @param p1 Probability of response in group 1 for the binary endpoint (0 < p1 < 1)
#' @param p2 Probability of response in group 2 for the binary endpoint (0 < p2 < 1)
#' @param rho Biserial correlation between the latent continuous variable underlying
#'   the binary endpoint and the observed continuous endpoint
#' @param r Allocation ratio n1/n2 where n1 is sample size for group 1
#' @param alpha One-sided significance level (typically 0.025 or 0.05)
#' @param beta Type II error rate (typically 0.1 or 0.2). Power = 1 - beta
#' @param Test Statistical testing method for the binary endpoint. One of:
#'   \itemize{
#'     \item \code{"AN"}: Asymptotic normal method without continuity correction
#'     \item \code{"ANc"}: Asymptotic normal method with continuity correction
#'     \item \code{"AS"}: Arcsine method without continuity correction
#'     \item \code{"ASc"}: Arcsine method with continuity correction
#'     \item \code{"Fisher"}: Fisher's exact test (uses sequential search)
#'   }
#' @param nMC Number of Monte Carlo replications when Test = "Fisher" (default: 10000)
#'
#' @return A data frame with the following columns:
#'   \item{delta}{Mean difference for continuous endpoint}
#'   \item{sd}{Standard deviation for continuous endpoint}
#'   \item{p1}{Response probability in group 1 for binary endpoint}
#'   \item{p2}{Response probability in group 2 for binary endpoint}
#'   \item{rho}{Biserial correlation}
#'   \item{r}{Allocation ratio}
#'   \item{alpha}{One-sided significance level}
#'   \item{beta}{Type II error rate}
#'   \item{Test}{Testing method used for binary endpoint}
#'   \item{n1}{Required sample size for group 1}
#'   \item{n2}{Required sample size for group 2}
#'   \item{n}{Total sample size (n1 + n2)}
#'
#' @details
#' This function implements the sample size calculation for mixed continuous-binary
#' co-primary endpoints following the methodology in Sozu et al. (2012).
#'
#' **Endpoint Types:**
#' \itemize{
#'   \item \strong{Continuous Endpoint}: Analyzed using t-test for comparing means
#'   \item \strong{Binary Endpoint}: Analyzed using one of several methods (AN, ANc, AS, ASc, or Fisher)
#' }
#'
#' **Biserial Correlation Model:**
#' The binary endpoint is assumed to arise from dichotomizing a latent continuous
#' variable at a threshold. The correlation parameter rho represents the biserial
#' correlation between the observed continuous endpoint and this latent continuous
#' variable underlying the binary endpoint.
#'
#' **Algorithm:**
#'
#' For methods AN, ANc, AS, and ASc, linear extrapolation algorithm is used:
#'
#' \strong{Step 1:} Initialize with sample sizes from single endpoint formulas
#'
#' \strong{Step 2-4:} Iteratively refine using linear extrapolation:
#' \deqn{n_2^{new} = \frac{n_2^{(0)}(power^{(1)} - (1-\beta)) - n_2^{(1)}(power^{(0)} - (1-\beta))}
#'       {power^{(1)} - power^{(0)}}}
#'
#' The algorithm converges when \eqn{n_2^{(1)} = n_2^{(0)}}.
#'
#' For Fisher's exact test, sequential search is used instead, as Monte Carlo
#' simulation has random variation that can prevent reliable convergence with
#' linear extrapolation.
#'
#' @references
#' Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination in
#' clinical trials with multiple co-primary endpoints including mixed continuous
#' and binary variables. \emph{Biometrical Journal}, 54(5), 716-729.
#'
#' @examples
#' # Example 1: Based on PREMIER study (Table 2 in Sozu et al. 2012)
#' # mTSS (continuous) and ACR50 (binary) with rho = 0.5
#' ss2MixedContinuousBinary(
#'   delta = 4.4,
#'   sd = 19.0,
#'   p1 = 0.59,
#'   p2 = 0.46,
#'   rho = 0.5,
#'   r = 1,
#'   alpha = 0.025,
#'   beta = 0.2,
#'   Test = "AN"
#' )
#'
#' # Example 2: With continuity correction
#' ss2MixedContinuousBinary(
#'   delta = 5.0,
#'   sd = 20.0,
#'   p1 = 0.65,
#'   p2 = 0.50,
#'   rho = 0.3,
#'   r = 1,
#'   alpha = 0.025,
#'   beta = 0.1,
#'   Test = "ANc"
#' )
#'
#' # Example 3: Arcsine transformation
#' ss2MixedContinuousBinary(
#'   delta = 4.5,
#'   sd = 18.0,
#'   p1 = 0.70,
#'   p2 = 0.55,
#'   rho = 0.4,
#'   r = 1,
#'   alpha = 0.025,
#'   beta = 0.1,
#'   Test = "AS"
#' )
#'
#' # Example 4: Unequal allocation
#' ss2MixedContinuousBinary(
#'   delta = 0.3,
#'   sd = 1.0,
#'   p1 = 0.6,
#'   p2 = 0.4,
#'   rho = 0.5,
#'   r = 2,
#'   alpha = 0.025,
#'   beta = 0.1,
#'   Test = "AS"
#' )
#'
#' \donttest{
#' # Example 5: Fisher's exact test (uses sequential search, computationally intensive)
#' set.seed(12345)
#' ss2MixedContinuousBinary(
#'   delta = 0.5,
#'   sd = 1.0,
#'   p1 = 0.4,
#'   p2 = 0.2,
#'   rho = 0.3,
#'   r = 1,
#'   alpha = 0.025,
#'   beta = 0.1,
#'   Test = "Fisher",
#'   nMC = 10000
#' )
#' }
#'
#' @export
ss2MixedContinuousBinary <- function(delta, sd, p1, p2, rho, r, alpha, beta, Test, nMC = 10000) {

  # Input validation
  if (delta <= 0) {
    stop("delta must be positive")
  }
  if (sd <= 0) {
    stop("sd must be positive")
  }
  if (p1 <= 0 || p1 >= 1) {
    stop("p1 must be in (0, 1)")
  }
  if (p2 <= 0 || p2 >= 1) {
    stop("p2 must be in (0, 1)")
  }
  if (abs(rho) >= 1) {
    stop("rho must be in (-1, 1)")
  }
  if (r <= 0) {
    stop("r must be positive")
  }
  if (alpha <= 0 || alpha >= 1) {
    stop("alpha must be in (0, 1)")
  }
  if (beta <= 0 || beta >= 1) {
    stop("beta must be in (0, 1)")
  }
  if (!Test %in% c("AN", "ANc", "AS", "ASc", "Fisher")) {
    stop("Test must be one of: AN, ANc, AS, ASc, Fisher")
  }

  if (Test == "Fisher") {
    # ===== FISHER'S EXACT TEST: Use sequential search =====
    # Monte Carlo simulation has random variation, so linear extrapolation
    # may not converge reliably. Instead, use sequential search.

    # Helper function for continuous endpoint
    ss1Continuous <- function(delta, sd, r, alpha, beta) {
      z_alpha <- qnorm(1 - alpha)
      z_beta <- qnorm(1 - beta)
      n2 <- ceiling(((z_alpha + z_beta) * sd / delta) ^ 2 * (1 + 1 / r))
      return(n2)
    }

    # Step 1: Initialize with sample size from single endpoint formulas
    n2_cont <- ss1Continuous(delta, sd, r, alpha, beta)
    n2_bin <- ss1BinaryApprox(p1, p2, r, alpha, beta, Test = "AN")[["n2"]]
    n2 <- max(n2_cont, n2_bin)
    n1 <- ceiling(r * n2)

    # Step 2: Calculate power at initial sample size
    power <- power2MixedContinuousBinary(n1, n2, delta, sd, p1, p2, rho, alpha, Test, nMC)[["powerCoprimary"]]

    # Step 3: Sequential search - increment n2 by 1 until target power is achieved
    while (power < 1 - beta) {
      n2 <- n2 + 1
      n1 <- ceiling(r * n2)
      power <- power2MixedContinuousBinary(n1, n2, delta, sd, p1, p2, rho, alpha, Test, nMC)[["powerCoprimary"]]
    }

    # Final sample sizes
    n <- n1 + n2

  } else {
    # ===== AN, ANc, AS, ASc METHODS: Use linear extrapolation =====

    # Helper function for continuous endpoint
    ss1Continuous <- function(delta, sd, r, alpha, beta) {
      z_alpha <- qnorm(1 - alpha)
      z_beta <- qnorm(1 - beta)
      n2 <- ceiling(((z_alpha + z_beta) * sd / delta) ^ 2 * (1 + 1 / r))
      return(n2)
    }

    # Step 1: Initialize sample sizes using single endpoint formulas
    n2_cont <- ss1Continuous(delta, sd, r, alpha, beta)
    n2_bin <- ss1BinaryApprox(p1, p2, r, alpha, beta, Test = Test)[["n2"]]
    n2_0 <- max(n2_cont, n2_bin)

    # For the second initial value, use adjusted target power
    n2_cont_adj <- ss1Continuous(delta, sd, r, alpha, 1 - (1 - beta) ^ (1/2))
    n2_bin_adj <- ss1BinaryApprox(p1, p2, r, alpha, 1 - (1 - beta) ^ (1/2), Test = Test)[["n2"]]
    n2_1 <- max(n2_cont_adj, n2_bin_adj)

    # Step 2-4: Iterative refinement using linear extrapolation
    max_iter <- 100
    iter <- 0

    while (n2_1 - n2_0 != 0 && iter < max_iter) {
      iter <- iter + 1

      # Calculate sample sizes for group 1
      n1_0 <- ceiling(r * n2_0)
      n1_1 <- ceiling(r * n2_1)

      # Calculate power at two candidate sample sizes
      power_n2_0 <- power2MixedContinuousBinary(n1_0, n2_0, delta, sd, p1, p2, rho, alpha, Test, nMC)[["powerCoprimary"]]
      power_n2_1 <- power2MixedContinuousBinary(n1_1, n2_1, delta, sd, p1, p2, rho, alpha, Test, nMC)[["powerCoprimary"]]

      # Linear extrapolation to find sample size that achieves target power
      # This solves: power = (1 - beta) for n2
      n2_updated <- (n2_0 * (power_n2_1 - (1 - beta)) - n2_1 * (power_n2_0 - (1 - beta))) /
        (power_n2_1 - power_n2_0)

      # Update values for next iteration
      n2_1 <- n2_0
      n2_0 <- ceiling(n2_updated)
    }

    if (iter >= max_iter) {
      warning("Maximum iterations reached. Results may not have converged.")
    }

    # Final sample sizes
    n2 <- n2_0
    n1 <- ceiling(r * n2)
    n <- n1 + n2
  }

  # Return result as a data frame
  result <- data.frame(
    delta = delta,
    sd = sd,
    p1 = p1,
    p2 = p2,
    rho = rho,
    r = r,
    alpha = alpha,
    beta = beta,
    Test = Test,
    n1 = n1,
    n2 = n2,
    n = n
  )

  return(result)
}
