---
title: "Two Binary Co-Primary Endpoints (Exact Methods)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Two Binary Co-Primary Endpoints (Exact Methods)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

## Overview

This vignette demonstrates exact sample size calculation for clinical trials with two co-primary binary endpoints. The methodology is based on Homma and Yoshida (2025).

```{r setup, message=FALSE, warning=FALSE}
library(twoCoprimary)
library(dplyr)
library(tidyr)
library(knitr)
```

## Background

### When to Use Exact Methods

Exact methods are recommended when:

- **Small to medium sample sizes** (N < 200)
- **Extreme probabilities** (p < 0.10 or p > 0.90)
- **Strict Type I error control** is required

### Available Exact Tests

1. **Fisher's exact test**: Classic conditional test
2. **Z-pool exact unconditional test**: Barnard's test variant
3. **Boschloo's exact unconditional test**: Most powerful unconditional test

## Replicating Homma and Yoshida (2025) Table 4

### Scenario 1: Moderate Effect Sizes

```{r table4_scenario1}
# Scenario: p11=0.7, p21=0.4, p12=0.6, p22=0.3
rho_values <- c(0, 0.3, 0.5, 0.8)
tests <- c("Fisher", "Z-pool", "Boschloo")

results_scenario1 <- lapply(tests, function(test_name) {
  results_rho <- lapply(rho_values, function(rho) {
    result <- ss2BinaryExact(
      p11 = 0.7, p21 = 0.4,
      p12 = 0.6, p22 = 0.3,
      r = 1,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      beta = 0.2,
      Test = test_name
    )
    
    power <- power2BinaryExact(
      n1 = result$n1, n2 = result$n2,
      p11 = 0.7, p21 = 0.4,
      p12 = 0.6, p22 = 0.3,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      Test = test_name
    )
    
    data.frame(
      Test = test_name,
      rho = rho,
      n_per_group = result$n2,
      N_total = result$N,
      power_both = power$powerCoprimary
    )
  })
  bind_rows(results_rho)
})

table4_scenario1 <- bind_rows(results_scenario1)

table4_scenario1_wide <- table4_scenario1 %>%
  select(Test, rho, n_per_group, power_both) %>%
  pivot_wider(
    names_from = rho,
    values_from = c(n_per_group, power_both),
    names_glue = "{.value}_rho{rho}"
  )

kable(table4_scenario1_wide,
      caption = "Table 4 (Scenario 1): p11=0.7, p21=0.4, p12=0.6, p22=0.3",
      digits = 3)
```

### Scenario 2: Larger Effect Sizes

```{r table4_scenario2}
# Note: Max feasible rho for this combination is ~0.76
rho_values_scenario2 <- c(0, 0.3, 0.5)

results_scenario2 <- lapply(tests, function(test_name) {
  results_rho <- lapply(rho_values_scenario2, function(rho) {
    result <- ss2BinaryExact(
      p11 = 0.8, p21 = 0.5,
      p12 = 0.7, p22 = 0.4,
      r = 1,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      beta = 0.2,
      Test = test_name
    )
    
    power <- power2BinaryExact(
      n1 = result$n1, n2 = result$n2,
      p11 = 0.8, p21 = 0.5,
      p12 = 0.7, p22 = 0.4,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      Test = test_name
    )
    
    data.frame(
      Test = test_name,
      rho = rho,
      n_per_group = result$n2,
      power_both = power$powerCoprimary
    )
  })
  bind_rows(results_rho)
})

table4_scenario2 <- bind_rows(results_scenario2)

table4_scenario2_wide <- table4_scenario2 %>%
  select(Test, rho, n_per_group, power_both) %>%
  pivot_wider(
    names_from = rho,
    values_from = c(n_per_group, power_both),
    names_glue = "{.value}_rho{rho}"
  )

kable(table4_scenario2_wide,
      caption = "Table 4 (Scenario 2): p11=0.8, p21=0.5, p12=0.7, p22=0.4 (ρ ≤ 0.5)",
      digits = 3)
```

### Scenario 3: Unbalanced Allocation

```{r table4_scenario3}
results_scenario3 <- lapply(tests, function(test_name) {
  results_rho <- lapply(c(0, 0.5), function(rho) {
    result <- ss2BinaryExact(
      p11 = 0.7, p21 = 0.4,
      p12 = 0.6, p22 = 0.3,
      r = 2,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      beta = 0.2,
      Test = test_name
    )
    
    power <- power2BinaryExact(
      n1 = result$n1, n2 = result$n2,
      p11 = 0.7, p21 = 0.4,
      p12 = 0.6, p22 = 0.3,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      Test = test_name
    )
    
    data.frame(
      Test = test_name,
      rho = rho,
      n2 = result$n2,
      n1 = result$n1,
      N_total = result$N,
      power_both = power$powerCoprimary
    )
  })
  bind_rows(results_rho)
})

table4_scenario3 <- bind_rows(results_scenario3)

kable(table4_scenario3,
      caption = "Table 4 (Scenario 3): Unbalanced Allocation (2:1)",
      digits = 3)
```

## Comparison: Exact vs Asymptotic

```{r exact_vs_asymptotic}
p11 <- 0.7; p21 <- 0.4
p12 <- 0.6; p22 <- 0.3
rho <- 0.5

exact_fisher <- ss2BinaryExact(
  p11 = p11, p21 = p21, p12 = p12, p22 = p22,
  r = 1, rho1 = rho, rho2 = rho,
  alpha = 0.025, beta = 0.2,
  Test = "Fisher"
)

exact_zpool <- ss2BinaryExact(
  p11 = p11, p21 = p21, p12 = p12, p22 = p22,
  r = 1, rho1 = rho, rho2 = rho,
  alpha = 0.025, beta = 0.2,
  Test = "Z-pool"
)

exact_boschloo <- ss2BinaryExact(
  p11 = p11, p21 = p21, p12 = p12, p22 = p22,
  r = 1, rho1 = rho, rho2 = rho,
  alpha = 0.025, beta = 0.2,
  Test = "Boschloo"
)

asymp <- ss2BinaryApprox(
  p11 = p11, p21 = p21, p12 = p12, p22 = p22,
  r = 1, rho1 = rho, rho2 = rho,
  alpha = 0.025, beta = 0.2,
  Test = "AN"
)

comparison <- data.frame(
  Method = c("Fisher", "Z-pool", "Boschloo", "Asymptotic"),
  n_per_group = c(exact_fisher$n2, exact_zpool$n2, 
                  exact_boschloo$n2, asymp$n2),
  N_total = c(exact_fisher$N, exact_zpool$N, 
              exact_boschloo$N, asymp$N)
)

comparison <- comparison %>%
  mutate(
    Diff_vs_Asymp = N_total - asymp$N,
    Pct_diff = round((N_total - asymp$N) / asymp$N * 100, 1)
  )

kable(comparison,
      caption = "Exact vs Asymptotic Methods (ρ=0.5)",
      digits = 1)
```

**Key findings**:
- Fisher's test is most conservative (largest N)
- Boschloo's test is most powerful (smallest N)
- Asymptotic method may underestimate sample size

**Important**: Not all correlations are feasible for all probability combinations. For Scenario 2, max feasible ρ ≈ 0.76.

## Correlation Bounds

```{r correlation_bounds_check}
scenarios <- list(
  list(p1 = 0.7, p2 = 0.6, desc = "Scenario 1 (Treatment)"),
  list(p1 = 0.4, p2 = 0.3, desc = "Scenario 1 (Control)"),
  list(p1 = 0.8, p2 = 0.7, desc = "Scenario 2 (Treatment)"),
  list(p1 = 0.5, p2 = 0.4, desc = "Scenario 2 (Control)")
)

bounds_results <- lapply(scenarios, function(scenario) {
  bounds <- corrbound2Binary(scenario$p1, scenario$p2)
  
  data.frame(
    Description = scenario$desc,
    p1 = scenario$p1,
    p2 = scenario$p2,
    Lower = bounds[1],
    Upper = bounds[2]
  )
})

bounds_table <- bind_rows(bounds_results)

kable(bounds_table,
      caption = "Feasible Correlation Ranges",
      digits = 3)
```

## Power Curves

```{r power_curves, fig.width=8, fig.height=6}
p11 <- 0.7; p21 <- 0.4
p12 <- 0.6; p22 <- 0.3
rho <- 0.5

n_seq <- seq(50, 120, by = 5)

power_data <- lapply(tests, function(test_name) {
  powers <- sapply(n_seq, function(n) {
    power <- power2BinaryExact(
      n1 = n, n2 = n,
      p11 = p11, p21 = p21,
      p12 = p12, p22 = p22,
      rho1 = rho, rho2 = rho,
      alpha = 0.025,
      Test = test_name
    )
    power$powerCoprimary
  })
  
  data.frame(
    Test = test_name,
    n = n_seq,
    power = powers
  )
})

power_curves_data <- bind_rows(power_data)

# Base R plot
par(mar = c(5, 4, 4, 2) + 0.1)

unique_tests <- unique(power_curves_data$Test)
colors <- c("Fisher" = "blue", "Z-pool" = "red", "Boschloo" = "green")
ltys <- c("Fisher" = 1, "Z-pool" = 2, "Boschloo" = 3)

plot(range(power_curves_data$n), c(0.5, 1),
     type = "n",
     xlab = "Sample Size per Group (n)",
     ylab = "Power",
     main = "Power Curves for Exact Tests",
     las = 1)

abline(h = 0.8, lty = 2, col = "gray50", lwd = 2)

for (test in unique_tests) {
  test_data <- power_curves_data[power_curves_data$Test == test, ]
  lines(test_data$n, test_data$power, 
        col = colors[test], lty = ltys[test], lwd = 2)
}

legend("bottomright",
       legend = unique_tests,
       col = colors[unique_tests],
       lty = ltys[unique_tests],
       lwd = 2,
       bty = "n")

grid()
```

## Summary

### Key Findings

1. **Exact methods guarantee Type I error control**
2. **Test comparison**:
   - Fisher: Most conservative
   - Z-pool: Moderate
   - Boschloo: Most powerful
3. **Correlation impact**: ~11% reduction at ρ = 0.8
4. **Computational cost**: 10-100× slower than asymptotic

### Recommendations

- **Small trials (N < 100)**: Use exact methods
- **Medium trials (100 ≤ N ≤ 200)**: Either method acceptable
- **Large trials (N > 200)**: Asymptotic sufficient

## References

Homma, G., & Yoshida, T. (2025). Exact power and sample size in clinical trials with two co-primary binary endpoints. *Statistical Methods in Medical Research* (in press).

Boschloo, R. D. (1970). Raised conditional level of significance for the 2×2-table when testing the equality of two probabilities. *Statistica Neerlandica*, 24(1), 1-9.
