---
title: "Mixed Continuous and Binary Co-Primary Endpoints"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mixed Continuous and Binary Co-Primary Endpoints}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

## Overview

This vignette demonstrates sample size calculation for clinical trials with two co-primary endpoints where one is continuous and one is binary. The methodology is based on Sozu et al. (2012).

```{r setup, message=FALSE, warning=FALSE}
library(twoCoprimary)
library(dplyr)
library(tidyr)
library(knitr)
```

## Background

### Clinical Context

Mixed continuous and binary co-primary endpoints are common in:

- **Alzheimer's trials**: Cognitive score (continuous) + Clinical global impression (binary)
- **Depression trials**: HAM-D score (continuous) + Response rate (binary)
- **Cardiovascular trials**: Blood pressure change (continuous) + Target achievement (binary)
- **Pain trials**: Pain intensity (continuous) + ≥50% pain reduction (binary)

### Correlation Structure

The correlation between a continuous variable Y₁ and a binary variable Y₂ is expressed using the **biserial correlation** ρ, which measures the correlation between:

- Y₁: Observed continuous variable
- Y₂*: Latent continuous variable underlying the binary outcome

The observed binary outcome Y₂ = 1 if Y₂* exceeds a threshold.

## Statistical Framework

### Model

**Continuous endpoint** (k = 1):
$$Y_{ij1} \sim N(\mu_{j1}, \sigma^2)$$

**Binary endpoint** (k = 2):
$$Y_{ij2} \sim \text{Bernoulli}(p_{j2})$$

**Biserial correlation**: ρ relates the continuous Y₁ to the latent continuous variable underlying Y₂.

### Test Statistics

**Continuous endpoint**:
$$Z_1 = \frac{\bar{Y}_{11} - \bar{Y}_{21}}{\sigma\sqrt{1/n_1 + 1/n_2}}$$

**Binary endpoint** (various methods):
- **AN**: Asymptotic normal without continuity correction
- **ANc**: Asymptotic normal with continuity correction
- **AS**: Arcsine transformation
- **Fisher**: Fisher's exact test

### Joint Distribution

The test statistics $(Z_1, Z_2)$ follow an asymptotic bivariate normal distribution with correlation γ that depends on ρ.

## Replicating Sozu et al. (2012) Table 1

Table 1 shows sample sizes for different standardized effect sizes and probability pairs with equal individual power (c₁*/c₂* = 1).

### Understanding c₁*/c₂*

The parameter c₁*/c₂* represents the ratio of arguments in the power function. When c₁*/c₂* = 1, both endpoints have approximately equal individual power.

### Table 1: Equal Individual Power (c₁*/c₂* = 1)

```{r table1_equal_power}
# Scenarios from Table 1
# δ₁*: standardized effect size for continuous endpoint
# (πT2, πC2): probabilities for binary endpoint

scenarios_table1 <- data.frame(
  delta_star = c(0.100, 0.103, 0.112, 0.132, 0.201, 0.210, 0.231, 0.281),
  pT2 = c(0.55, 0.65, 0.75, 0.85, 0.60, 0.70, 0.80, 0.90),
  pC2 = c(0.50, 0.60, 0.70, 0.80, 0.50, 0.60, 0.70, 0.80)
)

rho_values <- c(0, 0.3, 0.5, 0.8)

# Calculate sample sizes for each scenario and correlation
results_table1 <- lapply(1:nrow(scenarios_table1), function(i) {
  scenario <- scenarios_table1[i, ]
  
  results_rho <- lapply(rho_values, function(rho) {
    result <- ss2MixedContinuousBinary(
      delta = scenario$delta_star,
      sd = 1,  # Standardized
      p1 = scenario$pT2,
      p2 = scenario$pC2,
      rho = rho,
      r = 1,
      alpha = 0.025,
      beta = 0.2,
      Test = "AN"
    )
    
    data.frame(
      delta_star = scenario$delta_star,
      binary_pair = paste0("(", scenario$pT2, ", ", scenario$pC2, ")"),
      rho = rho,
      n_per_group = result$n2
    )
  })
  bind_rows(results_rho)
})

table1_results <- bind_rows(results_table1)

# Reshape for better presentation
table1_wide <- table1_results %>%
  select(delta_star, binary_pair, rho, n_per_group) %>%
  pivot_wider(
    names_from = rho,
    values_from = n_per_group,
    names_prefix = "rho_"
  )

kable(table1_wide,
      caption = "Table 1: Sample Size per Group (c₁*/c₂* = 1, Equal Individual Power)",
      digits = 0,
      col.names = c("δ₁*", "(πT₂, πC₂)", "ρ=0.0", "ρ=0.3", "ρ=0.5", "ρ=0.8"))
```

**Key observations**:
- As correlation increases, sample size decreases (5-7% reduction at ρ = 0.8)
- Smaller effect sizes require larger sample sizes
- Sample size is similar to that required for two continuous endpoints

### Table 1: Unequal Individual Power (c₁*/c₂* = 1.5)

When c₁*/c₂* = 1.5, the continuous endpoint has higher individual power.

```{r table1_unequal_power_1_5}
# Scenarios with c₁*/c₂* = 1.5
scenarios_table1_1_5 <- data.frame(
  delta_star = c(0.115, 0.119, 0.129, 0.151, 0.232, 0.242, 0.266, 0.323),
  pT2 = c(0.55, 0.65, 0.75, 0.85, 0.60, 0.70, 0.80, 0.90),
  pC2 = c(0.50, 0.60, 0.70, 0.80, 0.50, 0.60, 0.70, 0.80)
)

results_table1_1_5 <- lapply(1:nrow(scenarios_table1_1_5), function(i) {
  scenario <- scenarios_table1_1_5[i, ]
  
  results_rho <- lapply(rho_values, function(rho) {
    result <- ss2MixedContinuousBinary(
      delta = scenario$delta_star,
      sd = 1,
      p1 = scenario$pT2,
      p2 = scenario$pC2,
      rho = rho,
      r = 1,
      alpha = 0.025,
      beta = 0.2,
      Test = "AN"
    )
    
    data.frame(
      delta_star = scenario$delta_star,
      binary_pair = paste0("(", scenario$pT2, ", ", scenario$pC2, ")"),
      rho = rho,
      n_per_group = result$n2
    )
  })
  bind_rows(results_rho)
})

table1_1_5_results <- bind_rows(results_table1_1_5)

# Reshape
table1_1_5_wide <- table1_1_5_results %>%
  select(delta_star, binary_pair, rho, n_per_group) %>%
  pivot_wider(
    names_from = rho,
    values_from = n_per_group,
    names_prefix = "rho_"
  )

kable(table1_1_5_wide,
      caption = "Table 1: Sample Size per Group (c₁*/c₂* = 1.5)",
      digits = 0,
      col.names = c("δ₁*", "(πT₂, πC₂)", "ρ=0.0", "ρ=0.3", "ρ=0.5", "ρ=0.8"))
```

### Table 1: Highly Unequal Power (c₁*/c₂* = 3)

When c₁*/c₂* = 3, the binary endpoint dominates sample size.

```{r table1_unequal_power_3}
# Scenarios with c₁*/c₂* = 3
scenarios_table1_3 <- data.frame(
  delta_star = c(0.160, 0.165, 0.179, 0.211, 0.322, 0.336, 0.370, 0.450),
  pT2 = c(0.55, 0.65, 0.75, 0.85, 0.60, 0.70, 0.80, 0.90),
  pC2 = c(0.50, 0.60, 0.70, 0.80, 0.50, 0.60, 0.70, 0.80)
)

results_table1_3 <- lapply(1:nrow(scenarios_table1_3), function(i) {
  scenario <- scenarios_table1_3[i, ]
  
  results_rho <- lapply(rho_values, function(rho) {
    result <- ss2MixedContinuousBinary(
      delta = scenario$delta_star,
      sd = 1,
      p1 = scenario$pT2,
      p2 = scenario$pC2,
      rho = rho,
      r = 1,
      alpha = 0.025,
      beta = 0.2,
      Test = "AN"
    )
    
    data.frame(
      delta_star = scenario$delta_star,
      binary_pair = paste0("(", scenario$pT2, ", ", scenario$pC2, ")"),
      rho = rho,
      n_per_group = result$n2
    )
  })
  bind_rows(results_rho)
})

table1_3_results <- bind_rows(results_table1_3)

# Reshape
table1_3_wide <- table1_3_results %>%
  select(delta_star, binary_pair, rho, n_per_group) %>%
  pivot_wider(
    names_from = rho,
    values_from = n_per_group,
    names_prefix = "rho_"
  )

kable(table1_3_wide,
      caption = "Table 1: Sample Size per Group (c₁*/c₂* = 3)",
      digits = 0,
      col.names = c("δ₁*", "(πT₂, πC₂)", "ρ=0.0", "ρ=0.3", "ρ=0.5", "ρ=0.8"))
```

**Key findings**:
- When c₁*/c₂* = 3, correlation has minimal impact on sample size
- Sample size approaches that needed for the binary endpoint alone
- The endpoint with smaller individual power dominates

## Replicating Sozu et al. (2012) Table 2

Table 2 shows a specific application to mTSS (modified Total Sharp Score) and ACR50 in rheumatoid arthritis trials.

### Table 2: Rheumatoid Arthritis Trial Example

```{r table2_ra_trial}
# mTSS: Modified Total Sharp Score (continuous)
# ACR50: American College of Rheumatology 50% improvement (binary)

# Different scenarios with varying standard deviations
sd_values <- c(19.0, 20.0, 21.0, 22.0)
rho_values_table2 <- c(0, 0.3, 0.5, 0.8)

results_table2 <- lapply(sd_values, function(sd_val) {
  results_rho <- lapply(rho_values_table2, function(rho) {
    result <- ss2MixedContinuousBinary(
      delta = 4.4,  # mTSS effect
      sd = sd_val,
      p1 = 0.59,    # ACR50 treatment
      p2 = 0.46,    # ACR50 control
      rho = rho,
      r = 1,
      alpha = 0.025,
      beta = 0.2,
      Test = "AN"
    )
    
    data.frame(
      delta = 4.4,
      sd = sd_val,
      ACR50_pair = "(0.59, 0.46)",
      rho = rho,
      n_per_group = result$n2,
      N_total = result$N
    )
  })
  bind_rows(results_rho)
})

table2_results <- bind_rows(results_table2)

# Reshape
table2_wide <- table2_results %>%
  select(sd, rho, n_per_group) %>%
  pivot_wider(
    names_from = rho,
    values_from = n_per_group,
    names_prefix = "rho_"
  )

kable(table2_wide,
      caption = "Table 2: Rheumatoid Arthritis Trial (mTSS + ACR50)",
      digits = 0,
      col.names = c("SD (mTSS)", "ρ=0.0", "ρ=0.3", "ρ=0.5", "ρ=0.8"))
```

**Clinical interpretation**:
- δ = 4.4 points difference in mTSS
- σ varies from 19.0 to 22.0 (uncertainty in variance)
- ACR50 rates: 59% vs 46%
- Sample size is relatively insensitive to SD in this range

## Power Verification

Verify that calculated sample sizes achieve target power:

```{r power_verification}
# Select representative scenarios
test_scenarios <- data.frame(
  delta = c(0.10, 0.20, 0.15, 0.25),
  sd = c(1, 1, 1, 1),
  p1 = c(0.55, 0.70, 0.60, 0.80),
  p2 = c(0.50, 0.60, 0.50, 0.70),
  rho = c(0.3, 0.5, 0.5, 0.8)
)

power_results <- lapply(1:nrow(test_scenarios), function(i) {
  scenario <- test_scenarios[i, ]
  
  # Get sample size
  ss <- ss2MixedContinuousBinary(
    delta = scenario$delta,
    sd = scenario$sd,
    p1 = scenario$p1,
    p2 = scenario$p2,
    rho = scenario$rho,
    r = 1,
    alpha = 0.025,
    beta = 0.2,
    Test = "AN"
  )
  
  # Calculate power
  power <- power2MixedContinuousBinary(
    n1 = ss$n1,
    n2 = ss$n2,
    delta = scenario$delta,
    sd = scenario$sd,
    p1 = scenario$p1,
    p2 = scenario$p2,
    rho = scenario$rho,
    alpha = 0.025,
    Test = "AN"
  )
  
  data.frame(
    delta_star = scenario$delta,
    binary_pair = paste0("(", scenario$p1, ", ", scenario$p2, ")"),
    rho = scenario$rho,
    n_per_group = ss$n2,
    N_total = ss$N,
    power_cont = power$powerCont,
    power_binary = power$powerBin,
    power_both = power$powerCoprimary
  )
})

power_check <- bind_rows(power_results)

kable(power_check,
      caption = "Power Verification for Selected Scenarios",
      digits = 3,
      col.names = c("δ*", "Binary (π₁, π₂)", "ρ", "n per group", 
                    "N total", "Power (Cont)", "Power (Binary)", "Power (Both)"))
```

All scenarios achieve approximately 0.8 power for co-primary endpoints.

## Impact of Test Method

Compare different test methods for the binary endpoint:

```{r test_method_comparison}
# Fixed scenario
delta <- 0.15
p1 <- 0.65
p2 <- 0.50
rho <- 0.5

test_methods <- c("AN", "ANc", "AS", "ASc")

test_comparison <- lapply(test_methods, function(test_method) {
  result <- ss2MixedContinuousBinary(
    delta = delta,
    sd = 1,
    p1 = p1,
    p2 = p2,
    rho = rho,
    r = 1,
    alpha = 0.025,
    beta = 0.2,
    Test = test_method
  )
  
  data.frame(
    Test_method = test_method,
    n_per_group = result$n2,
    N_total = result$N
  )
})

test_comparison_table <- bind_rows(test_comparison)

kable(test_comparison_table,
      caption = "Comparison of Different Test Methods for Binary Endpoint",
      digits = 0,
      col.names = c("Test Method", "n per group", "N total"))
```

**Key findings**:
- **AN** (no continuity correction): Smallest sample size
- **ANc** (with continuity correction): Slightly larger (~1-5% increase)
- **AS** (arcsine): Similar to AN
- **ASc** (arcsine with CC): Similar to ANc

## Correlation Impact Visualization

```{r correlation_impact_plot, fig.width=8, fig.height=6}
# Fixed effect sizes, vary correlation
delta <- 0.15
p1 <- 0.65
p2 <- 0.50

rho_seq <- seq(0, 0.8, by = 0.05)

sample_sizes <- sapply(rho_seq, function(rho) {
  result <- ss2MixedContinuousBinary(
    delta = delta,
    sd = 1,
    p1 = p1,
    p2 = p2,
    rho = rho,
    r = 1,
    alpha = 0.025,
    beta = 0.2,
    Test = "AN"
  )
  result$N
})

plot(rho_seq, sample_sizes,
     type = "l", lwd = 2, col = "blue",
     xlab = "Biserial Correlation (ρ)",
     ylab = "Total Sample Size (N)",
     main = paste0("Sample Size vs Correlation\n",
                   "δ*=", delta, ", Binary: (", p1, ", ", p2, ")"),
     las = 1)
grid()

# Add reference line at rho=0
abline(h = sample_sizes[1], lty = 2, col = "gray")

# Calculate reductions
reduction_05 <- round((1 - sample_sizes[11]/sample_sizes[1]) * 100, 1)
reduction_08 <- round((1 - sample_sizes[17]/sample_sizes[1]) * 100, 1)

legend("topright",
       legend = c(
         paste0("ρ=0.5: ", reduction_05, "% reduction"),
         paste0("ρ=0.8: ", reduction_08, "% reduction")
       ),
       bty = "n")
```

## Clinical Application: Alzheimer's Disease Trial

Consider an Alzheimer's trial with:

1. **ADAS-cog** (continuous): Cognitive assessment scale
2. **CIBIC-plus** (binary): Clinical global impression of change (improved vs not improved)

```{r alzheimers_mixed_example}
# Parameters
alzheimers_design <- ss2MixedContinuousBinary(
  delta = 3.0,      # ADAS-cog: 3-point improvement
  sd = 10.0,        # SD = 10 points
  p1 = 0.40,        # CIBIC-plus: 40% improved (treatment)
  p2 = 0.25,        # CIBIC-plus: 25% improved (placebo)
  rho = 0.5,        # Moderate correlation
  r = 1,
  alpha = 0.025,
  beta = 0.1,       # 90% power
  Test = "AN"
)

cat("Alzheimer's Trial Design (Mixed Endpoints):\n")
cat("Sample size per group:", alzheimers_design$n2, "\n")
cat("Total sample size:", alzheimers_design$N, "\n\n")

# Compare with no correlation
alzheimers_nocorr <- ss2MixedContinuousBinary(
  delta = 3.0,
  sd = 10.0,
  p1 = 0.40,
  p2 = 0.25,
  rho = 0,  # No correlation
  r = 1,
  alpha = 0.025,
  beta = 0.1,
  Test = "AN"
)

cat("If correlation ignored (ρ=0):\n")
cat("Sample size per group:", alzheimers_nocorr$n2, "\n")
cat("Total sample size:", alzheimers_nocorr$N, "\n\n")

reduction <- alzheimers_nocorr$N - alzheimers_design$N
pct_reduction <- round(reduction / alzheimers_nocorr$N * 100, 1)

cat("Benefit of accounting for correlation:\n")
cat("Sample size reduction:", reduction, "subjects\n")
cat("Percentage reduction:", pct_reduction, "%\n")
```

## Comparison with Two Continuous Endpoints

How do mixed endpoints compare to two continuous endpoints?

```{r mixed_vs_two_continuous}
# Mixed endpoints
mixed <- ss2MixedContinuousBinary(
  delta = 0.3,
  sd = 1,
  p1 = 0.65,
  p2 = 0.50,
  rho = 0.5,
  r = 1,
  alpha = 0.025,
  beta = 0.2,
  Test = "AN"
)

# Two continuous (same effect size)
two_cont <- ss2Continuous(
  delta1 = 0.3,
  delta2 = 0.3,
  sd1 = 1,
  sd2 = 1,
  rho = 0.5,
  r = 1,
  alpha = 0.025,
  beta = 0.2,
  known_var = TRUE
)

comparison <- data.frame(
  Endpoint_types = c("Mixed (Continuous + Binary)", "Two Continuous"),
  n_per_group = c(mixed$n2, two_cont$n2),
  N_total = c(mixed$N, two_cont$N)
)

kable(comparison,
      caption = "Comparison: Mixed vs Two Continuous Endpoints (ρ=0.5)",
      digits = 0,
      col.names = c("Endpoint Types", "n per group", "N total"))
```

**Finding**: Mixed endpoints and two continuous endpoints require similar sample sizes when effect sizes are comparable.

## Summary

### Key Findings

1. **Correlation impact**: 5-7% reduction at ρ = 0.8, similar to other endpoint types

2. **Power balance** (c₁*/c₂*):
   - When c₁*/c₂* = 1: Equal power, correlation matters most
   - When c₁*/c₂* = 3: Binary endpoint dominates, correlation impact minimal

3. **Test method**: AN (no continuity correction) gives smallest sample size; continuity correction adds 1-5%

4. **Comparison with two continuous**: Sample sizes are similar when effect sizes are comparable

5. **Biserial correlation**: More challenging to estimate than Pearson correlation; requires understanding of latent variable structure

### Practical Recommendations

- **Estimating ρ**: Use pilot data or historical studies; be conservative if uncertain
- **Test selection**: AN is most common; use Fisher for small samples or regulatory requirements
- **Sample size planning**: Calculate for ρ = 0 (conservative) and expected ρ (realistic)

### Challenges

1. **Correlation estimation**: Biserial correlation is harder to estimate than Pearson
2. **Latent variable assumption**: Binary endpoint must conceptually have an underlying continuous scale
3. **Threshold specification**: The dichotomization threshold affects correlation

## References

Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination in clinical trials with multiple co-primary endpoints including mixed continuous and binary variables. *Biometrical Journal*, 54(5), 716-729.

Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination in superiority clinical trials with multiple co-primary correlated endpoints. *Journal of Biopharmaceutical Statistics*, 21(4), 650-668.

Tate, R. F. (1954). Correlation between a discrete and a continuous variable. Point-biserial correlation. *Annals of Mathematical Statistics*, 25, 603-607.
