---
title: "Overview of Two Co-Primary Endpoints Analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Overview of Two Co-Primary Endpoints Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

The `twoCoprimary` package provides comprehensive tools for sample size calculation and power analysis in clinical trials with two co-primary endpoints. This package implements methodologies from multiple publications and supports various endpoint types.

```{r setup}
library(twoCoprimary)
```

## What are Co-Primary Endpoints?

In clinical trials, **co-primary endpoints** are multiple primary endpoints that must **all** show statistically significant treatment effects for the trial to be considered successful. This is in contrast to multiple primary endpoints where demonstrating an effect on **any one** endpoint is sufficient.

### Statistical Properties

- **No multiplicity adjustment needed** for Type I error control
- The overall Type I error rate is controlled at level α without Bonferroni correction
- The overall power is the joint probability: Power = P(Reject H₀₁ **and** Reject H₀₂)
- Accounting for **correlation** between endpoints can improve efficiency

### Hypotheses Structure

For two co-primary endpoints, we test:

**Null hypothesis**: H₀ = H₀₁ ∪ H₀₂ (at least one null hypothesis is true)

**Alternative hypothesis**: H₁ = H₁₁ ∩ H₁₂ (both alternative hypotheses are true)

We reject H₀ only if **both** H₀₁ and H₀₂ are rejected at level α.

## Statistical Framework

### Intersection-Union Test (IUT)

The co-primary endpoint framework is based on the intersection-union test principle. Let Z₁ and Z₂ be the test statistics for endpoints 1 and 2, respectively.

**Decision rule**: Reject H₀ if and only if:
$$Z_1 > z_{1-\alpha} \text{ and } Z_2 > z_{1-\alpha}$$

where z₁₋α is the (1-α)-th quantile of the standard normal distribution.

### Type I Error Control

The overall Type I error rate is:

$$\alpha_{\text{overall}} = P(\text{Reject } H_0 \mid H_0 \text{ true})$$

Under the intersection-union test, this is automatically controlled at level α without adjustment:

$$\alpha_{\text{overall}} \leq \alpha$$

This is because rejecting when **both** statistics exceed the threshold is more conservative than rejecting when **either** statistic exceeds the threshold.

### Overall Power

Under the alternative hypothesis H₁, the overall power is:

$$1 - \beta = P(Z_1 > z_{1-\alpha} \text{ and } Z_2 > z_{1-\alpha} \mid H_1)$$

When (Z₁, Z₂) follow a bivariate normal distribution with correlation ρ:

$$1 - \beta = \Phi_2(-z_{1-\alpha} + \mu_1, -z_{1-\alpha} + \mu_2 \mid \rho)$$

where:
- Φ₂(·, · | ρ) is the bivariate normal cumulative distribution function with correlation ρ
- μ₁ and μ₂ are the non-centrality parameters under H₁

### Impact of Correlation

The correlation ρ between test statistics affects the overall power:

- **Positive correlation** (ρ > 0): Increases power and reduces required sample size
- **Zero correlation** (ρ = 0): Test statistics are independent
- **Negative correlation** (ρ < 0): Decreases power and increases required sample size

**Key insight**: Accounting for positive correlation between endpoints can lead to substantial sample size reductions (typically 5-15% for ρ = 0.5-0.8) compared to assuming independence.

## Supported Endpoint Types

The package supports five combinations of co-primary endpoints:

### 1. Two Continuous Endpoints

**Use case**: Trials measuring two continuous outcomes (e.g., systolic and diastolic blood pressure)

**Statistical model**: Both endpoints follow normal distributions

**Key functions**:
- `ss2Continuous()`: Sample size calculation
- `power2Continuous()`: Power calculation

**Reference**: Sozu et al. (2011)

```{r two_continuous_example, eval=FALSE}
# Example: Two continuous endpoints with correlation ρ = 0.5
ss2Continuous(
  delta1 = 0.5,  # Standardized effect size for endpoint 1
  delta2 = 0.5,  # Standardized effect size for endpoint 2
  r = 1,         # Balanced allocation
  rho = 0.5,     # Correlation between endpoints
  alpha = 0.025,
  beta = 0.2
)
```

### 2. Two Binary Endpoints (Asymptotic Approximation)

**Use case**: Trials with two binary outcomes using normal approximation (large sample)

**Statistical model**: Binary endpoints with asymptotic normal approximation

**Key functions**:
- `ss2Binary()`: Sample size calculation
- `power2Binary()`: Power calculation

**Reference**: Sozu et al. (2010)

**When to use**: Large sample sizes (typically N > 200) and probabilities not too extreme (0.1 < p < 0.9)

```{r two_binary_approx_example, eval=FALSE}
# Example: Two binary endpoints
ss2Binary(
  p11 = 0.7, p21 = 0.4,  # Endpoint 1: treatment vs control
  p12 = 0.6, p22 = 0.3,  # Endpoint 2: treatment vs control
  r = 1,
  rho1 = 0.3, rho2 = 0.3,
  alpha = 0.025,
  beta = 0.2
)
```

### 3. Two Binary Endpoints (Exact Methods)

**Use case**: Small to medium sample sizes requiring exact inference

**Statistical model**: Binary endpoints with exact tests

**Key functions**:
- `ss2BinaryExact()`: Sample size calculation using exact tests
- `power2BinaryExact()`: Exact power calculation

**Reference**: Homma and Yoshida (2025)

**Supported tests**:
- Fisher's exact test (conditional test)
- Z-pooled exact unconditional test (Barnard's test variant)
- Boschloo's exact unconditional test (uniformly most powerful)

**When to use**: Small/medium samples (N < 200), extreme probabilities (p < 0.1 or p > 0.9), or when strict Type I error control is required

```{r two_binary_exact_example, eval=FALSE}
# Example: Exact methods for small samples
ss2BinaryExact(
  p11 = 0.7, p21 = 0.4,
  p12 = 0.6, p22 = 0.3,
  r = 1,
  rho1 = 0.5, rho2 = 0.5,
  alpha = 0.025,
  beta = 0.2,
  test = "Fisher"  # or "Z-pooled", "Boschloo"
)
```

### 4. Mixed Continuous and Binary Endpoints

**Use case**: Trials with one continuous and one binary outcome

**Statistical model**: Normal distribution for continuous endpoint, Bernoulli for binary endpoint, with biserial correlation

**Key functions**:
- `ss2MixedContinuousBinary()`: Sample size calculation
- `power2MixedContinuousBinary()`: Power calculation

**Reference**: Sozu et al. (2012)

**Correlation structure**: Uses biserial correlation between observed continuous variable and latent continuous variable underlying the binary outcome

```{r mixed_cont_binary_example, eval=FALSE}
# Example: Continuous + Binary endpoints
ss2MixedContinuousBinary(
  delta = 0.5,    # Standardized effect for continuous endpoint
  p1 = 0.7, p2 = 0.4,  # Binary endpoint probabilities
  r = 1,
  rho1 = 0.3, rho2 = 0.3,
  alpha = 0.025,
  beta = 0.2
)
```

### 5. Mixed Count and Continuous Endpoints

**Use case**: Trials with overdispersed count data (e.g., exacerbations) and continuous outcomes (e.g., lung function)

**Statistical model**: Negative binomial distribution for count endpoint, normal distribution for continuous endpoint

**Key functions**:
- `ss2MixedCountContinuous()`: Sample size calculation
- `power2MixedCountContinuous()`: Power calculation
- `corrbound2MixedCountContinuous()`: Calculate valid correlation bounds

**Reference**: Homma and Yoshida (2024)

**Special consideration**: The negative binomial distribution accommodates overdispersion (variance > mean) common in count data

```{r mixed_count_cont_example, eval=FALSE}
# Example: Count (exacerbations) + Continuous (FEV1)
ss2MixedCountContinuous(
  r1 = 1.0, r2 = 1.25,  # Count rates
  nu = 0.8,              # Dispersion parameter
  t = 1,                 # Follow-up time
  mu1 = -50, mu2 = 0,    # Continuous means
  sd = 250,              # Standard deviation
  r = 1,
  rho1 = 0.4, rho2 = 0.4,
  alpha = 0.025,
  beta = 0.2
)
```

## Impact of Correlation

A key advantage of accounting for correlation between co-primary endpoints is the potential for **sample size reduction**.

The table below illustrates this for two continuous endpoints:

```{r correlation_impact}
# Sample size at different correlation levels
correlations <- c(0, 0.3, 0.5, 0.8)
results <- sapply(correlations, function(rho) {
  ss2Continuous(
    delta1 = 0.5,
    delta2 = 0.5,
    sd1 = 1,
    sd2 = 1,
    rho = rho,
    r = 1,
    alpha = 0.025,
    beta = 0.2
  )$N
})

data.frame(
  Correlation = correlations,
  Total_N = results,
  Reduction = paste0(round((1 - results/results[1]) * 100, 1), "%")
)
```

As correlation increases, the required sample size decreases. At ρ = 0.8, approximately 11% reduction in sample size can be achieved compared to ρ = 0.

### Why Does Correlation Matter?

The correlation between endpoints affects the joint distribution of test statistics. When endpoints are positively correlated:

1. **Test statistics tend to move together**: If Z₁ is large, Z₂ is also likely to be large
2. **Higher probability of rejecting both nulls**: P(Z₁ > c and Z₂ > c) increases with ρ
3. **Sample size reduction**: Fewer subjects needed to achieve target power

Mathematically, for bivariate normal (Z₁, Z₂) with correlation ρ:

$$P(Z_1 > c, Z_2 > c \mid \rho) > P(Z_1 > c, Z_2 > c \mid \rho = 0)$$

when ρ > 0 and both endpoints have positive treatment effects.

## Choosing the Right Method

| Endpoint Types | Sample Size | Method | Key Considerations |
|----------------|-------------|--------|-------------------|
| Both continuous | Any | Asymptotic | Simple, well-established |
| Both binary | Large (N > 200) | Asymptotic | Fast computation, probabilities moderate |
| Both binary | Small/Medium | Exact | Better Type I error control, exact inference |
| 1 Continuous + 1 Binary | Any | Asymptotic | Handles mixed types, biserial correlation |
| 1 Count + 1 Continuous | Any | Asymptotic | Accounts for overdispersion |

### Decision Guidelines

**For binary endpoints**:
- Use **asymptotic methods** when: N > 200, 0.1 < p < 0.9, computational efficiency important
- Use **exact methods** when: N < 200, extreme probabilities (p < 0.1 or p > 0.9), regulatory requirements for exact tests

**For mixed endpoint types**:
- Ensure correlation structure is appropriate (e.g., biserial for continuous-binary)
- Consider clinical plausibility of correlation magnitude
- Use conservative estimates if correlation is uncertain

## Sample Size Calculation Approach

All methods in this package follow a similar computational approach:

1. **Specify design parameters**: Effect sizes, probabilities, standard deviations, etc.
2. **Specify correlation**: Between endpoints or test statistics
3. **Specify error rates**: Type I error α (typically 0.025 for one-sided) and Type II error β (typically 0.2 for 80% power)
4. **Calculate sample size**: Using analytical formulas or iterative algorithms
5. **Verify power**: Confirm that calculated sample size achieves target power

### Linear Extrapolation Algorithm

For some endpoint types (e.g., mixed count-continuous), an iterative linear extrapolation algorithm is used:

1. Calculate initial sample sizes from single-endpoint formulas
2. Compute power at these sample sizes
3. Refine using linear extrapolation: n⁽ⁱ⁺¹⁾ = n⁽ⁱ⁾ × (1 - β) / power⁽ⁱ⁾
4. Iterate until convergence

## Detailed Vignettes

For detailed methodology, examples, and validation against published results, please see:

1. `vignette("two-continuous-endpoints")`: Two continuous endpoints
2. `vignette("two-binary-endpoints-approx")`: Two binary endpoints (asymptotic)
3. `vignette("two-binary-endpoints-exact")`: Two binary endpoints (exact)
4. `vignette("mixed-continuous-binary")`: Mixed continuous and binary
5. `vignette("mixed-count-continuous")`: Mixed count and continuous

## References

1. Sozu, T., Sugimoto, T., & Hamasaki, T. (2011). Sample size determination in superiority clinical trials with multiple co-primary continuous endpoints. *Japanese Journal of Biometrics*, 32(1), 15-31.

2. Sozu, T., Sugimoto, T., & Hamasaki, T. (2010). Sample size determination in clinical trials with multiple co-primary binary endpoints. *Statistics in Medicine*, 29(21), 2169-2179.

3. Homma, G., & Yoshida, T. (2025). Exact power and sample size in clinical trials with two co-primary binary endpoints. *Statistical Methods in Medical Research* (in press).

4. Sozu, T., Sugimoto, T., & Hamasaki, T. (2012). Sample size determination in clinical trials with multiple co-primary endpoints including mixed continuous and binary variables. *Biometrical Journal*, 54(5), 716-729.

5. Homma, G., & Yoshida, T. (2024). Sample size calculation in clinical trials with two co-primary endpoints including overdispersed count and continuous outcomes. *Pharmaceutical Statistics*, 23(1), 46-59.
